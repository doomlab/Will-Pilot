---
title             : "Moral Foundations of U.S. Political News Organizations"
shorttitle        : "MORAL NEWS"

author:
  - name          : "William E. Padfield"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "901 S. National Ave, Springfield, MO, 65897"
    email         : "wpadfield@gmail.com"
  - name          : "Erin M. Buchanan, Ph.D."
    affiliation   : "2"
  - name          : "Kayden N. Jordan, Ph.D."
    affiliation   : "2"

affiliation:
  - id            : "1"
    institution   : "Missouri State University"
  - id            : "2"
    institution  : "Harrisburg University of Science and Technology"

authornote: |
  William Padfield completed this project as part of his thesis requirements for a master's degree candidate in Psychology at Missouri State University. Submitted to Meta-Psychology. Participate in open peer review by commenting through hypothes.is directly on this preprint. The full editorial process of all articles under review at Meta-Psychology can be found following this link: https://tinyurl.com/mp-submissions

abstract: |
  Partisan differences and diviseness have become an increasing hot topic in psychological research. Many theories have been proposed to explain these differences and divisions including Moral Foundations Theory. The current research seeks to use a linguistic measure of Moral Foundations, the Moral Foundations Dictionary (MFD), to test the theory in terms of predicted partisan differences. Through web scraping, we extracted articles from popular partisan news sources' websites, calculated MFD word frequencies, and identified words' respective valences. This process attempts to uncover news outlets' positive or negative endorsements of certain moral dimensions concomitant with a particular ideology. In Study 1, we gathered political articles from four sources. We were unable to reveal significant differences in moral endorsements, but we solidified the method to be employed in further research. In Study 2, we expanded their number of sources to 10 and analyzed articles that pertain to two specific topics: the 2018 confirmation hearings of U.S. Supreme Court Justice Brett Kavanaugh and the partial U.S. Government Shutdown of 2018-2019. Once again, no significant differences in moral endorsements were found. Together with past work, the results shed doubt on the validity of the MFD as a reliable measurement tool.

keywords          : "politics, morality, psycholinguistics"

bibliography      : ["./metapsych_bib.bib"] #turn this off right now so it knits

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r load_packages, include = FALSE}
library(papaja)
library(MuMIn)
library(reshape)
library(nlme)
library(ggplot2)
library(expss)
library(MOTE)
library(quanteda)
library(quanteda.textstats)
library(tm)
library(ngram)
library(ggplot2)
library(reshape)
library(knitr)
library(performance)
library(dplyr)
library(rio)

knitr::opts_chunk$set(cache = TRUE)
options(tinytex.verbose = TRUE)
percentmiss <- function(x){sum(is.na(x))/length(x)*100}
```

The field of moral psychology has a long history with modern moral psychology beginning in the late 1960s with Lawrence Kohlberg's theory of moral development [@Kohlberg1977]. Since then, Kohlberg's theory has been highly criticized with numerous theories and hypotheses proposed to replace it. One of these theories is Moral Foundations Theory (MFT) proposed by Jonathan Haidt and Jesse Graham [@Haidt2007]. While the theory itself has been widely criticized and debated, the goal of the current work is to tackle a related measurement issue, the Moral Foundations Dictionary (MFD) [@Graham2009]. @Graham2009 developed a lexicon-based linguistic measure of MFT arguing that moral concerns and the propositions of MFT could be measured and tested with the words people use. Here we first review evidence and criticisms against this assumption. We then provide our own test of the MFD using partisan news articles.

## Moral Foundations Dictionary

Haidt and Jesse (2007) formulated MFT as a method by which to capture the entirety of humans' moral domain. We argued older theories of moral psychology were focused primarily on issues of justice, fairness, and caring - individually focused foundations of morality that align with the beliefs of political liberals. In other words, moral psychology ignored the valid moral foundations of conservatives. MFT holds that people's moral domain can be mapped by quantifying their endorsement of five moral foundations: *harm/care*, *fairness/reciprocity*, *ingroup/loyalty*, *authority/respect*, and *purity/sanctity* [@Haidt2007].

In order to capture language's role in moral and political reasoning, @Graham2009 formulated the MFD in order to capture moral reasoning and justification as used in speech and text. The MFD is composed of 259 words, with around 50 words assigned to each of the five foundations. @Graham2009 created a preliminary list of words that they believed would be associated with the five foundations. Then, using the Linguistic Inquiry and Word Count [LIWC; @Pennebaker2007] computer program, they analyzed transcripts of liberal and conservative Christian sermons in order to obtain frequencies of the occurrence of words from we' initial list.

Similar to previous research on MFT, liberal ministers used *harm*, *fairness*, and *ingroup* words more often than conservative ministers. Conversely, conservative ministers used *authority* and *purity* words more often than liberal ministers. However, conservative ministers did not use *ingroup/loyalty* words more than liberals. Rather, liberal ministers used words pertaining to *ingroup/loyalty*, but in contexts that promote rebellion and independence - causes *opposite* to positive endorsements of that foundation [@Graham2009].

## Critiques of Moral Foundations

MFT has received criticism on the grounds that its assumptions regarding moral intuitions have little empirical basis. @Suhler2011 criticized the content and taxonomy of the five foundations and question whether or not the foundations are sufficiently distinct as to stand as their own foundation. Likewise, @Gray2015 argues that the measurement of the moral foundations confounds morality with other constructs (such as weirdness) and the moral foundations lack statistical and conceptual distinction. @Schein2015 argues that harm-based morality is the most parsimonious and logical explanation for MFT findings.

Beyond the critiques of the theory itself, many have also provided strong critiques of the measurement using MFD. Conducting two close conceptual replication studies using religious sermons and six extension studies using U.S. Congressional speeches, party platforms, State of the Union addresses, media outlets, and political organization texts, @Frimer2020 found that the liberal-conservative differences found in the original study replicated in only 30% of cases and the effect sizes were over 30 times smaller than reported in @Graham2009. In a meta-analysis, the theorized differences were only found for authority and purity (e.g., conservatives used more authority and purity words). Loyalty was contrary to theoretical predictions (e.g., used more by liberals), and no differences were found for harm and fairness. Additionally, @Frimer2020 tested the theory under the most forgiving conditions using not only the original MFD but also the revised MFD2 as well using log transformed scores as well as raw scores. Even under the best circumstances (log transformed MFD2 scores), only 2 of the foundations showed theorized differences but with very small effects. Other studies have also found conflicting findings which fail to support the basic assertions of MFT. Exploring the political Twitterverse, @Sterling2018 found differences in the MFD depend on political sophistication. For example, harm words were used more by liberals only if they had low levels of political sophistication; at high levels of political sophistication, conservatives used more harm words. While the MFD has not been extensively used (at least in published research), studies which have use the MFD to test partisan differences have found mixed results in terms of supporting MFT [@Clifford2013; @Frimer2015; @Sagi2014]. Like @Frimer2020, we attempt to give the MFD the best chance for success by incorporating a weighting method to address the skewedness and sparsity of the linguistic data.

The most successful attempts to validate a linguistic measure of moral foundations have used more complex methods (compared to the original dictionary-based approach). These attempts generally fall into two categories: human annotations and semantic representations. @Hopp2021 represents the first approach where instead of relying on 'experts', a large sample of lay people were crowdsourced to manually annotate document for content relevant to each foundation. While resource-intensive, this method better captures how people may encounter and judge moral issues in everyday life leading to a more ecologically valid dictionary. @Garten2016 represents the second categories which instead relies on data-driven semantic analysis. Using shallow neural net models like word2vec [@mikolov_efficient_2013], moral foundations were measured using semantic similarity vectors rather than simple word counts.

As a further conceptual replication of @Frimer2020, we test the liberal-conservative difference proposed by MFT using partisan media content and the MFD. We first test differences in a general news corpus compared liberal sources (National Public Radio [NPR] and the New York Times [NYT]) to conservative sources (Fox News and Breitbart). Second, we examined news about specific political events: Brett Kavanaugh's U.S. Supreme Court nomination and the U.S. Government Shutdown in 2018-2019. In the second study, the news sources were expanded to cover NYT, NPR, Slate, Huffington Post, and Politico on the liberal side and Fox News, Breitbart, The Rush Limbaugh Show, The Blaze, and Sean Hannity on the conservative side. To address potential issues of measurement with the MFD, the MFD was combined with previous research by the current authors (see below) and weighted by valence to create weighted percentages to better specify endorsement. Like @Frimer2020, results were judged based on the direction of the liberal-conservative difference compared MFT predictions and the size of the effect compared to past studies.

# Study 1

# Method

For the first study, we approached the study with the intention to answer a method question. That is, this portion of the current research was conducted in order to solidify the best method by which to analyze political news text under the MFT framework while also alleviating some of the aforementioned valence problem observed in the MFD. We hypothesized the news sources generally perceived as liberal leaning (*NPR* and *The New York Times*) would contain MFD words and valences indicating endorsements of the individualizing moral foundations (*harm/care* and *fairness/reciprocity*). Additionally, we hypothesized the two sources generally perceived to be conservative leaning (*Fox News* and *Breitbart*) would feature MFD words and valences indicating equal endorsement of all five foundations.

## Sources

Political articles were collected from the websites of four notable U.S. news sources, a process known as web scraping. The sources were *NYT*, *NPR*, *Fox News*, and *Breitbart*. They were selected for their widespread recognition and the fact political partisans have strong preferences for some sources over others. We determined the political lean of each source by referencing @Mitchell2014's article demonstrating the self-reported ideological consistency represented by the consumers of several news sources. In general, the *NYT* and *NPR* are preferred by consumers reporting a liberal bias or lean. In contrast, *Fox News* and *Breitbart* are believed to have a conservative bias or lean. @Mitchell2014's article presented political ideology as a scale ranging from "consistently liberal" to "consistently conservative." In between these extremes lie more moderate positions, including "mostly liberal," "mixed," and "mostly conservative." Owing to the lower number of sources analyzed herein, we elected to categorize the sources as either "liberal" and "conservative" in order to form a basis for comparison. At the time of our data collection, these sources were also selected because they were open (i.e., no subscription required to access articles), and their websites were designed in a way that made webscraping possible.

Political articles in particular were identified and subsequently scraped by including the specific URL directing to each source's political content in the *R* script. For example, rather than scrape from nytimes.com, which would return undesired results (non-political features, reviews, etc.), we instead included nytimes.com/section/politics so that more or less exclusively political content was obtained. All code for this manuscript can be found at https://osf.io/5kpj7/, and the scripts are provided inline with this manuscript written with the *papaja* library [@Aust2017].

Identification of the sources' political URLs presented a problem for two of the sources owing to complications with how their particular sites were structured. While in the multi-week process of scraping articles, we noticed word counts for *NPR* and *Fox News* were not growing at a similar pace as those from the *NYT* and *Breitbart*. Upon investigation, we found another, more robust URL for political content from NPR: their politics content "archive." The page structure on NPR's website was such that only a limited selection of articles is displayed to the user at a given time. Scraping both the archive and the normal politics page ensured we were obtaining most (if not all) new articles as they were published. We later ran a process in order to exclude any duplicate articles. *Fox News* presented a similar issue. We discovered *Fox News* utilized six URLs in addition to the regular politics page. These URLs led to pages containing content pertaining the U.S. Executive Branch, Senate, House of Representatives, Judicial Branch, foreign policy, and elections. Once again, duplicates were subsequently eliminated from any analyses.  

## Materials

Using the *rvest* library in the statistical package *R*, we pulled body text for individual articles from each of the aforementioned sources (identified using CSS language) and compiled them into a dataset [@Wickham2016]. Using this dataset, we identified word count and average word count per source. This process was completed once daily starting in February 2018 until March 2018. Starting in mid-March 2018, the process was completed twice daily - once in the morning and again in the evening. Data collection was terminated once 250,000 words per source was collected in April 2018.  

```{r include = F, eval = F}
# to see the web scraping and data cleanup for this section see web_scraping.Rmd
# this code was run previously to create the data for this manuscript
# note that website changes to places like the NYT means it likely does
# not run in the same way anymore
```

## Data analysis

Once data collection ended, the text was scanned using the *ngram* package in *R* [@Schmidt2017]. This package includes a word count function, which was used to remove articles that came through as blank text, as well as to eliminate text picked up from the Disqus commenting system used by certain websites. At this point, duplicate articles were discarded.

The article text was processed using the *tm* and *ngram* packages in *R* in order to render the text in lowercase, remove punctuation, and fix spacing issues [@Feinerer2017]. The individual words were then reduced to their stems (i.e., *abused* was stemmed to *abus*). The same procedure was applied to the MFD words and the words in the @Warriner2013 dataset. Using the @Warriner2013 dictionary, the words making up each of the five foundations in the MFD were matched to their respective valence value.   

Concurrent research by @Jordan2019 assesses the validity of both the MFQ and the MFD through a multi-trait multi-method analysis of the two instruments using multiple samples. The instruments and foundation areas are being analyzed against one another, in order to test reliability, as well as against the Congressional Record in order to test predictive validity for political orientation. We were able to identify a number of potential new words that, if added to the MFD, could comprise a dictionary with greater validity, and less likelihood of zero percent texts, as this often occurs with the current MFD. Those results have informed this analysis, and their updated findings may change the underlying dictionary used in this analysis (albeit, we do not expect any changes in the results presented below).

A complete list of the words for each moral foundation area was created from previous experiments. The total number of times each of those words was used in an article was calculated. This information was merged with the valence values from the @Warriner2013 dataset. A weighted score was calculated by multiplying the frequency of occurrence within a document times the *z*-scored valence values and divided by the word count for that article. The final score was multiplied by 100 to represented a weighted percentage. Finally, the weighted scores were summed within in each article to get a total weighted percentage of the use of moral area specific words by article. Valences were *z*-scored in order to eliminate any ambiguity regarding the direction of the valence. Positive values indicate positive valence, and negative values indicate negative valence. Words were categorized in accordance to their MFD affiliation, creating a weighted sum for each moral foundation. See Table \@ref(tab:example-weight) for an example. 

```{r stem_text, eval=TRUE, include=FALSE}
final = read.csv("./exp1_data/finaldata.csv", stringsAsFactors = F)
final = na.omit(final) #one weird NA line

#process the Text column (write a loop) - save processed text as a separate column
for(i in 1:nrow(final)) {

  final$edited[i] = preprocess(final$Text[i], #one value at a time
           case = "lower",
           remove.punct = TRUE,
           remove.numbers = FALSE,
           fix.spacing = TRUE)

##stem the words - do this second in the loop
  final$stemmed[i] = stemDocument(final$edited[i], language = "english")
}

```

```{r stem_warriner, include = FALSE}
##open the Warriner data for later
warriner = read.csv("./exp1_data/BRM-emot-submit.csv", stringsAsFactors = F) #want v.mean.sum
warriner$V.Mean.Sum = scale(warriner$V.Mean.Sum)

for(i in 1:nrow(warriner)) {
  warriner$Word2[i] = stemDocument(warriner$Word[i], language = "english")
}
```

```{r create_datasets_harm, echo = F, include=FALSE}
#read in the harm total words from the mtmm project
harm_all = read.csv("./exp1_data/harm_words_total.csv", stringsAsFactors = F)

harm_final_data = data.frame("URL" = NA, "Source" = NA, "Var1" = NA, "Freq" = NA, "wordcount" = NA)

for (i in 1:nrow(final)) {
##first make a table of a response, unlisting everything
temp = as.data.frame(table(unlist(strsplit(final$stemmed[i], " "))))

#only pull the words in the dataset for each foundation
temp2 = temp[temp$Var1 %in% unique(harm_all$words[harm_all$words != "" & harm_all$words != "NA" & !is.na(harm_all$words)]), ]

#control here for times when no words
if (nrow(temp2) == 0){
  temp2 = data.frame("Var1" = 0, "Freq" = 0)
}

#add to the dataset
temp2$URL = final$Url[i]
temp2$Source = final$Source[i]
temp2$wordcount = final$wordcount[i]

#bind with original
harm_final_data = rbind(harm_final_data, temp2)
}

#pull in the data from Warriner
harm_final_data$valence = vlookup(harm_final_data$Var1, #index in original data
                                  warriner, #where's the stuff you want to put in
                                  "V.Mean.Sum", #what column is the stuff you want
                                  "Word2") #what's the matching index

#figure out stupid words
#table(harm_final_data$Var1[is.na(harm_final_data$valence) & harm_final_data$Freq > 0])
#fought, safer, spurn
harm_final_data$valence[harm_final_data$Var1 == "fought"] = warriner$V.Mean.Sum[warriner$Word2 == "fight"]
harm_final_data$valence[harm_final_data$Var1 == "safer"] = warriner$V.Mean.Sum[warriner$Word2 == "safe"]
#no spurn available
```

```{r create_datasets_fair, include=FALSE}
fair_all = read.csv("./exp1_data/fair_words_total.csv", stringsAsFactors = F)

fair_final_data = data.frame("URL" = NA, "Source" = NA, "Var1" = NA, "Freq" = NA, "wordcount" = NA)

for (i in 1:nrow(final)) {
##first make a table of a response, unlisting everything
temp = as.data.frame(table(unlist(strsplit(final$stemmed[i], " "))))

#only pull the words in the dataset for each foundation
temp2 = temp[temp$Var1 %in% unique(fair_all$words[fair_all$words != "" & fair_all$words != "NA" & !is.na(fair_all$words)]), ]

#control here for times when no words
if (nrow(temp2) == 0){
  temp2 = data.frame("Var1" = 0, "Freq" = 0)
}

#add to the dataset
temp2$URL = final$Url[i]
temp2$Source = final$Source[i]
temp2$wordcount = final$wordcount[i]

#bind with original
fair_final_data = rbind(fair_final_data, temp2)
}

fair_final_data$valence = vlookup(fair_final_data$Var1, #index in original data
                                  warriner, #where's the stuff you want to put in
                                  "V.Mean.Sum", #what column is the stuff you want
                                  "Word2") #what's the matching index

#figure out stupid words
table(fair_final_data$Var1[is.na(fair_final_data$valence) & fair_final_data$Freq > 0])
#just plagiar safer
fair_final_data$valence[fair_final_data$Var1 == "safer"] = warriner$V.Mean.Sum[warriner$Word2 == "safe"]
#nothing for just or plagiarism
```

```{r create_datasets_ingroup, include=FALSE}
ingroup_all = read.csv("./exp1_data/ingroup_words_total.csv", stringsAsFactors = F)

ingroup_final_data = data.frame("URL" = NA, "Source" = NA, "Var1" = NA, "Freq" = NA, "wordcount" = NA)

for (i in 1:nrow(final)) {
##first make a table of a response, unlisting everything
temp = as.data.frame(table(unlist(strsplit(final$stemmed[i], " "))))

#only pull the words in the dataset for each foundation
temp2 = temp[temp$Var1 %in% unique(ingroup_all$words[ingroup_all$words != "" & ingroup_all$words != "NA" & !is.na(ingroup_all$words)]), ]

#control here for times when no words
if (nrow(temp2) == 0){
  temp2 = data.frame("Var1" = 0, "Freq" = 0)
}

#add to the dataset
temp2$URL = final$Url[i]
temp2$Source = final$Source[i]
temp2$wordcount = final$wordcount[i]

#bind with original
ingroup_final_data = rbind(ingroup_final_data, temp2)
}

ingroup_final_data$valence = vlookup(ingroup_final_data$Var1, #index in original data
                                  warriner, #where's the stuff you want to put in
                                  "V.Mean.Sum", #what column is the stuff you want
                                  "Word2") #what's the matching index

#figure out stupid words
table(ingroup_final_data$Var1[is.na(ingroup_final_data$valence) & ingroup_final_data$Freq > 0])
#backstabb  benedict      best      fals   indvidu      juda    knight      true
ingroup_final_data$valence[ingroup_final_data$Var1 == "fals"] = warriner$V.Mean.Sum[warriner$Word2 == "FALSE"]
ingroup_final_data$valence[ingroup_final_data$Var1 == "indvidu"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "individu"])
ingroup_final_data$valence[ingroup_final_data$Var1 == "true"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "TRUE"])
```

```{r create_datasets_authority, include=FALSE}
authority_all = read.csv("./exp1_data/authority_words_total.csv", stringsAsFactors = F)

authority_final_data = data.frame("URL" = NA, "Source" = NA, "Var1" = NA, "Freq" = NA, "wordcount" = NA)

for (i in 1:nrow(final)) {
##first make a table of a response, unlisting everything
temp = as.data.frame(table(unlist(strsplit(final$stemmed[i], " "))))

#only pull the words in the dataset for each foundation
temp2 = temp[temp$Var1 %in% unique(authority_all$words[authority_all$words != "" & authority_all$words != "NA" & !is.na(authority_all$words)]), ]

#control here for times when no words
if (nrow(temp2) == 0){
  temp2 = data.frame("Var1" = 0, "Freq" = 0)
}

#add to the dataset
temp2$URL = final$Url[i]
temp2$Source = final$Source[i]
temp2$wordcount = final$wordcount[i]

#bind with original
authority_final_data = rbind(authority_final_data, temp2)
}

authority_final_data$valence = vlookup(authority_final_data$Var1, #index in original data
                                  warriner, #where's the stuff you want to put in
                                  "V.Mean.Sum", #what column is the stuff you want
                                  "Word2") #what's the matching index

#figure out stupid words
table(authority_final_data$Var1[is.na(authority_final_data$valence) & authority_final_data$Freq > 0])
#  abov behind   gase higher  older  taken
authority_final_data$valence[authority_final_data$Var1 == "gase"] = warriner$V.Mean.Sum[warriner$Word2 == "gas"]
authority_final_data$valence[authority_final_data$Var1 == "higher"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "high"])
authority_final_data$valence[authority_final_data$Var1 == "older"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "old"])
authority_final_data$valence[authority_final_data$Var1 == "taken"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "take"])
```

```{r create_datasets_purity, include=FALSE}
purity_all = read.csv("./exp1_data/purity_words_total.csv", stringsAsFactors = F)

purity_final_data = data.frame("URL" = NA, "Source" = NA, "Var1" = NA, "Freq" = NA, "wordcount" = NA)

for (i in 1:nrow(final)) {
##first make a table of a response, unlisting everything
temp = as.data.frame(table(unlist(strsplit(final$stemmed[i], " "))))

#only pull the words in the dataset for each foundation
temp2 = temp[temp$Var1 %in% unique(purity_all$words[purity_all$words != "" & purity_all$words != "NA" & !is.na(purity_all$words)]), ]

#control here for times when no words
if (nrow(temp2) == 0){
  temp2 = data.frame("Var1" = 0, "Freq" = 0)
}

#add to the dataset
temp2$URL = final$Url[i]
temp2$Source = final$Source[i]
temp2$wordcount = final$wordcount[i]

#bind with original
purity_final_data = rbind(purity_final_data, temp2)
}

purity_final_data$valence = vlookup(purity_final_data$Var1, #index in original data
                                  warriner, #where's the stuff you want to put in
                                  "V.Mean.Sum", #what column is the stuff you want
                                  "Word2") #what's the matching index

#figure out stupid words
table(purity_final_data$Var1[is.na(purity_final_data$valence) & purity_final_data$Freq > 0])
#befor christian     jesus      mari      none    sacred    someon      true     women
purity_final_data$valence[purity_final_data$Var1 == "sacred"] = warriner$V.Mean.Sum[warriner$Word2 == "sacr"]
purity_final_data$valence[purity_final_data$Var1 == "true"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "TRUE"])
purity_final_data$valence[purity_final_data$Var1 == "women"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "woman"])
```

```{r descriptives, echo = F, include = FALSE}
#summarize the dataset so that you have the total and percent for each foundation
# summary(harm_final_data)
# summary(fair_final_data)
# summary(ingroup_final_data)
# summary(authority_final_data)
# summary(purity_final_data)
# #report descriptive statistics of the foundations
# mean(harm_final_data$valence)
# sd(harm_final_data$valence)
# mean(fair_final_data$valence)
# sd(fair_final_data$valence)
# mean(ingroup_final_data$valence)
# sd(ingroup_final_data$valence)
# mean(authority_final_data$valence)
# sd(authority_final_data$valence)
# mean(purity_final_data$valence)
# sd(purity_final_data$valence)
#note that a big problem is the valence of the words
```

```{r analysis_harm, include = FALSE}
#final_data clean up
#multiply by frequency and create percentage
harm_final_data$weight = harm_final_data$Freq * harm_final_data$valence / harm_final_data$wordcount * 100

#flatten down to sum by article
harm_final_temp = aggregate(harm_final_data$weight,
          by = list(harm_final_data$URL),
          FUN = sum, na.rm = T)
colnames(harm_final_temp) = c("URL", "MFDweight")

harm_final_temp$lean[grepl("nytimes.com", harm_final_temp$URL) |
                       grepl("npr.org", harm_final_temp$URL)] = "Liberal"
harm_final_temp$lean[grepl("breitbart.com", harm_final_temp$URL) |
                       grepl("foxnews.com", harm_final_temp$URL)] = "Conservative"

harm_final_temp$Source[grepl("nytimes.com", harm_final_temp$URL)] = "NY Times"
harm_final_temp$Source[grepl("npr.org", harm_final_temp$URL)] = "NPR"
harm_final_temp$Source[grepl("foxnews.com", harm_final_temp$URL)] = "Fox"
harm_final_temp$Source[grepl("breitbart.com", harm_final_temp$URL)] = "Breitbart"

harm_icc <- lme(MFDweight ~ 1, 
                data = harm_final_temp,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source)
                )

harm_model = lme(MFDweight ~ lean,
                 data = harm_final_temp,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source)
                 )
summary(harm_model)

# check linearity
random <- rchisq(nrow(harm_final_temp), 7)
residuals <- scale(residuals(harm_model))
fitted <- scale(fitted(harm_model))
hist(residuals)
{qqnorm(residuals); abline(0,1)}
{plot(fitted, residuals); abline(h = 0); abline(v = 0)}
```

```{r analysis_fair, include = FALSE}
#final_data clean up
#multiply by frequency and create percentage
fair_final_data$weight = fair_final_data$Freq * fair_final_data$valence / fair_final_data$wordcount * 100

#flatten down to sum by article
fair_final_temp = aggregate(fair_final_data$weight,
          by = list(fair_final_data$URL),
          FUN = sum, na.rm = T)
colnames(fair_final_temp) = c("URL", "MFDweight")

fair_final_temp$lean[grepl("nytimes.com", fair_final_temp$URL) |
                       grepl("npr.org", fair_final_temp$URL)] = "Liberal"
fair_final_temp$lean[grepl("breitbart.com", fair_final_temp$URL) |
                       grepl("foxnews.com", fair_final_temp$URL)] = "Conservative"

fair_final_temp$Source[grepl("nytimes.com", fair_final_temp$URL)] = "NY Times"
fair_final_temp$Source[grepl("npr.org", fair_final_temp$URL)] = "NPR"
fair_final_temp$Source[grepl("foxnews.com", fair_final_temp$URL)] = "Fox"
fair_final_temp$Source[grepl("breitbart.com", fair_final_temp$URL)] = "Breitbart"

fair_icc <- lme(MFDweight ~ 1, 
                data = fair_final_temp,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source)
                )

fair_model = lme(MFDweight ~ lean,
                 data = fair_final_temp,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))
summary(fair_model)

# check linearity
random <- rchisq(nrow(fair_final_temp), 7)
residuals <- scale(residuals(fair_model))
fitted <- scale(fitted(fair_model))
hist(residuals)
{qqnorm(residuals); abline(0,1)}
{plot(fitted, residuals); abline(h = 0); abline(v = 0)}
```

```{r analysis_ingroup, include = FALSE}
#final_data clean up
#multiply by frequency and create percentage
ingroup_final_data$weight = ingroup_final_data$Freq * ingroup_final_data$valence / ingroup_final_data$wordcount * 100

#flatten down to sum by article
ingroup_final_temp = aggregate(ingroup_final_data$weight,
          by = list(ingroup_final_data$URL),
          FUN = sum, na.rm = T)
colnames(ingroup_final_temp) = c("URL", "MFDweight")

ingroup_final_temp$lean[grepl("nytimes.com", ingroup_final_temp$URL) |
                       grepl("npr.org", ingroup_final_temp$URL)] = "Liberal"
ingroup_final_temp$lean[grepl("breitbart.com", ingroup_final_temp$URL) |
                       grepl("foxnews.com", ingroup_final_temp$URL)] = "Conservative"

ingroup_final_temp$Source[grepl("nytimes.com", ingroup_final_temp$URL)] = "NY Times"
ingroup_final_temp$Source[grepl("npr.org", ingroup_final_temp$URL)] = "NPR"
ingroup_final_temp$Source[grepl("foxnews.com", ingroup_final_temp$URL)] = "Fox"
ingroup_final_temp$Source[grepl("breitbart.com", ingroup_final_temp$URL)] = "Breitbart"

ingroup_icc = lme(MFDweight ~ 1,
                 data = ingroup_final_temp,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))

ingroup_model = lme(MFDweight ~ lean,
                 data = ingroup_final_temp,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))
summary(ingroup_model)

# check linearity
random <- rchisq(nrow(ingroup_final_temp), 7)
residuals <- scale(residuals(ingroup_model))
fitted <- scale(fitted(ingroup_model))
hist(residuals)
{qqnorm(residuals); abline(0,1)}
{plot(fitted, residuals); abline(h = 0); abline(v = 0)}
```

```{r analysis_authority, include = FALSE}
#final_data clean up
#multiply by frequency and create percentage
authority_final_data$weight = authority_final_data$Freq * authority_final_data$valence / authority_final_data$wordcount * 100

#flatten down to sum by article
authority_final_temp = aggregate(authority_final_data$weight,
          by = list(authority_final_data$URL),
          FUN = sum, na.rm = T)
colnames(authority_final_temp) = c("URL", "MFDweight")

authority_final_temp$lean[grepl("nytimes.com", authority_final_temp$URL) |
                       grepl("npr.org", authority_final_temp$URL)] = "Liberal"
authority_final_temp$lean[grepl("breitbart.com", authority_final_temp$URL) |
                       grepl("foxnews.com", authority_final_temp$URL)] = "Conservative"

authority_final_temp$Source[grepl("nytimes.com", authority_final_temp$URL)] = "NY Times"
authority_final_temp$Source[grepl("npr.org", authority_final_temp$URL)] = "NPR"
authority_final_temp$Source[grepl("foxnews.com", authority_final_temp$URL)] = "Fox"
authority_final_temp$Source[grepl("breitbart.com", authority_final_temp$URL)] = "Breitbart"

authority_icc = lme(MFDweight ~ 1,
                 data = authority_final_temp,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))

authority_model = lme(MFDweight ~ lean,
                 data = authority_final_temp,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))
summary(authority_model)

# check linearity
random <- rchisq(nrow(authority_final_temp), 7)
residuals <- scale(residuals(authority_model))
fitted <- scale(fitted(authority_model))
hist(residuals)
{qqnorm(residuals); abline(0,1)}
{plot(fitted, residuals); abline(h = 0); abline(v = 0)}
```

```{r analysis_purity, include = FALSE}
#final_data clean up
#multiply by frequency and create percentage
purity_final_data$weight = purity_final_data$Freq * purity_final_data$valence / purity_final_data$wordcount * 100

#flatten down to sum by article
purity_final_temp = aggregate(purity_final_data$weight,
          by = list(purity_final_data$URL),
          FUN = sum, na.rm = T)
colnames(purity_final_temp) = c("URL", "MFDweight")

purity_final_temp$lean[grepl("nytimes.com", purity_final_temp$URL) |
                       grepl("npr.org", purity_final_temp$URL)] = "Liberal"
purity_final_temp$lean[grepl("breitbart.com", purity_final_temp$URL) |
                       grepl("foxnews.com", purity_final_temp$URL)] = "Conservative"

purity_final_temp$Source[grepl("nytimes.com", purity_final_temp$URL)] = "NY Times"
purity_final_temp$Source[grepl("npr.org", purity_final_temp$URL)] = "NPR"
purity_final_temp$Source[grepl("foxnews.com", purity_final_temp$URL)] = "Fox"
purity_final_temp$Source[grepl("breitbart.com", purity_final_temp$URL)] = "Breitbart"

purity_icc = lme(MFDweight ~ 1,
                 data = purity_final_temp,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))

purity_model = lme(MFDweight ~ lean,
                 data = purity_final_temp,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))
summary(purity_model)

# check linearity
random <- rchisq(nrow(purity_final_temp), 7)
residuals <- scale(residuals(purity_model))
fitted <- scale(fitted(purity_model))
hist(residuals)
{qqnorm(residuals); abline(0,1)}
{plot(fitted, residuals); abline(h = 0); abline(v = 0)}
```

```{r example-weight, results = 'asis', echo = FALSE}
temp_table <- harm_final_data %>% 
  filter(Freq > 0) %>% 
  arrange(-Freq) %>% 
  group_by(Var1) %>% 
  slice_head() %>% 
  group_by(URL) %>% 
  arrange(-Freq) %>% 
  slice_head() %>% 
  ungroup() %>% 
  slice_sample(n = 15, replace = F)

apa_table(temp_table %>% select(-URL), 
          note = "Concepts were stemmed to match datasets.",
          caption = "Example of Weighted Coding for Harm Words",
          col.names = c("Source", "Concept", "Frequency", "Total Words", "Valence", "Weighted Score"),
          format = "latex",
          escape = F,
          align = c("l", "l", rep("c", 4)),
          font_size = 'footnotesize',
          placement = "h"
          )
```

# Results

## Descriptive Statistics

```{r exp1_descriptive_calc, echo = F, include = F}
final$uniquewords = NA
final$valenceavg = NA

for (i in 1:nrow(final)){

  #add unique
  final$uniquewords[i] = length(unique(unlist(strsplit(final$stemmed[i], " "))))

  #add valence
  tempwords = as.data.frame(unlist(strsplit(final$stemmed[i], " ")))
  colnames(tempwords) = "theword"
  tempwords$tempval = vlookup(tempwords$theword, #index in original data
                    warriner, #where's the stuff you want to put in
                    "V.Mean.Sum", #what column is the stuff you want
                    "Word2") #what's the matching index

  final$valenceavg[i] = mean(tempwords$tempval, na.rm = T)

}


# tapply(final$valenceavg, final$Source, mean)
# tapply(final$valenceavg, final$Source, sd)
# tapply(final$wordcount, final$Source, mean)
# tapply(final$wordcount, final$Source, sd)
# tapply(final$uniquewords, final$Source, mean)
# tapply(final$uniquewords, final$Source, sd)
# tapply(final$Source, final$Source, length)
# tapply(final$wordcount, final$Source, sum)

final$FK = NA

for (i in 1:nrow(final)){
  final$FK[i] = unlist(textstat_readability(final$Text[i],
                     measure = "Flesch.Kincaid")$Flesch.Kincaid)
}

# tapply(final$FK, final$Source, mean)
# tapply(final$FK, final$Source, sd)

####build the table here####
tableprint = matrix(NA, nrow=4, ncol=11)
colnames(tableprint) = c("Source", "Mean_Valence", "SD_Valence", "Number_of_Articles", "Total_Words", "Mean_Tokens", "SD_Tokens", "Mean_Types", "SD_Types", "Mean_Readability", "SD_Readability")

#tableprint[ , 1] = unique(final$Source)
tableprint[ , 1] = c("Breitbart", "Fox News", "NPR", "New York Times")
tableprint[ , 2] = tapply(final$valenceavg, final$Source, mean)
tableprint[ , 3] = tapply(final$valenceavg, final$Source, sd)
tableprint[ , 4] = tapply(final$valenceavg, final$Source, length)
tableprint[ , 5] = tapply(final$wordcount, final$Source, sum)
tableprint[ , 6] = tapply(final$wordcount, final$Source, mean)
tableprint[ , 7] = tapply(final$wordcount, final$Source, sd)
tableprint[ , 8] = tapply(final$uniquewords, final$Source, mean)
tableprint[ , 9] = tapply(final$uniquewords, final$Source, sd)
tableprint[ , 10] = tapply(final$FK, final$Source, mean)
tableprint[ , 11] = tapply(final$FK, final$Source, sd)

tableprint[ , c(2,3,6,7,8,9,10,11)] = printnum(as.numeric(tableprint[ , c(2,3,6,7,8,9,10,11)]), big.mark = "")

tableprint = tableprint[c(3, 4, 1, 2) , ]
```

We calculated descriptive statistics for each news source in order to understand any and all fundamental linguistic differences in the sources' use of English. Statistics calculated included average *z*-scored valence of the unique words per article, number of articles per source, total number of words per source, average number of tokens (words) per article in each source, average number of types (unique words) per article in each source, and mean readability level per source. Readability statistics were calculated using the Flesch-Kincaid Grade Level Readability formula [@Kincaid1975]. Readability is calculated using a formula where the total number of syllables, words, and sentences in a given passage are determinants of its difficulty. The obtained value is intended to match up with the U.S. grade level at which one should be able to comfortably read the passage [@Kincaid1975]. For example, a text with a readability score of 11 should be easily read by a U.S. high school junior.

As seen in Table \@ref(tab:exp1-source-descriptives), the sources are similar in some aspects yet different in others. Valence appears to be slightly positive across all sources. The large standard deviations seem to indicate little to no presence of a difference in valence across sources. *NYT* published the greatest number of articles as well as total words. *Breitbart* featured the lowest number of articles, and *NPR* the lowest number of total words from all articles. Per individual article, however, *Breitbart* appears to feature the highest average number of words as well as unique words. Once again the standard deviations call into question any apparent differences between sources. Finally, *Fox News* articles had the lowest reading grade level on average, while *NYT* had the highest. This result might be attributable to the greater number of tokens in the average *NYT* article compared to *Fox News*. The standard deviations for readability suggest the presence of a diverse array of articles for each source, ranging from low to high reading level. Large standard deviations suggest the sources feature a lot of overlap between them in their representation of scores.

```{r exp1-source-descriptives, results = 'asis', echo = FALSE}
#change this to match
apa_table(as.data.frame(tableprint),
          note = "Readability statistics were calculated using the Flesch-Kincaid Grade Level readability formula. V = Valence, T = Tokens or total words, Ty = Types or unique words, FK = Flesch-Kincaid",
          caption = "Study 1 - Descriptive Statistics by Source",
          col.names = c("Source", "$M_V$", "$SD_V$", "$N_{Article}$", "$N_{Words}$", "$M_T$", "$SD_T$", "$M_{Ty}$", "$SD_{Ty}$", "$M_{FK}$", "$SD_{FK}$"),
          format = "latex",
          escape = F,
          align = c("l", rep("c", 10)),
          font_size = 'footnotesize',
          placement = "h"
          )
```

## Inferential Statistics

To analyze if news sources adhered to differences in word use based on their target audience, we utilized a multilevel model (MLM) to analyze the data. MLM is a regression technique that allows one to control for the repeated measurement and nested structured of the data, which creates correlated error [@Gelman2006]. Using the *nlme* library in *R* [@Pinheiro2017], each foundation's weighted percentage was predicated here by the political lean of the news source, using the individual news sources as a random intercept to control for the structure of the data. Therefore, the models were calculated by: Weighted Score ~ Political Lean + (~1|Source). 

The multilevel model did not indicate the presence of any significant or practical effect of political lean for any of the five moral foundations. The strongest effect size was observed for the *authority/respect* foundation, but the effect was in the opposite direction from what was originally hypothesized - liberal sources tended to use more *authority/respect* words than did conservative sources. Descriptive and test statistics, *p*-values and effect sizes (Cohen's *d*) can be found in Table \@ref(tab:exp1-table). To interpret the weighted scores, one can examine the mean and standard deviations for each. A zero score for the mean, with a non-zero standard deviation, would indicate a perfect balance of positive and negative words in each category, likely representing a neutral tone when all words are considered. Negative percentages would indicate more representation of the negative words in the MFD area, while positive percentages indicate an endorsement of the positive words in a MFD. Therefore, we suggest using the sign of the mean score to determine the directionality of the endorsement for the MFD (positive, neutral, negative), and the standard deviation to ensure that a zero score is not zero endorsement (i.e., a SD of zero indicates no words were used). Based on the weighted percent values for the five foundations, we observed that MFD words seem to make up a small portion of the article text. Furthermore, the observed percentages and means appear to indicate a generally positive endorsement of all five foundations across both liberal and conservative sources.

```{r exp1_table_calc, include = F, echo = F}
#MFD, mean, sd, mean, sd, t, p, d
tableprint2 = matrix(NA, ncol = 9, nrow = 5)
colnames(tableprint2) = c("Foundation", "M_C", "SD_C", "M_L", "SD_L", "t", "p", "d", "ICC")

#calculate d
#harm
harm_d = d.ind.t(m1 = mean(harm_final_temp$MFDweight[harm_final_temp$lean == "Conservative"], na.rm = T),
                 m2 = mean(harm_final_temp$MFDweight[harm_final_temp$lean == "Liberal"], na.rm = T),
                 sd1 = sd(harm_final_temp$MFDweight[harm_final_temp$lean == "Conservative"], na.rm = T),
                 sd2 = sd(harm_final_temp$MFDweight[harm_final_temp$lean == "Liberal"], na.rm = T),
                 n1 = length(harm_final_temp$MFDweight[harm_final_temp$lean == "Conservative"]),
                 n2 = length(harm_final_temp$MFDweight[harm_final_temp$lean == "Liberal"]),
                 a = .05)

#fair
fair_d = d.ind.t(m1 = mean(fair_final_temp$MFDweight[fair_final_temp$lean == "Conservative"], na.rm = T),
                 m2 = mean(fair_final_temp$MFDweight[fair_final_temp$lean == "Liberal"], na.rm = T),
                 sd1 = sd(fair_final_temp$MFDweight[fair_final_temp$lean == "Conservative"], na.rm = T),
                 sd2 = sd(fair_final_temp$MFDweight[fair_final_temp$lean == "Liberal"], na.rm = T),
                 n1 = length(fair_final_temp$MFDweight[fair_final_temp$lean == "Conservative"]),
                 n2 = length(fair_final_temp$MFDweight[fair_final_temp$lean == "Liberal"]),
                 a = .05)

#ingroup
ingroup_d = d.ind.t(m1 = mean(ingroup_final_temp$MFDweight[ingroup_final_temp$lean == "Conservative"], na.rm = T),
                 m2 = mean(ingroup_final_temp$MFDweight[ingroup_final_temp$lean == "Liberal"], na.rm = T),
                 sd1 = sd(ingroup_final_temp$MFDweight[ingroup_final_temp$lean == "Conservative"], na.rm = T),
                 sd2 = sd(ingroup_final_temp$MFDweight[ingroup_final_temp$lean == "Liberal"], na.rm = T),
                 n1 = length(ingroup_final_temp$MFDweight[ingroup_final_temp$lean == "Conservative"]),
                 n2 = length(ingroup_final_temp$MFDweight[ingroup_final_temp$lean == "Liberal"]),
                 a = .05)

#authority
authority_d = d.ind.t(m1 = mean(authority_final_temp$MFDweight[authority_final_temp$lean == "Conservative"], na.rm = T),
                 m2 = mean(authority_final_temp$MFDweight[authority_final_temp$lean == "Liberal"], na.rm = T),
                 sd1 = sd(authority_final_temp$MFDweight[authority_final_temp$lean == "Conservative"], na.rm = T),
                 sd2 = sd(authority_final_temp$MFDweight[authority_final_temp$lean == "Liberal"], na.rm = T),
                 n1 = length(authority_final_temp$MFDweight[authority_final_temp$lean == "Conservative"]),
                 n2 = length(authority_final_temp$MFDweight[authority_final_temp$lean == "Liberal"]),
                 a = .05)

#purity
purity_d = d.ind.t(m1 = mean(purity_final_temp$MFDweight[purity_final_temp$lean == "Conservative"], na.rm = T),
                 m2 = mean(purity_final_temp$MFDweight[purity_final_temp$lean == "Liberal"], na.rm = T),
                 sd1 = sd(purity_final_temp$MFDweight[purity_final_temp$lean == "Conservative"], na.rm = T),
                 sd2 = sd(purity_final_temp$MFDweight[purity_final_temp$lean == "Liberal"], na.rm = T),
                 n1 = length(purity_final_temp$MFDweight[purity_final_temp$lean == "Conservative"]),
                 n2 = length(purity_final_temp$MFDweight[purity_final_temp$lean == "Liberal"]),
                 a = .05)

#put in the numbers
tableprint2[1, ] = c("Harm/Care", harm_d$M1, harm_d$sd1, harm_d$M2, harm_d$sd1,
                    summary(harm_model)$tTable[2,4], summary(harm_model)$tTable[2,5],
                    harm_d$d, icc(harm_icc)$ICC_unadjusted)
tableprint2[2, ] = c("Fairness/Reciprocity", fair_d$M1, fair_d$sd1, fair_d$M2, fair_d$sd1,
                    summary(fair_model)$tTable[2,4], summary(fair_model)$tTable[2,5],
                    fair_d$d, icc(fair_icc)$ICC_unadjusted)
tableprint2[3, ] = c("Ingroup/Loyalty", ingroup_d$M1, ingroup_d$sd1, ingroup_d$M2, ingroup_d$sd1,
                    summary(ingroup_model)$tTable[2,4], summary(ingroup_model)$tTable[2,5],
                    ingroup_d$d, icc(ingroup_icc)$ICC_unadjusted)
tableprint2[4, ] = c("Authority/Respect", authority_d$M1, authority_d$sd1, authority_d$M2, authority_d$sd1,
                    summary(authority_model)$tTable[2,4], summary(authority_model)$tTable[2,5],
                    authority_d$d, icc(authority_icc)$ICC_unadjusted)
tableprint2[5, ] = c("Purity/Sanctity", purity_d$M1, purity_d$sd1, purity_d$M2, purity_d$sd1,
                    summary(purity_model)$tTable[2,4], summary(purity_model)$tTable[2,5],
                    purity_d$d, icc(purity_icc)$ICC_unadjusted)

tableprint2[ , c(2:6, 8)] = printnum(as.numeric(tableprint2[ , c(2:6, 8)]), big.mark = "")
tableprint2[ , 7] = printp(as.numeric(tableprint2[ , 7]))
tableprint2[ , 9] = printp(as.numeric(tableprint2[ , 7]))
```

```{r exp1-table, results = 'asis', echo = F}
apa_table(as.data.frame(tableprint2),
          note = "For mean and standard deviation values, 'C' and 'L' refer to 'conservative' and 'liberal,' respectively",
          caption = "Study 1 Results - Multilevel Model",
          col.names = c("Foundation", "$M_C$", "$SD_C$", "$M_L$", "$SD_L$", "$t$", "$p$", "$d$", "ICC"),
          format = "latex",
          escape = F,
          align = c("l", rep("c", 7)),
          font_size = 'footnotesize',
          placement = "h"
          )
```

```{r conference-pic, eval = F, include = F}
cleanup = theme(panel.grid.major = element_blank(),
                panel.grid.minor = element_blank(),
                panel.background = element_blank(),
                axis.line.x = element_line(color = "black"),
                axis.line.y = element_line(color = "black"),
                legend.key = element_rect(fill = "white"),
                text = element_text(size = 10))

graphdata = as.data.frame(tableprint)
graphlong = melt(graphdata[ , c(1,2,4)],
                 id = "Foundation")
graphlong2 = melt(graphdata[ , c(1, 3,5)],
                  id = "Foundation",
                  measured = c("SD_C", "SD_L"))
graphlong$sd = graphlong2$value
graphlong$lower = as.numeric(as.character(graphlong$value)) - 2*as.numeric(as.character(graphlong$sd))
graphlong$upper = as.numeric(as.character(graphlong$value)) + 2*as.numeric(as.character(graphlong$sd))

graphlong$value = as.numeric(as.character(graphlong$value))

graph_data = ggplot(graphlong, aes(Foundation, value, color = variable)) +
  geom_point(position = position_dodge(width = 0.90)) +
  geom_errorbar(aes(ymin = lower, ymax = upper),
                position = position_dodge(width = 0.90),
                width = .2) +
  cleanup +
  ylab("Mean Weighted Valence") +
  scale_color_manual(values = c("red", "blue"),
                       labels = c("Conservative", "Liberal"),
                       name = "Party") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  geom_hline(yintercept = 0, linetype = 1, color = "black")

tiff(filename = "exp1_graph.tiff", res = 300, width = 4,
     height = 3, units = 'in', compression = "lzw")
plot(graph_data)
dev.off()

```

# Discussion

The results obtained in Study 1 fail to support the differences predicted by MFT. First, differences between liberal and conservative news sources failed to reach statistical or practical (effect size) significance for any foundations. Second, looking purely at the direction of the differences, the results run completely contrary to the differences expected by MFT. Conservative sources scored higher on concern for harm and fairness while liberal sources scored higher on concern for loyalty, authority, and purity. Overall, the results lend strong support to the case against the MFD and weakens the case generally for MFT.

However, one possible limitation of the current data is the generalness of the corpus. The selection of the broad and amorphous topic of "political news" may have led to the scraping of large numbers of articles with little to no moral-centric content. To address this limitation, two changes that were subsequently employed in Study 2. First, we elected to include more news sources for web scraping and analysis in addition to the four used in Study 1. Second, we chose to focus  data collection efforts on two heavily moralized events in the Trump administration: (1) the nomination and confirmation of Justice Brett Kavanaugh to the U.S. Supreme Court and the U.S. government shutdown in December 2018 through January 2019 over disagreements about funding a U.S.-Mexico border wall. Hence, Study 2 is the best test of the MFT and the MFD in the context of partisan news.

# Study 2

# Method

In contrast to Study 1, we approached Study 2 with the intention to confirm the method employed was valid for the analysis of the scraped text as well as for any inferences drawn from the analyses. For the second study, we hypothesized that news sources perceived as liberal will exhibit positive endorsements of the individualizing moral foundations (*harm/care* and *fairness/reciprocity*) in their articles reporting on both the Kavanaugh confirmation hearing as well as the 2018-2019 government shutdown. News sources perceived as conservative are hypothesized to positively endorse all five foundations equally in their coverage of the Kavanaugh hearing and the government shutdown. We tested the hypothesis by analyzing the content scraped from news sources' web pages spanning the two weeks before (September 13, 2018) and two weeks after (October 11, 2018) Kavanaugh's confirmation hearing, owing to its prominence in the news. Likewise, we analyzed content spanning two weeks before the start of the government shutdown (December 8, 2018) to two weeks following the end of the shutdown (February 8, 2019). The content will be analyzed for valence and moral alignment under MFT.

```{r include = F, echo = F}
# please see the web_scraping.Rmd to see how we originally collected this data
```

## Sources

Articles pertaining to the Brett Kavanaugh Supreme Court confirmation hearing and the 2018-2019 U.S. Government shutdown were scraped from the websites of 10 U.S. news sources. As in Study 1, these sources were selected owing to their favorability among political partisans according to @Mitchell2014. The sources favored by the highest proportion of consistent liberals were the *NYT*, *NPR*, *Slate*, *Huffington Post*, and *Politico* [@Mitchell2014]. The sources favored by the highest proportion of consistent conservatives included *Fox News*, *Breitbart*, *The Rush Limbaugh Show*, *The Blaze*, and *Sean Hannity*. These sources were primarily selected due to their political lean but also due to our ability to webscrape their contents without a subscription based service. Political articles referencing Brett Kavanaugh's nomination process were identified and subsequently scraped by including the URL for each source's coverage of the nomination in the *R* script.

## Materials

Using the *rvest* and *RSelenium* libraries, we pulled body text for individual articles from each of the aforementioned 10 news sources and compiled them together [@Wickham2016; @harrison_rselenium_2020]. Using this dataset, we identified word count and average word count per source. This process was run for articles pertaining to Kavanaugh's nomination that were published between September 13, 2018 and October 11, 2018 inclusive. This date range was selected in reference to the widely-publicized and viewed nomination hearing on September 27, 2018. We set the start date at September 13 (two weeks before the hearing) and the end date at October 11 (two weeks after the hearing) so that we could capture a large amount of data (roughly one month) during which Kavanaugh's nomination was at its peak saturation in news coverage.

The same process was followed for scraping articles related to the partial U.S. Government shutdown of 2018-2019. The articles scraped were published between December 8, 2018 and February 8, 2019 inclusive. Once again, we elected to scrape articles published two weeks before and after the event in question in order to capitalize on the shutdown's saturation in American news media.

```{r data_clean_kav, eval = T, echo = F}
##combine all kav data into one dataset
#read it in
NYtimes_kav = read.csv("./exp2_data/NYtimes_kav.csv", stringsAsFactors = F, fileEncoding="UTF-8") #ok
NPR_kav = read.csv("./exp2_data/NPR_kav.csv", stringsAsFactors = F, fileEncoding="UTF-8") #ok
SLATE_kav = read.csv("./exp2_data/SLATE_kav.csv", stringsAsFactors = F, fileEncoding="UTF-8") #ok
HUFFPO_kav = read.csv("./exp2_data/HUFFPO_kav.csv", stringsAsFactors = F, fileEncoding="UTF-8") #ok
POLITICO_kav = read.csv("./exp2_data/POLITICO_kav.csv", stringsAsFactors = F, fileEncoding="UTF-8") #ok
FOX_kav = read.csv("./exp2_data/FOX_kav.csv", stringsAsFactors = F) #ok
BREITBART_kav = read.csv("./exp2_data/BREITBART_kav.csv", stringsAsFactors = F) #ok
RUSH_kav = read.csv("./exp2_data/RUSH_kav.csv", stringsAsFactors = F, fileEncoding="UTF-8") #ok
BLAZE_kav = read.csv("./exp2_data/BLAZE_kav.csv", stringsAsFactors = F, fileEncoding="UTF-8") #ok
HANNITY_kav = read.csv("./exp2_data/HANNITY_kav.csv", stringsAsFactors = F, fileEncoding="UTF-8") #ok


#merge it together
master_kav = rbind(NYtimes_kav, NPR_kav, SLATE_kav,
                        HUFFPO_kav, POLITICO_kav, FOX_kav,
                        BREITBART_kav, RUSH_kav, BLAZE_kav,
                        HANNITY_kav)

#fix this issue
master_kav$Text = gsub("\\.", "\\. ", master_kav$Text)

##get rid of the blank stuff
library(ngram)

for (i in 1:nrow(master_kav)) {
  master_kav$wordcount[i] = wordcount(master_kav$Text[i])
}

nozero = subset(master_kav, wordcount > 0)
nozero = subset(nozero, Source == "NY Times" | Source == "BLAZE" | Source == "NPR" | Source == "HUFFPO" | Source == "FOX" | Source == "HANNITY" | Source == "SLATE" | Source == "POLITICO" | Source == "RUSH" | Source == "BREITBART")
# tapply(nozero$wordcount, nozero$Source, mean)
# tapply(nozero$wordcount, nozero$Source, sum)

##take out the disqus ones - there are none
#nodis = nozero[ -c(grep("disqus", nozero$Url)), ]

##all data
final_kav = nozero
```

```{r data_clean_gs, eval = T, echo = F}
##combine all gs data into one dataset
#read it in
NYtimes_gs = read.csv("./exp2_data/NYtimes_gs.csv", stringsAsFactors = F, fileEncoding = "UTF-8") #ok
NPR_gs = read.csv("./exp2_data/NPR_gs.csv", stringsAsFactors = F) #ok
SLATE_gs = read.csv("./exp2_data/SLATE_gs.csv", stringsAsFactors = F) #ok
HUFFPO_gs = read.csv("./exp2_data/HUFFPO_gs.csv", stringsAsFactors = F) #ok
POLITICO_gs = read.csv("./exp2_data/POLITICO_gs.csv", stringsAsFactors = F, fileEncoding = "UTF-8") #not ok
FOX_gs = read.csv("./exp2_data/FOX_gs.csv", stringsAsFactors = F) #ok
BREITBART_gs = read.csv("./exp2_data/BREITBART_gs.csv", stringsAsFactors = F) #ok
RUSH_gs = read.csv("./exp2_data/RUSH_gs.csv", stringsAsFactors = F, fileEncoding = "UTF-8") #not ok
BLAZE_gs = read.csv("./exp2_data/BLAZE_gs.csv", stringsAsFactors = F) #ok
HANNITY_gs = read.csv("./exp2_data/HANNITY_gs.csv", stringsAsFactors = F) #ok

#merge it together
master_gs = rbind(NYtimes_gs, NPR_gs, SLATE_gs,
                        HUFFPO_gs, POLITICO_gs, FOX_gs,
                        BREITBART_gs, RUSH_gs, BLAZE_gs,
                        HANNITY_gs)

#fix this issue
master_gs$Text = gsub("\\.", "\\. ", master_gs$Text)

for (i in 1:nrow(master_gs)) {
  master_gs$wordcount[i] = wordcount(master_gs$Text[i])
}

nozero = subset(master_gs, wordcount > 0)
nozero = subset(nozero, Source == "NY Times" | Source == "BLAZE" | Source == "NPR" | Source == "HUFFPO" | Source == "FOX" | Source == "HANNITY" | Source == "SLATE" | Source == "POLITICO" | Source == "RUSH" | Source == "BREITBART")

# tapply(nozero$wordcount, nozero$Source, mean)
# tapply(nozero$wordcount, nozero$Source, sum)

##take out the disqus ones
#nodis = nozero[ -c(grep("disqus", nozero$Url)), ]

##all data
final_gs = nozero
```

```{r stem_text_both, eval = T, echo = F}
#process the Text column (write a loop) - save processed text as a separate column
for(i in 1:nrow(final_kav)) {

  final_kav$edited[i] = preprocess(final_kav$Text[i], #one value at a time
           case = "lower",
           remove.punct = TRUE,
           remove.numbers = FALSE,
           fix.spacing = TRUE)

##stem the words - do this second in the loop
  final_kav$stemmed[i] = stemDocument(final_kav$edited[i], language = "english")
}

#process the Text column (write a loop) - save processed text as a separate column
for(i in 1:nrow(final_gs)) {

  final_gs$edited[i] = preprocess(final_gs$Text[i], #one value at a time
           case = "lower",
           remove.punct = TRUE,
           remove.numbers = FALSE,
           fix.spacing = TRUE)

##stem the words - do this second in the loop
  final_gs$stemmed[i] = stemDocument(final_gs$edited[i], language = "english")
}

```

## Data analysis

As in Study 1, the text was scanned with *ngram* [@Schmidt2017]. Again, blank articles, text from the Disqus system, and duplicate articles were removed. The text was processed and stemmed in order to convert to a usable form for further analysis [@Feinerer2017]. Each individual word was reduced to its stem (i.e., *diseased* was stemmed to *diseas*). Once again, the same procedure was applied to the MFD words and the words in the @Warriner2013 dataset. We obtained the words' percent occurrence in the text. Percents were multiplied by *z*-scored valence and categorized into their proper MFD category.

```{r create_datasets_harm_kav, eval = T, echo = F, include = F}
#read in the harm total words from the mtmm project
harm_all_kav = read.csv("./exp1_data/harm_words_total.csv", stringsAsFactors = F)

harm_final_data_kav = data.frame("URL" = NA, "Source" = NA, "Var1" = NA, "Freq" = NA, "wordcount" = NA)

for (i in 1:nrow(final_kav)) {
##first make a table of a response, unlisting everything
temp = as.data.frame(table(unlist(strsplit(final_kav$stemmed[i], " "))))

#only pull the words in the dataset for each foundation
temp2 = temp[temp$Var1 %in% unique(harm_all_kav$words[harm_all_kav$words != "" & harm_all_kav$words != "NA" & !is.na(harm_all_kav$words)]), ]

#control here for times when no words
if (nrow(temp2) == 0){
  temp2 = data.frame("Var1" = 0, "Freq" = 0)
}

#add to the dataset
temp2$URL = final_kav$Url[i]
temp2$Source = final_kav$Source[i]
temp2$wordcount = final_kav$wordcount[i]

#bind with original
harm_final_data_kav = rbind(harm_final_data_kav, temp2)
}

#pull in the data from Warriner
harm_final_data_kav$valence = vlookup(harm_final_data_kav$Var1, #index in original data
                                  warriner, #where's the stuff you want to put in
                                  "V.Mean.Sum", #what column is the stuff you want
                                  "Word2") #what's the matching index

#figure out stupid words
#table(harm_final_data_kav$Var1[is.na(harm_final_data_kav$valence) & harm_final_data_kav$Freq > 0])
#fought, safer, spurn
harm_final_data_kav$valence[harm_final_data_kav$Var1 == "fought"] = warriner$V.Mean.Sum[warriner$Word2 == "fight"]
harm_final_data_kav$valence[harm_final_data_kav$Var1 == "safer"] = warriner$V.Mean.Sum[warriner$Word2 == "safe"]
#no spurn avaliable
```

```{r create_datasets_fair_kav, include=FALSE}
fair_all_kav = read.csv("./exp1_data/fair_words_total.csv", stringsAsFactors = F)

fair_final_data_kav = data.frame("URL" = NA, "Source" = NA, "Var1" = NA, "Freq" = NA, "wordcount" = NA)

for (i in 1:nrow(final_kav)) {
##first make a table of a response, unlisting everything
temp = as.data.frame(table(unlist(strsplit(final_kav$stemmed[i], " "))))

#only pull the words in the dataset for each foundation
temp2 = temp[temp$Var1 %in% unique(fair_all_kav$words[fair_all_kav$words != "" & fair_all_kav$words != "NA" & !is.na(fair_all_kav$words)]), ]

#control here for times when no words
if (nrow(temp2) == 0){
  temp2 = data.frame("Var1" = 0, "Freq" = 0)
}

#add to the dataset
temp2$URL = final_kav$Url[i]
temp2$Source = final_kav$Source[i]
temp2$wordcount = final_kav$wordcount[i]

#bind with original
fair_final_data_kav = rbind(fair_final_data_kav, temp2)
}

fair_final_data_kav$valence = vlookup(fair_final_data_kav$Var1, #index in original data
                                  warriner, #where's the stuff you want to put in
                                  "V.Mean.Sum", #what column is the stuff you want
                                  "Word2") #what's the matching index

#figure out stupid words
table(fair_final_data_kav$Var1[is.na(fair_final_data_kav$valence) & fair_final_data_kav$Freq > 0])
#just plagiar safer
fair_final_data_kav$valence[fair_final_data_kav$Var1 == "safer"] = warriner$V.Mean.Sum[warriner$Word2 == "safe"]
#nothing for just or plagiarism
```

```{r create_datasets_ingroup_kav, include=FALSE}
ingroup_all_kav = read.csv("./exp1_data/ingroup_words_total.csv", stringsAsFactors = F)

ingroup_final_data_kav = data.frame("URL" = NA, "Source" = NA, "Var1" = NA, "Freq" = NA, "wordcount" = NA)

for (i in 1:nrow(final_kav)) {
##first make a table of a response, unlisting everything
temp = as.data.frame(table(unlist(strsplit(final_kav$stemmed[i], " "))))

#only pull the words in the dataset for each foundation
temp2 = temp[temp$Var1 %in% unique(ingroup_all_kav$words[ingroup_all_kav$words != "" & ingroup_all_kav$words != "NA" & !is.na(ingroup_all_kav$words)]), ]

#control here for times when no words
if (nrow(temp2) == 0){
  temp2 = data.frame("Var1" = 0, "Freq" = 0)
}

#add to the dataset
temp2$URL = final_kav$Url[i]
temp2$Source = final_kav$Source[i]
temp2$wordcount = final_kav$wordcount[i]

#bind with original
ingroup_final_data_kav = rbind(ingroup_final_data_kav, temp2)
}

ingroup_final_data_kav$valence = vlookup(ingroup_final_data_kav$Var1, #index in original data
                                  warriner, #where's the stuff you want to put in
                                  "V.Mean.Sum", #what column is the stuff you want
                                  "Word2") #what's the matching index

#figure out stupid words
table(ingroup_final_data_kav$Var1[is.na(ingroup_final_data_kav$valence) & ingroup_final_data_kav$Freq > 0])
#backstabb  benedict      best      fals   indvidu      juda    knight      true
ingroup_final_data_kav$valence[ingroup_final_data_kav$Var1 == "fals"] = warriner$V.Mean.Sum[warriner$Word2 == "FALSE"]
ingroup_final_data_kav$valence[ingroup_final_data_kav$Var1 == "indvidu"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "individu"])
ingroup_final_data_kav$valence[ingroup_final_data_kav$Var1 == "true"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "TRUE"])
```

```{r create_datasets_authority_kav, include=FALSE}
authority_all_kav = read.csv("./exp1_data/authority_words_total.csv", stringsAsFactors = F)

authority_final_data_kav = data.frame("URL" = NA, "Source" = NA, "Var1" = NA, "Freq" = NA, "wordcount" = NA)

for (i in 1:nrow(final_kav)) {
##first make a table of a response, unlisting everything
temp = as.data.frame(table(unlist(strsplit(final_kav$stemmed[i], " "))))

#only pull the words in the dataset for each foundation
temp2 = temp[temp$Var1 %in% unique(authority_all_kav$words[authority_all_kav$words != "" & authority_all_kav$words != "NA" & !is.na(authority_all_kav$words)]), ]

#control here for times when no words
if (nrow(temp2) == 0){
  temp2 = data.frame("Var1" = 0, "Freq" = 0)
}

#add to the dataset
temp2$URL = final_kav$Url[i]
temp2$Source = final_kav$Source[i]
temp2$wordcount = final_kav$wordcount[i]

#bind with original
authority_final_data_kav = rbind(authority_final_data_kav, temp2)
}

authority_final_data_kav$valence = vlookup(authority_final_data_kav$Var1, #index in original data
                                  warriner, #where's the stuff you want to put in
                                  "V.Mean.Sum", #what column is the stuff you want
                                  "Word2") #what's the matching index

#figure out stupid words
table(authority_final_data_kav$Var1[is.na(authority_final_data_kav$valence) & authority_final_data_kav$Freq > 0])
#  abov behind   gase higher  older  taken
authority_final_data_kav$valence[authority_final_data_kav$Var1 == "gase"] = warriner$V.Mean.Sum[warriner$Word2 == "gas"]
authority_final_data_kav$valence[authority_final_data_kav$Var1 == "higher"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "high"])
authority_final_data_kav$valence[authority_final_data_kav$Var1 == "older"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "old"])
authority_final_data_kav$valence[authority_final_data_kav$Var1 == "taken"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "take"])
```

```{r create_datasets_purity_kav, include=FALSE}
purity_all_kav = read.csv("./exp1_data/purity_words_total.csv", stringsAsFactors = F)

purity_final_data_kav = data.frame("URL" = NA, "Source" = NA, "Var1" = NA, "Freq" = NA, "wordcount" = NA)

for (i in 1:nrow(final_kav)) {
##first make a table of a response, unlisting everything
temp = as.data.frame(table(unlist(strsplit(final_kav$stemmed[i], " "))))

#only pull the words in the dataset for each foundation
temp2 = temp[temp$Var1 %in% unique(purity_all_kav$words[purity_all_kav$words != "" & purity_all_kav$words != "NA" & !is.na(purity_all_kav$words)]), ]

#control here for times when no words
if (nrow(temp2) == 0){
  temp2 = data.frame("Var1" = 0, "Freq" = 0)
}

#add to the dataset
temp2$URL = final_kav$Url[i]
temp2$Source = final_kav$Source[i]
temp2$wordcount = final_kav$wordcount[i]

#bind with original
purity_final_data_kav = rbind(purity_final_data_kav, temp2)
}

purity_final_data_kav$valence = vlookup(purity_final_data_kav$Var1, #index in original data
                                  warriner, #where's the stuff you want to put in
                                  "V.Mean.Sum", #what column is the stuff you want
                                  "Word2") #what's the matching index

#figure out stupid words
table(purity_final_data_kav$Var1[is.na(purity_final_data_kav$valence) & purity_final_data_kav$Freq > 0])
#befor christian     jesus      mari      none    sacred    someon      true     women
purity_final_data_kav$valence[purity_final_data_kav$Var1 == "sacred"] = warriner$V.Mean.Sum[warriner$Word2 == "sacr"]
purity_final_data_kav$valence[purity_final_data_kav$Var1 == "true"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "TRUE"])
purity_final_data_kav$valence[purity_final_data_kav$Var1 == "women"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "woman"])
```

```{r create_datasets_harm_gs, eval = T, echo = F, include = F}
#read in the harm total words from the mtmm project
harm_all_gs = read.csv("./exp1_data/harm_words_total.csv", stringsAsFactors = F)

harm_final_data_gs = data.frame("URL" = NA, "Source" = NA, "Var1" = NA, "Freq" = NA, "wordcount" = NA)

for (i in 1:nrow(final_gs)) {
##first make a table of a response, unlisting everything
temp = as.data.frame(table(unlist(strsplit(final_gs$stemmed[i], " "))))

#only pull the words in the dataset for each foundation
temp2 = temp[temp$Var1 %in% unique(harm_all_gs$words[harm_all_gs$words != "" & harm_all_gs$words != "NA" & !is.na(harm_all_gs$words)]), ]

#control here for times when no words
if (nrow(temp2) == 0){
  temp2 = data.frame("Var1" = 0, "Freq" = 0)
}

#add to the dataset
temp2$URL = final_gs$Url[i]
temp2$Source = final_gs$Source[i]
temp2$wordcount = final_gs$wordcount[i]

#bind with original
harm_final_data_gs = rbind(harm_final_data_gs, temp2)
}

#pull in the data from Warriner
harm_final_data_gs$valence = vlookup(harm_final_data_gs$Var1, #index in original data
                                  warriner, #where's the stuff you want to put in
                                  "V.Mean.Sum", #what column is the stuff you want
                                  "Word2") #what's the matching index

#figure out stupid words
#table(harm_final_data_gs$Var1[is.na(harm_final_data_gs$valence) & harm_final_data_gs$Freq > 0])
#fought, safer, spurn
harm_final_data_gs$valence[harm_final_data_gs$Var1 == "fought"] = warriner$V.Mean.Sum[warriner$Word2 == "fight"]
harm_final_data_gs$valence[harm_final_data_gs$Var1 == "safer"] = warriner$V.Mean.Sum[warriner$Word2 == "safe"]
#no spurn avaliable
```

```{r create_datasets_fair_gs, echo = F, include=FALSE}
fair_all_gs = read.csv("./exp1_data/fair_words_total.csv", stringsAsFactors = F)

fair_final_data_gs = data.frame("URL" = NA, "Source" = NA, "Var1" = NA, "Freq" = NA, "wordcount" = NA)

for (i in 1:nrow(final_gs)) {
##first make a table of a response, unlisting everything
temp = as.data.frame(table(unlist(strsplit(final_gs$stemmed[i], " "))))

#only pull the words in the dataset for each foundation
temp2 = temp[temp$Var1 %in% unique(fair_all_gs$words[fair_all_gs$words != "" & fair_all_gs$words != "NA" & !is.na(fair_all_gs$words)]), ]

#control here for times when no words
if (nrow(temp2) == 0){
  temp2 = data.frame("Var1" = 0, "Freq" = 0)
}

#add to the dataset
temp2$URL = final_gs$Url[i]
temp2$Source = final_gs$Source[i]
temp2$wordcount = final_gs$wordcount[i]

#bind with original
fair_final_data_gs = rbind(fair_final_data_gs, temp2)
}

fair_final_data_gs$valence = vlookup(fair_final_data_gs$Var1, #index in original data
                                  warriner, #where's the stuff you want to put in
                                  "V.Mean.Sum", #what column is the stuff you want
                                  "Word2") #what's the matching index

#figure out stupid words
table(fair_final_data_gs$Var1[is.na(fair_final_data_gs$valence) & fair_final_data_gs$Freq > 0])
#just plagiar safer
fair_final_data_gs$valence[fair_final_data_gs$Var1 == "safer"] = warriner$V.Mean.Sum[warriner$Word2 == "safe"]
#nothing for just or plagiarism
```

```{r create_datasets_ingroup_gs, echo = F, include=FALSE}
ingroup_all_gs = read.csv("./exp1_data/ingroup_words_total.csv", stringsAsFactors = F)

ingroup_final_data_gs = data.frame("URL" = NA, "Source" = NA, "Var1" = NA, "Freq" = NA, "wordcount" = NA)

for (i in 1:nrow(final_gs)) {
##first make a table of a response, unlisting everything
temp = as.data.frame(table(unlist(strsplit(final_gs$stemmed[i], " "))))

#only pull the words in the dataset for each foundation
temp2 = temp[temp$Var1 %in% unique(ingroup_all_gs$words[ingroup_all_gs$words != "" & ingroup_all_gs$words != "NA" & !is.na(ingroup_all_gs$words)]), ]

#control here for times when no words
if (nrow(temp2) == 0){
  temp2 = data.frame("Var1" = 0, "Freq" = 0)
}

#add to the dataset
temp2$URL = final_gs$Url[i]
temp2$Source = final_gs$Source[i]
temp2$wordcount = final_gs$wordcount[i]

#bind with original
ingroup_final_data_gs = rbind(ingroup_final_data_gs, temp2)
}

ingroup_final_data_gs$valence = vlookup(ingroup_final_data_gs$Var1, #index in original data
                                  warriner, #where's the stuff you want to put in
                                  "V.Mean.Sum", #what column is the stuff you want
                                  "Word2") #what's the matching index

#figure out stupid words
table(ingroup_final_data_gs$Var1[is.na(ingroup_final_data_gs$valence) & ingroup_final_data_gs$Freq > 0])
#backstabb  benedict      best      fals   indvidu      juda    knight      true
ingroup_final_data_gs$valence[ingroup_final_data_gs$Var1 == "fals"] = warriner$V.Mean.Sum[warriner$Word2 == "FALSE"]
ingroup_final_data_gs$valence[ingroup_final_data_gs$Var1 == "indvidu"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "individu"])
ingroup_final_data_gs$valence[ingroup_final_data_gs$Var1 == "true"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "TRUE"])
```

```{r create_datasets_authority_gs, echo = F, include=FALSE}
authority_all_gs = read.csv("./exp1_data/authority_words_total.csv", stringsAsFactors = F)

authority_final_data_gs = data.frame("URL" = NA, "Source" = NA, "Var1" = NA, "Freq" = NA, "wordcount" = NA)

for (i in 1:nrow(final_gs)) {
##first make a table of a response, unlisting everything
temp = as.data.frame(table(unlist(strsplit(final_gs$stemmed[i], " "))))

#only pull the words in the dataset for each foundation
temp2 = temp[temp$Var1 %in% unique(authority_all_gs$words[authority_all_gs$words != "" & authority_all_gs$words != "NA" & !is.na(authority_all_gs$words)]), ]

#control here for times when no words
if (nrow(temp2) == 0){
  temp2 = data.frame("Var1" = 0, "Freq" = 0)
}

#add to the dataset
temp2$URL = final_gs$Url[i]
temp2$Source = final_gs$Source[i]
temp2$wordcount = final_gs$wordcount[i]

#bind with original
authority_final_data_gs = rbind(authority_final_data_gs, temp2)
}

authority_final_data_gs$valence = vlookup(authority_final_data_gs$Var1, #index in original data
                                  warriner, #where's the stuff you want to put in
                                  "V.Mean.Sum", #what column is the stuff you want
                                  "Word2") #what's the matching index

#figure out stupid words
table(authority_final_data_gs$Var1[is.na(authority_final_data_gs$valence) & authority_final_data_gs$Freq > 0])
#  abov behind   gase higher  older  taken
authority_final_data_gs$valence[authority_final_data_gs$Var1 == "gase"] = warriner$V.Mean.Sum[warriner$Word2 == "gas"]
authority_final_data_gs$valence[authority_final_data_gs$Var1 == "higher"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "high"])
authority_final_data_gs$valence[authority_final_data_gs$Var1 == "older"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "old"])
authority_final_data_gs$valence[authority_final_data_gs$Var1 == "taken"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "take"])
```

```{r create_datasets_purity_gs, echo = F, include=FALSE}
purity_all_gs = read.csv("./exp1_data/purity_words_total.csv", stringsAsFactors = F)

purity_final_data_gs = data.frame("URL" = NA, "Source" = NA, "Var1" = NA, "Freq" = NA, "wordcount" = NA)

for (i in 1:nrow(final_gs)) {
##first make a table of a response, unlisting everything
temp = as.data.frame(table(unlist(strsplit(final_gs$stemmed[i], " "))))

#only pull the words in the dataset for each foundation
temp2 = temp[temp$Var1 %in% unique(purity_all_gs$words[purity_all_gs$words != "" & purity_all_gs$words != "NA" & !is.na(purity_all_gs$words)]), ]

#control here for times when no words
if (nrow(temp2) == 0){
  temp2 = data.frame("Var1" = 0, "Freq" = 0)
}

#add to the dataset
temp2$URL = final_gs$Url[i]
temp2$Source = final_gs$Source[i]
temp2$wordcount = final_gs$wordcount[i]

#bind with original
purity_final_data_gs = rbind(purity_final_data_gs, temp2)
}

purity_final_data_gs$valence = vlookup(purity_final_data_gs$Var1, #index in original data
                                  warriner, #where's the stuff you want to put in
                                  "V.Mean.Sum", #what column is the stuff you want
                                  "Word2") #what's the matching index

#figure out stupid words
table(purity_final_data_gs$Var1[is.na(purity_final_data_gs$valence) & purity_final_data_gs$Freq > 0])
#befor christian     jesus      mari      none    sacred    someon      true     women
purity_final_data_gs$valence[purity_final_data_gs$Var1 == "sacred"] = warriner$V.Mean.Sum[warriner$Word2 == "sacr"]
purity_final_data_gs$valence[purity_final_data_gs$Var1 == "true"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "TRUE"])
purity_final_data_gs$valence[purity_final_data_gs$Var1 == "women"] = mean(warriner$V.Mean.Sum[warriner$Word2 == "woman"])
```

```{r descriptives_both, echo = F, include = FALSE}
##summarize the dataset so that you have the total and percent for each foundation
#kav
summary(harm_final_data_kav)
summary(fair_final_data_kav)
summary(ingroup_final_data_kav)
summary(authority_final_data_kav)
summary(purity_final_data_kav)
#gs
summary(harm_final_data_gs)
summary(fair_final_data_gs)
summary(ingroup_final_data_gs)
summary(authority_final_data_gs)
summary(purity_final_data_gs)
##report descriptive statistics of the foundations
#kav
mean(harm_final_data_kav$valence, na.rm = T)
sd(harm_final_data_kav$valence, na.rm = T)
mean(fair_final_data_kav$valence, na.rm = T)
sd(fair_final_data_kav$valence, na.rm = T)
mean(ingroup_final_data_kav$valence, na.rm = T)
sd(ingroup_final_data_kav$valence, na.rm = T)
mean(authority_final_data_kav$valence, na.rm = T)
sd(authority_final_data_kav$valence, na.rm = T)
mean(purity_final_data_kav$valence, na.rm = T)
sd(purity_final_data_kav$valence, na.rm = T)
#gs
mean(harm_final_data_gs$valence, na.rm = T)
sd(harm_final_data_gs$valence, na.rm = T)
mean(fair_final_data_gs$valence, na.rm = T)
sd(fair_final_data_gs$valence, na.rm = T)
mean(ingroup_final_data_gs$valence, na.rm = T)
sd(ingroup_final_data_gs$valence, na.rm = T)
mean(authority_final_data_gs$valence, na.rm = T)
sd(authority_final_data_gs$valence, na.rm = T)
mean(purity_final_data_gs$valence, na.rm = T)
sd(purity_final_data_gs$valence, na.rm = T)
#note that a big problem is the valence of the words
```

```{r analysis_harm_kav, include = FALSE}
#final_data clean up
#multiply by frequency and create percentage
harm_final_data_kav$weight = harm_final_data_kav$Freq * harm_final_data_kav$valence / harm_final_data_kav$wordcount * 100

#flatten down to sum by article
harm_final_temp_kav = aggregate(harm_final_data_kav$weight,
          by = list(harm_final_data_kav$URL),
          FUN = sum, na.rm = T)
colnames(harm_final_temp_kav) = c("URL", "MFDweight")

harm_final_temp_kav$lean[grepl("nytimes.com", harm_final_temp_kav$URL) |
                       grepl("npr.org", harm_final_temp_kav$URL) |
                        grepl("slate.com", harm_final_temp_kav$URL) |
                        grepl("huffingtonpost.com", harm_final_temp_kav$URL) |
                        grepl("politico.com", harm_final_temp_kav$URL)] = "Liberal"

harm_final_temp_kav$lean[grepl("breitbart.com", harm_final_temp_kav$URL) |
                       grepl("foxnews.com", harm_final_temp_kav$URL) |
                       grepl("rushlimbaugh.com", harm_final_temp_kav$URL) |
                       grepl("theblaze.com", harm_final_temp_kav$URL) |
                       grepl("hannity.com", harm_final_temp_kav$URL)] = "Conservative"

harm_final_temp_kav$Source[grepl("nytimes.com", harm_final_temp_kav$URL)] = "NY Times"
harm_final_temp_kav$Source[grepl("npr.org", harm_final_temp_kav$URL)] = "NPR"
harm_final_temp_kav$Source[grepl("slate.com", harm_final_temp_kav$URL)] = "Slate"
harm_final_temp_kav$Source[grepl("huffingtonpost.com", harm_final_temp_kav$URL)] = "Huffington Post"
harm_final_temp_kav$Source[grepl("politico.com", harm_final_temp_kav$URL)] = "Politico"
harm_final_temp_kav$Source[grepl("foxnews.com", harm_final_temp_kav$URL)] = "Fox"
harm_final_temp_kav$Source[grepl("breitbart.com", harm_final_temp_kav$URL)] = "Breitbart"
harm_final_temp_kav$Source[grepl("rushlimbaugh.com", harm_final_temp_kav$URL)] = "Rush Limbaugh"
harm_final_temp_kav$Source[grepl("theblaze.com", harm_final_temp_kav$URL)] = "The Blaze"
harm_final_temp_kav$Source[grepl("hannity.com", harm_final_temp_kav$URL)] = "Sean Hannity"

harm_icc_k <- lme(MFDweight ~ 1,
                 data = harm_final_temp_kav,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))

harm_model_kav = lme(MFDweight ~ lean,
                 data = harm_final_temp_kav,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))
summary(harm_model_kav)
r.squaredGLMM(harm_model_kav)

# check linearity
random <- rchisq(nrow(harm_final_temp_kav), 7)
residuals <- scale(residuals(harm_model_kav))
fitted <- scale(fitted(harm_model_kav))
hist(residuals)
{qqnorm(residuals); abline(0,1)}
{plot(fitted, residuals); abline(h = 0); abline(v = 0)}
```

```{r analysis_fair_kav, include = FALSE}
#final_data clean up
#multiply by frequency and create percentage
fair_final_data_kav$weight = fair_final_data_kav$Freq * fair_final_data_kav$valence / fair_final_data_kav$wordcount * 100

#flatten down to sum by article
fair_final_temp_kav = aggregate(fair_final_data_kav$weight,
          by = list(fair_final_data_kav$URL),
          FUN = sum, na.rm = T)
colnames(fair_final_temp_kav) = c("URL", "MFDweight")

fair_final_temp_kav$lean[grepl("nytimes.com", fair_final_temp_kav$URL) |
                       grepl("npr.org", fair_final_temp_kav$URL) |
                        grepl("slate.com", fair_final_temp_kav$URL) |
                        grepl("huffingtonpost.com", fair_final_temp_kav$URL) |
                        grepl("politico.com", fair_final_temp_kav$URL)] = "Liberal"

fair_final_temp_kav$lean[grepl("breitbart.com", fair_final_temp_kav$URL) |
                       grepl("foxnews.com", fair_final_temp_kav$URL) |
                       grepl("rushlimbaugh.com", fair_final_temp_kav$URL) |
                       grepl("theblaze.com", fair_final_temp_kav$URL) |
                       grepl("hannity.com", fair_final_temp_kav$URL)] = "Conservative"

fair_final_temp_kav$Source[grepl("nytimes.com", fair_final_temp_kav$URL)] = "NY Times"
fair_final_temp_kav$Source[grepl("npr.org", fair_final_temp_kav$URL)] = "NPR"
fair_final_temp_kav$Source[grepl("slate.com", fair_final_temp_kav$URL)] = "Slate"
fair_final_temp_kav$Source[grepl("huffingtonpost.com", fair_final_temp_kav$URL)] = "Huffington Post"
fair_final_temp_kav$Source[grepl("politico.com", fair_final_temp_kav$URL)] = "Politico"
fair_final_temp_kav$Source[grepl("foxnews.com", fair_final_temp_kav$URL)] = "Fox"
fair_final_temp_kav$Source[grepl("breitbart.com", fair_final_temp_kav$URL)] = "Breitbart"
fair_final_temp_kav$Source[grepl("rushlimbaugh.com", fair_final_temp_kav$URL)] = "Rush Limbaugh"
fair_final_temp_kav$Source[grepl("theblaze.com", fair_final_temp_kav$URL)] = "The Blaze"
fair_final_temp_kav$Source[grepl("hannity.com", fair_final_temp_kav$URL)] = "Sean Hannity"

fair_icc_k <- lme(MFDweight ~ 1,
                 data = fair_final_temp_kav,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))

fair_model_kav = lme(MFDweight ~ lean,
                 data = fair_final_temp_kav,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))
summary(fair_model_kav)

# check linearity
random <- rchisq(nrow(fair_final_temp_kav), 7)
residuals <- scale(residuals(fair_model_kav))
fitted <- scale(fitted(fair_model_kav))
hist(residuals)
{qqnorm(residuals); abline(0,1)}
{plot(fitted, residuals); abline(h = 0); abline(v = 0)}
```

```{r analysis_ingroup_kav, include = FALSE}
#final_data clean up
#multiply by frequency and create percentage
ingroup_final_data_kav$weight = ingroup_final_data_kav$Freq * ingroup_final_data_kav$valence / ingroup_final_data_kav$wordcount * 100

#flatten down to sum by article
ingroup_final_temp_kav = aggregate(ingroup_final_data_kav$weight,
          by = list(ingroup_final_data_kav$URL),
          FUN = sum, na.rm = T)
colnames(ingroup_final_temp_kav) = c("URL", "MFDweight")

ingroup_final_temp_kav$lean[grepl("nytimes.com", ingroup_final_temp_kav$URL) |
                       grepl("npr.org", ingroup_final_temp_kav$URL) |
                        grepl("slate.com", ingroup_final_temp_kav$URL) |
                        grepl("huffingtonpost.com", ingroup_final_temp_kav$URL) |
                        grepl("politico.com", ingroup_final_temp_kav$URL)] = "Liberal"

ingroup_final_temp_kav$lean[grepl("breitbart.com", ingroup_final_temp_kav$URL) |
                       grepl("foxnews.com", ingroup_final_temp_kav$URL) |
                       grepl("rushlimbaugh.com", ingroup_final_temp_kav$URL) |
                       grepl("theblaze.com", ingroup_final_temp_kav$URL) |
                       grepl("hannity.com", ingroup_final_temp_kav$URL)] = "Conservative"

ingroup_final_temp_kav$Source[grepl("nytimes.com", ingroup_final_temp_kav$URL)] = "NY Times"
ingroup_final_temp_kav$Source[grepl("npr.org", ingroup_final_temp_kav$URL)] = "NPR"
ingroup_final_temp_kav$Source[grepl("slate.com", ingroup_final_temp_kav$URL)] = "Slate"
ingroup_final_temp_kav$Source[grepl("huffingtonpost.com", ingroup_final_temp_kav$URL)] = "Huffington Post"
ingroup_final_temp_kav$Source[grepl("politico.com", ingroup_final_temp_kav$URL)] = "Politico"
ingroup_final_temp_kav$Source[grepl("foxnews.com", ingroup_final_temp_kav$URL)] = "Fox"
ingroup_final_temp_kav$Source[grepl("breitbart.com", ingroup_final_temp_kav$URL)] = "Breitbart"
ingroup_final_temp_kav$Source[grepl("rushlimbaugh.com", ingroup_final_temp_kav$URL)] = "Rush Limbaugh"
ingroup_final_temp_kav$Source[grepl("theblaze.com", ingroup_final_temp_kav$URL)] = "The Blaze"
ingroup_final_temp_kav$Source[grepl("hannity.com", ingroup_final_temp_kav$URL)] = "Sean Hannity"

ingroup_icc_k <- lme(MFDweight ~ 1,
                 data = ingroup_final_temp_kav,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))

ingroup_model_kav = lme(MFDweight ~ lean,
                 data = ingroup_final_temp_kav,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))
summary(ingroup_model_kav)

# check linearity
random <- rchisq(nrow(ingroup_final_temp_kav), 7)
residuals <- scale(residuals(ingroup_model_kav))
fitted <- scale(fitted(ingroup_model_kav))
hist(residuals)
{qqnorm(residuals); abline(0,1)}
{plot(fitted, residuals); abline(h = 0); abline(v = 0)}
```

```{r analysis_authority_kav, include = FALSE}
#final_data clean up
#multiply by frequency and create percentage
authority_final_data_kav$weight = authority_final_data_kav$Freq * authority_final_data_kav$valence / authority_final_data_kav$wordcount * 100

#flatten down to sum by article
authority_final_temp_kav = aggregate(authority_final_data_kav$weight,
          by = list(authority_final_data_kav$URL),
          FUN = sum, na.rm = T)
colnames(authority_final_temp_kav) = c("URL", "MFDweight")

authority_final_temp_kav$lean[grepl("nytimes.com", authority_final_temp_kav$URL) |
                       grepl("npr.org", authority_final_temp_kav$URL) |
                        grepl("slate.com", authority_final_temp_kav$URL) |
                        grepl("huffingtonpost.com", authority_final_temp_kav$URL) |
                        grepl("politico.com", authority_final_temp_kav$URL)] = "Liberal"

authority_final_temp_kav$lean[grepl("breitbart.com", authority_final_temp_kav$URL) |
                       grepl("foxnews.com", authority_final_temp_kav$URL) |
                       grepl("rushlimbaugh.com", authority_final_temp_kav$URL) |
                       grepl("theblaze.com", authority_final_temp_kav$URL) |
                       grepl("hannity.com", authority_final_temp_kav$URL)] = "Conservative"

authority_final_temp_kav$Source[grepl("nytimes.com", authority_final_temp_kav$URL)] = "NY Times"
authority_final_temp_kav$Source[grepl("npr.org", authority_final_temp_kav$URL)] = "NPR"
authority_final_temp_kav$Source[grepl("slate.com", authority_final_temp_kav$URL)] = "Slate"
authority_final_temp_kav$Source[grepl("huffingtonpost.com", authority_final_temp_kav$URL)] = "Huffington Post"
authority_final_temp_kav$Source[grepl("politico.com", authority_final_temp_kav$URL)] = "Politico"
authority_final_temp_kav$Source[grepl("foxnews.com", authority_final_temp_kav$URL)] = "Fox"
authority_final_temp_kav$Source[grepl("breitbart.com", authority_final_temp_kav$URL)] = "Breitbart"
authority_final_temp_kav$Source[grepl("rushlimbaugh.com", authority_final_temp_kav$URL)] = "Rush Limbaugh"
authority_final_temp_kav$Source[grepl("theblaze.com", authority_final_temp_kav$URL)] = "The Blaze"
authority_final_temp_kav$Source[grepl("hannity.com", authority_final_temp_kav$URL)] = "Sean Hannity"

authority_icc_k <- lme(MFDweight ~ 1,
                 data = authority_final_temp_kav,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))

authority_model_kav = lme(MFDweight ~ lean,
                 data = authority_final_temp_kav,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))
summary(authority_model_kav)

# check linearity
random <- rchisq(nrow(authority_final_temp_kav), 7)
residuals <- scale(residuals(authority_model_kav))
fitted <- scale(fitted(authority_model_kav))
hist(residuals)
{qqnorm(residuals); abline(0,1)}
{plot(fitted, residuals); abline(h = 0); abline(v = 0)}
```

```{r analysis_purity_kav, include = FALSE}
#final_data clean up
#multiply by frequency and create percentage
purity_final_data_kav$weight = purity_final_data_kav$Freq * purity_final_data_kav$valence / purity_final_data_kav$wordcount * 100

#flatten down to sum by article
purity_final_temp_kav = aggregate(purity_final_data_kav$weight,
          by = list(purity_final_data_kav$URL),
          FUN = sum, na.rm = T)
colnames(purity_final_temp_kav) = c("URL", "MFDweight")

purity_final_temp_kav$lean[grepl("nytimes.com", purity_final_temp_kav$URL) |
                       grepl("npr.org", purity_final_temp_kav$URL) |
                        grepl("slate.com", purity_final_temp_kav$URL) |
                        grepl("huffingtonpost.com", purity_final_temp_kav$URL) |
                        grepl("politico.com", purity_final_temp_kav$URL)] = "Liberal"

purity_final_temp_kav$lean[grepl("breitbart.com", purity_final_temp_kav$URL) |
                       grepl("foxnews.com", purity_final_temp_kav$URL) |
                       grepl("rushlimbaugh.com", purity_final_temp_kav$URL) |
                       grepl("theblaze.com", purity_final_temp_kav$URL) |
                       grepl("hannity.com", purity_final_temp_kav$URL)] = "Conservative"

purity_final_temp_kav$Source[grepl("nytimes.com", purity_final_temp_kav$URL)] = "NY Times"
purity_final_temp_kav$Source[grepl("npr.org", purity_final_temp_kav$URL)] = "NPR"
purity_final_temp_kav$Source[grepl("slate.com", purity_final_temp_kav$URL)] = "Slate"
purity_final_temp_kav$Source[grepl("huffingtonpost.com", purity_final_temp_kav$URL)] = "Huffington Post"
purity_final_temp_kav$Source[grepl("politico.com", purity_final_temp_kav$URL)] = "Politico"
purity_final_temp_kav$Source[grepl("foxnews.com", purity_final_temp_kav$URL)] = "Fox"
purity_final_temp_kav$Source[grepl("breitbart.com", purity_final_temp_kav$URL)] = "Breitbart"
purity_final_temp_kav$Source[grepl("rushlimbaugh.com", purity_final_temp_kav$URL)] = "Rush Limbaugh"
purity_final_temp_kav$Source[grepl("theblaze.com", purity_final_temp_kav$URL)] = "The Blaze"
purity_final_temp_kav$Source[grepl("hannity.com", purity_final_temp_kav$URL)] = "Sean Hannity"

purity_icc_k <- lme(MFDweight ~ 1,
                 data = purity_final_temp_kav,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))

purity_model_kav = lme(MFDweight ~ lean,
                 data = purity_final_temp_kav,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))
summary(purity_model_kav)

# check linearity
random <- rchisq(nrow(purity_final_temp_kav), 7)
residuals <- scale(residuals(purity_model_kav))
fitted <- scale(fitted(purity_model_kav))
hist(residuals)
{qqnorm(residuals); abline(0,1)}
{plot(fitted, residuals); abline(h = 0); abline(v = 0)}
```

```{r analysis_harm_gs, include = FALSE}
#final_data clean up
#multiply by frequency and create percentage
harm_final_data_gs$weight = harm_final_data_gs$Freq * harm_final_data_gs$valence / harm_final_data_gs$wordcount * 100

#flatten down to sum by article
harm_final_temp_gs = aggregate(harm_final_data_gs$weight,
          by = list(harm_final_data_gs$URL),
          FUN = sum, na.rm = T)
colnames(harm_final_temp_gs) = c("URL", "MFDweight")

harm_final_temp_gs$lean[grepl("nytimes.com", harm_final_temp_gs$URL) |
                       grepl("npr.org", harm_final_temp_gs$URL) |
                        grepl("slate.com", harm_final_temp_gs$URL) |
                        grepl("huffingtonpost.com", harm_final_temp_gs$URL) |
                        grepl("politico.com", harm_final_temp_gs$URL)] = "Liberal"

harm_final_temp_gs$lean[grepl("breitbart.com", harm_final_temp_gs$URL) |
                       grepl("foxnews.com", harm_final_temp_gs$URL) |
                       grepl("rushlimbaugh.com", harm_final_temp_gs$URL) |
                       grepl("theblaze.com", harm_final_temp_gs$URL) |
                       grepl("hannity.com", harm_final_temp_gs$URL)] = "Conservative"

harm_final_temp_gs$Source[grepl("nytimes.com", harm_final_temp_gs$URL)] = "NY Times"
harm_final_temp_gs$Source[grepl("npr.org", harm_final_temp_gs$URL)] = "NPR"
harm_final_temp_gs$Source[grepl("slate.com", harm_final_temp_gs$URL)] = "Slate"
harm_final_temp_gs$Source[grepl("huffingtonpost.com", harm_final_temp_gs$URL)] = "Huffington Post"
harm_final_temp_gs$Source[grepl("politico.com", harm_final_temp_gs$URL)] = "Politico"
harm_final_temp_gs$Source[grepl("foxnews.com", harm_final_temp_gs$URL)] = "Fox"
harm_final_temp_gs$Source[grepl("breitbart.com", harm_final_temp_gs$URL)] = "Breitbart"
harm_final_temp_gs$Source[grepl("rushlimbaugh.com", harm_final_temp_gs$URL)] = "Rush Limbaugh"
harm_final_temp_gs$Source[grepl("theblaze.com", harm_final_temp_gs$URL)] = "The Blaze"
harm_final_temp_gs$Source[grepl("hannity.com", harm_final_temp_gs$URL)] = "Sean Hannity"

harm_icc_gs <- lme(MFDweight ~ 1,
                 data = harm_final_temp_gs,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))

harm_model_gs = lme(MFDweight ~ lean,
                 data = harm_final_temp_gs,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))
summary(harm_model_gs)

# check linearity
random <- rchisq(nrow(harm_final_temp_gs), 7)
residuals <- scale(residuals(harm_model_gs))
fitted <- scale(fitted(harm_model_gs))
hist(residuals)
{qqnorm(residuals); abline(0,1)}
{plot(fitted, residuals); abline(h = 0); abline(v = 0)}
```

```{r analysis_fair_gs, include = FALSE}
#final_data clean up
#multiply by frequency and create percentage
fair_final_data_gs$weight = fair_final_data_gs$Freq * fair_final_data_gs$valence / fair_final_data_gs$wordcount * 100

#flatten down to sum by article
fair_final_temp_gs = aggregate(fair_final_data_gs$weight,
          by = list(fair_final_data_gs$URL),
          FUN = sum, na.rm = T)
colnames(fair_final_temp_gs) = c("URL", "MFDweight")

fair_final_temp_gs$lean[grepl("nytimes.com", fair_final_temp_gs$URL) |
                       grepl("npr.org", fair_final_temp_gs$URL) |
                        grepl("slate.com", fair_final_temp_gs$URL) |
                        grepl("huffingtonpost.com", fair_final_temp_gs$URL) |
                        grepl("politico.com", fair_final_temp_gs$URL)] = "Liberal"

fair_final_temp_gs$lean[grepl("breitbart.com", fair_final_temp_gs$URL) |
                       grepl("foxnews.com", fair_final_temp_gs$URL) |
                       grepl("rushlimbaugh.com", fair_final_temp_gs$URL) |
                       grepl("theblaze.com", fair_final_temp_gs$URL) |
                       grepl("hannity.com", fair_final_temp_gs$URL)] = "Conservative"

fair_final_temp_gs$Source[grepl("nytimes.com", fair_final_temp_gs$URL)] = "NY Times"
fair_final_temp_gs$Source[grepl("npr.org", fair_final_temp_gs$URL)] = "NPR"
fair_final_temp_gs$Source[grepl("slate.com", fair_final_temp_gs$URL)] = "Slate"
fair_final_temp_gs$Source[grepl("huffingtonpost.com", fair_final_temp_gs$URL)] = "Huffington Post"
fair_final_temp_gs$Source[grepl("politico.com", fair_final_temp_gs$URL)] = "Politico"
fair_final_temp_gs$Source[grepl("foxnews.com", fair_final_temp_gs$URL)] = "Fox"
fair_final_temp_gs$Source[grepl("breitbart.com", fair_final_temp_gs$URL)] = "Breitbart"
fair_final_temp_gs$Source[grepl("rushlimbaugh.com", fair_final_temp_gs$URL)] = "Rush Limbaugh"
fair_final_temp_gs$Source[grepl("theblaze.com", fair_final_temp_gs$URL)] = "The Blaze"
fair_final_temp_gs$Source[grepl("hannity.com", fair_final_temp_gs$URL)] = "Sean Hannity"

fair_icc_gs <- lme(MFDweight ~ 1,
                 data = fair_final_temp_gs,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))

fair_model_gs = lme(MFDweight ~ lean,
                 data = fair_final_temp_gs,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))
summary(fair_model_gs)

# check linearity
random <- rchisq(nrow(fair_final_temp_gs), 7)
residuals <- scale(residuals(fair_model_gs))
fitted <- scale(fitted(fair_model_gs))
hist(residuals)
{qqnorm(residuals); abline(0,1)}
{plot(fitted, residuals); abline(h = 0); abline(v = 0)}
```

```{r analysis_ingroup_gs, include = FALSE}
#final_data clean up
#multiply by frequency and create percentage
ingroup_final_data_gs$weight = ingroup_final_data_gs$Freq * ingroup_final_data_gs$valence / ingroup_final_data_gs$wordcount * 100

#flatten down to sum by article
ingroup_final_temp_gs = aggregate(ingroup_final_data_gs$weight,
          by = list(ingroup_final_data_gs$URL),
          FUN = sum, na.rm = T)
colnames(ingroup_final_temp_gs) = c("URL", "MFDweight")

ingroup_final_temp_gs$lean[grepl("nytimes.com", ingroup_final_temp_gs$URL) |
                       grepl("npr.org", ingroup_final_temp_gs$URL) |
                        grepl("slate.com", ingroup_final_temp_gs$URL) |
                        grepl("huffingtonpost.com", ingroup_final_temp_gs$URL) |
                        grepl("politico.com", ingroup_final_temp_gs$URL)] = "Liberal"

ingroup_final_temp_gs$lean[grepl("breitbart.com", ingroup_final_temp_gs$URL) |
                       grepl("foxnews.com", ingroup_final_temp_gs$URL) |
                       grepl("rushlimbaugh.com", ingroup_final_temp_gs$URL) |
                       grepl("theblaze.com", ingroup_final_temp_gs$URL) |
                       grepl("hannity.com", ingroup_final_temp_gs$URL)] = "Conservative"

ingroup_final_temp_gs$Source[grepl("nytimes.com", ingroup_final_temp_gs$URL)] = "NY Times"
ingroup_final_temp_gs$Source[grepl("npr.org", ingroup_final_temp_gs$URL)] = "NPR"
ingroup_final_temp_gs$Source[grepl("slate.com", ingroup_final_temp_gs$URL)] = "Slate"
ingroup_final_temp_gs$Source[grepl("huffingtonpost.com", ingroup_final_temp_gs$URL)] = "Huffington Post"
ingroup_final_temp_gs$Source[grepl("politico.com", ingroup_final_temp_gs$URL)] = "Politico"
ingroup_final_temp_gs$Source[grepl("foxnews.com", ingroup_final_temp_gs$URL)] = "Fox"
ingroup_final_temp_gs$Source[grepl("breitbart.com", ingroup_final_temp_gs$URL)] = "Breitbart"
ingroup_final_temp_gs$Source[grepl("rushlimbaugh.com", ingroup_final_temp_gs$URL)] = "Rush Limbaugh"
ingroup_final_temp_gs$Source[grepl("theblaze.com", ingroup_final_temp_gs$URL)] = "The Blaze"
ingroup_final_temp_gs$Source[grepl("hannity.com", ingroup_final_temp_gs$URL)] = "Sean Hannity"

ingroup_icc_gs <- lme(MFDweight ~ 1,
                 data = ingroup_final_temp_gs,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))

ingroup_model_gs = lme(MFDweight ~ lean,
                 data = ingroup_final_temp_gs,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))
summary(ingroup_model_gs)

# check linearity
random <- rchisq(nrow(ingroup_final_temp_gs), 7)
residuals <- scale(residuals(ingroup_model_gs))
fitted <- scale(fitted(ingroup_model_gs))
hist(residuals)
{qqnorm(residuals); abline(0,1)}
{plot(fitted, residuals); abline(h = 0); abline(v = 0)}
```

```{r analysis_authority_gs, include = FALSE}
#final_data clean up
#multiply by frequency and create percentage
authority_final_data_gs$weight = authority_final_data_gs$Freq * authority_final_data_gs$valence / authority_final_data_gs$wordcount * 100

#flatten down to sum by article
authority_final_temp_gs = aggregate(authority_final_data_gs$weight,
          by = list(authority_final_data_gs$URL),
          FUN = sum, na.rm = T)
colnames(authority_final_temp_gs) = c("URL", "MFDweight")

authority_final_temp_gs$lean[grepl("nytimes.com", authority_final_temp_gs$URL) |
                       grepl("npr.org", authority_final_temp_gs$URL) |
                        grepl("slate.com", authority_final_temp_gs$URL) |
                        grepl("huffingtonpost.com", authority_final_temp_gs$URL) |
                        grepl("politico.com", authority_final_temp_gs$URL)] = "Liberal"

authority_final_temp_gs$lean[grepl("breitbart.com", authority_final_temp_gs$URL) |
                       grepl("foxnews.com", authority_final_temp_gs$URL) |
                       grepl("rushlimbaugh.com", authority_final_temp_gs$URL) |
                       grepl("theblaze.com", authority_final_temp_gs$URL) |
                       grepl("hannity.com", authority_final_temp_gs$URL)] = "Conservative"

authority_final_temp_gs$Source[grepl("nytimes.com", authority_final_temp_gs$URL)] = "NY Times"
authority_final_temp_gs$Source[grepl("npr.org", authority_final_temp_gs$URL)] = "NPR"
authority_final_temp_gs$Source[grepl("slate.com", authority_final_temp_gs$URL)] = "Slate"
authority_final_temp_gs$Source[grepl("huffingtonpost.com", authority_final_temp_gs$URL)] = "Huffington Post"
authority_final_temp_gs$Source[grepl("politico.com", authority_final_temp_gs$URL)] = "Politico"
authority_final_temp_gs$Source[grepl("foxnews.com", authority_final_temp_gs$URL)] = "Fox"
authority_final_temp_gs$Source[grepl("breitbart.com", authority_final_temp_gs$URL)] = "Breitbart"
authority_final_temp_gs$Source[grepl("rushlimbaugh.com", authority_final_temp_gs$URL)] = "Rush Limbaugh"
authority_final_temp_gs$Source[grepl("theblaze.com", authority_final_temp_gs$URL)] = "The Blaze"
authority_final_temp_gs$Source[grepl("hannity.com", authority_final_temp_gs$URL)] = "Sean Hannity"

authority_icc_gs <- lme(MFDweight ~ 1,
                 data = authority_final_temp_gs,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))

authority_model_gs = lme(MFDweight ~ lean,
                 data = authority_final_temp_gs,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))
summary(authority_model_gs)

# check linearity
random <- rchisq(nrow(authority_final_temp_gs), 7)
residuals <- scale(residuals(authority_model_gs))
fitted <- scale(fitted(authority_model_gs))
hist(residuals)
{qqnorm(residuals); abline(0,1)}
{plot(fitted, residuals); abline(h = 0); abline(v = 0)}
```

```{r analysis_purity_gs, include = FALSE}
#final_data clean up
#multiply by frequency and create percentage
purity_final_data_gs$weight = purity_final_data_gs$Freq * purity_final_data_gs$valence / purity_final_data_gs$wordcount * 100

#flatten down to sum by article
purity_final_temp_gs = aggregate(purity_final_data_gs$weight,
          by = list(purity_final_data_gs$URL),
          FUN = sum, na.rm = T)
colnames(purity_final_temp_gs) = c("URL", "MFDweight")

purity_final_temp_gs$lean[grepl("nytimes.com", purity_final_temp_gs$URL) |
                       grepl("npr.org", purity_final_temp_gs$URL) |
                        grepl("slate.com", purity_final_temp_gs$URL) |
                        grepl("huffingtonpost.com", purity_final_temp_gs$URL) |
                        grepl("politico.com", purity_final_temp_gs$URL)] = "Liberal"

purity_final_temp_gs$lean[grepl("breitbart.com", purity_final_temp_gs$URL) |
                       grepl("foxnews.com", purity_final_temp_gs$URL) |
                       grepl("rushlimbaugh.com", purity_final_temp_gs$URL) |
                       grepl("theblaze.com", purity_final_temp_gs$URL) |
                       grepl("hannity.com", purity_final_temp_gs$URL)] = "Conservative"

purity_final_temp_gs$Source[grepl("nytimes.com", purity_final_temp_gs$URL)] = "NY Times"
purity_final_temp_gs$Source[grepl("npr.org", purity_final_temp_gs$URL)] = "NPR"
purity_final_temp_gs$Source[grepl("slate.com", purity_final_temp_gs$URL)] = "Slate"
purity_final_temp_gs$Source[grepl("huffingtonpost.com", purity_final_temp_gs$URL)] = "Huffington Post"
purity_final_temp_gs$Source[grepl("politico.com", purity_final_temp_gs$URL)] = "Politico"
purity_final_temp_gs$Source[grepl("foxnews.com", purity_final_temp_gs$URL)] = "Fox"
purity_final_temp_gs$Source[grepl("breitbart.com", purity_final_temp_gs$URL)] = "Breitbart"
purity_final_temp_gs$Source[grepl("rushlimbaugh.com", purity_final_temp_gs$URL)] = "Rush Limbaugh"
purity_final_temp_gs$Source[grepl("theblaze.com", purity_final_temp_gs$URL)] = "The Blaze"
purity_final_temp_gs$Source[grepl("hannity.com", purity_final_temp_gs$URL)] = "Sean Hannity"

purity_icc_gs <- lme(MFDweight ~ 1,
                 data = purity_final_temp_gs,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))

purity_model_gs = lme(MFDweight ~ lean,
                 data = purity_final_temp_gs,
                 method = "ML",
                 na.action = "na.omit",
                 random = list(~1|Source))
summary(purity_model_gs)

# check linearity
random <- rchisq(nrow(purity_final_temp_gs), 7)
residuals <- scale(residuals(purity_model_gs))
fitted <- scale(fitted(purity_model_gs))
hist(residuals)
{qqnorm(residuals); abline(0,1)}
{plot(fitted, residuals); abline(h = 0); abline(v = 0)}
```

# Results

## Descriptive Statistics

We calculated descriptive statistics for each news source per topic in order to reveal the presence (if any) of linguistic differences in the sources' use of language. As in Study 1, statistics calculated include *z*-scored valence, number of articles per source, total words per source, mean tokens per article in each source, mean types per article in each source, and mean readability level (using the Flesch-Kincaid Grade Level Readability formula) per source [@Kincaid1975].

Table \@ref(tab:exp2-source-descriptives-kav) displays the descriptive statistics for sources' writing on the Kavanaugh confirmation hearing. The sources were similar in most basic linguistic aspects, except for number of articles. For example, *Sean Hannity* appears to have published only 27 articles while *Breitbart* published 757 articles on this topic. Valence was found to be slightly positive across all sources. *Fox News* produced the most total words with the most tokens on average. This is likely due to the fact *Fox News* transcribes many of their videos and publishes them in article form. *Politico* featured the highest number of types on average. *Rush Limbaugh* featured the lowest readability score on average by grade level while *Slate* featured the highest grade-level readability score. The large standard deviations for these statistics, however, preclude conclusions regarding differences in the sources' use of language, as there is likely a lot of overlap between sources' use of language.

```{r exp2_descriptive_calculate_kav, include = F, echo = F}
#Kav
final_kav$uniquewords = NA
final_kav$valenceavg = NA
for (i in 1:nrow(final_kav)){

  #add unique
  final_kav$uniquewords[i] = length(unique(unlist(strsplit(final_kav$stemmed[i], " "))))

  #add valence
  tempwords_kav = as.data.frame(unlist(strsplit(final_kav$stemmed[i], " ")))
  colnames(tempwords_kav) = "theword"
  tempwords_kav$tempval = vlookup(tempwords_kav$theword, #index in original data
                    warriner, #where's the stuff you want to put in
                    "V.Mean.Sum", #what column is the stuff you want
                    "Word2") #what's the matching index

  final_kav$valenceavg[i] = mean(tempwords_kav$tempval, na.rm = T)
}
# tapply(final_kav$valenceavg, final_kav$Source, mean)
# tapply(final_kav$valenceavg, final_kav$Source, sd)
# tapply(final_kav$wordcount, final_kav$Source, mean)
# tapply(final_kav$wordcount, final_kav$Source, sd)
# tapply(final_kav$uniquewords, final_kav$Source, mean)
# tapply(final_kav$uniquewords, final_kav$Source, sd)
# tapply(final_kav$Source, final_kav$Source, length)
# tapply(final_kav$wordcount, final_kav$Source, sum)
library(quanteda)
final_kav$FK = NA
for (i in 1:nrow(final_kav)){
  final_kav$FK[i] = unlist(textstat_readability(final_kav$Text[i],
                     measure = "Flesch.Kincaid")$Flesch.Kincaid)
}
# tapply(final_kav$FK, final_kav$Source, mean)
# tapply(final_kav$FK, final_kav$Source, sd)
#Kav Table
####build the table here####
tableprint3 = matrix(NA, nrow=10, ncol=11)
colnames(tableprint3) = c("Source", "Mean_Valence", "SD_Valence", "Number_of_Articles", "Total_Words", "Mean_Tokens", "SD_Tokens", "Mean_Types", "SD_Types", "Mean_Readability", "SD_Readability")
#tableprint3[ , 1] = unique(final_kav$Source)
tableprint3[ , 1] = c("The Blaze", "Breitbart", "Fox News", "Sean Hannity",
                     "Huffington Post", "NPR", "New York Times", "Politico",
                     "Rush Limbaugh", "Slate")
tableprint3[ , 2] = tapply(final_kav$valenceavg, final_kav$Source, mean, na.rm = T)
tableprint3[ , 3] = tapply(final_kav$valenceavg, final_kav$Source, sd, na.rm = T)
tableprint3[ , 4] = tapply(final_kav$valenceavg, final_kav$Source, length)
tableprint3[ , 5] = tapply(final_kav$wordcount, final_kav$Source, sum, na.rm = T)
tableprint3[ , 6] = tapply(final_kav$wordcount, final_kav$Source, mean, na.rm = T)
tableprint3[ , 7] = tapply(final_kav$wordcount, final_kav$Source, sd)
tableprint3[ , 8] = tapply(final_kav$uniquewords, final_kav$Source, mean, na.rm = T)
tableprint3[ , 9] = tapply(final_kav$uniquewords, final_kav$Source, sd, na.rm = T)
tableprint3[ , 10] = tapply(final_kav$FK, final_kav$Source, mean, na.rm = T)
tableprint3[ , 11] = tapply(final_kav$FK, final_kav$Source, sd, na.rm = T)
tableprint3[ , c(2,3,6,7,8,9,10,11)] = printnum(as.numeric(tableprint3[ , c(2,3,6,7,8,9,10,11)]), big.mark = "")
tableprint3 = tableprint3[c(5, 6, 7, 8, 10, 1, 2, 3, 4, 9), ]
```

```{r exp2-source-descriptives-kav, results = 'asis', echo = FALSE, message = F}
#change this to match
apa_table(as.data.frame(tableprint3),
          note = "Readability statistics were calculated using the Flesch-Kincaid Grade Level readability formula. V = Valence, T = Tokens or total words, Ty = Types or unique words, FK = Flesch-Kincaid",
          caption = "Kavanaugh - Descriptive Statistics by Source",
          col.names = c("Source", "$M_V$", "$SD_V$", "$N_{Article}$", "$N_{Words}$", "$M_T$", "$SD_T$", "$M_{Ty}$", "$SD_{Ty}$", "$M_{FK}$", "$SD_{FK}$"),
          format = "latex",
          escape = F,
          align = c("l", rep("c", 10)),
          font_size = 'footnotesize',
          placement = "h"
          )
```

Table \@ref(tab:exp2-source-descriptives-gs) displays descriptive statistics for articles about the partial government shutdown. Like the Kavanaugh hearing, the sources were similar in average valence (slightly positive). Once again, there was variation in the number of articles published by each source on this topic. *Sean Hannity*, *Rush Limbaugh*, and *The Blaze* published fewer than 100 articles while *Fox News* published 1,013 articles. *Fox News* again featured the most total words and mean tokens, but this is likely due to to the presence of a large amount of video transcriptions that the organization published as articles. *Politico* had the most types on average. For this topic, *Fox News* featured the lowest reading grade level while *Slate* featured the highest reading grade level. For each statistic, the excessively high standard deviations render any assertions regarding linguistic differences inconclusive on a descriptive level due to the aforementioned overlap in sources' language use.

```{r exp2_descriptive_calculate_gs}
#GS
final_gs$uniquewords = NA
final_gs$valenceavg = NA

for (i in 1:nrow(final_gs)){

  #add unique
  final_gs$uniquewords[i] = length(unique(unlist(strsplit(final_gs$stemmed[i], " "))))

  #add valence
  tempwords_gs = as.data.frame(unlist(strsplit(final_gs$stemmed[i], " ")))
  colnames(tempwords_gs) = "theword"
  tempwords_gs$tempval = vlookup(tempwords_gs$theword, #index in original data
                    warriner, #where's the stuff you want to put in
                    "V.Mean.Sum", #what column is the stuff you want
                    "Word2") #what's the matching index

  final_gs$valenceavg[i] = mean(tempwords_gs$tempval, na.rm = T)

}


# tapply(final_gs$valenceavg, final_gs$Source, mean)
# tapply(final_gs$valenceavg, final_gs$Source, sd)
# tapply(final_gs$wordcount, final_gs$Source, mean)
# tapply(final_gs$wordcount, final_gs$Source, sd)
# tapply(final_gs$uniquewords, final_gs$Source, mean)
# tapply(final_gs$uniquewords, final_gs$Source, sd)
# tapply(final_gs$Source, final_gs$Source, length)
# tapply(final_gs$wordcount, final_gs$Source, sum)

library(quanteda)

final_gs$FK = NA

for (i in 1:nrow(final_gs)){
  final_gs$FK[i] = unlist(textstat_readability(final_gs$Text[i],
                     measure = "Flesch.Kincaid")$Flesch.Kincaid)
}

# tapply(final_gs$FK, final_gs$Source, mean)
# tapply(final_gs$FK, final_gs$Source, sd)

#GS Table
####build the table here####
tableprint4 = matrix(NA, nrow=10, ncol=11)
colnames(tableprint4) = c("Source", "Mean_Valence", "SD_Valence", "Number_of_Articles", "Total_Words", "Mean_Tokens", "SD_Tokens", "Mean_Types", "SD_Types", "Mean_Readability", "SD_Readability")

#tableprint4[ , 1] = unique(final_gs$Source)
tableprint4[ , 1] = c("The Blaze", "Breitbart", "Fox News", "Sean Hannity",
                     "Huffington Post", "NPR", "New York Times", "Politico",
                     "Rush Limbaugh", "Slate")
tableprint4[ , 2] = tapply(final_gs$valenceavg, final_gs$Source, mean)
tableprint4[ , 3] = tapply(final_gs$valenceavg, final_gs$Source, sd)
tableprint4[ , 4] = tapply(final_gs$valenceavg, final_gs$Source, length)
tableprint4[ , 5] = tapply(final_gs$wordcount, final_gs$Source, sum)
tableprint4[ , 6] = tapply(final_gs$wordcount, final_gs$Source, mean)
tableprint4[ , 7] = tapply(final_gs$wordcount, final_gs$Source, sd)
tableprint4[ , 8] = tapply(final_gs$uniquewords, final_gs$Source, mean)
tableprint4[ , 9] = tapply(final_gs$uniquewords, final_gs$Source, sd)
tableprint4[ , 10] = tapply(final_gs$FK, final_gs$Source, mean)
tableprint4[ , 11] = tapply(final_gs$FK, final_gs$Source, sd)

tableprint4[ , c(2,3,6,7,8,9,10,11)] = printnum(as.numeric(tableprint4[ , c(2,3,6,7,8,9,10,11)]), big.mark = "")

tableprint4 = tableprint4[c(5, 6, 7, 8, 10, 1, 2, 3, 4, 9), ]
```

```{r exp2-source-descriptives-gs, results = 'asis', echo = FALSE, message = F}
#change this to match
apa_table(as.data.frame(tableprint4),
          note = "Readability statistics were calculated using the Flesch-Kincaid Grade Level readability formula. V = Valence, T = Tokens or total words, Ty = Types or unique words, FK = Flesch-Kincaid",
          caption = "Government Shutdown - Descriptive Statistics by Source",
          col.names = c("Source", "$M_V$", "$SD_V$", "$N_{Article}$", "$N_{Words}$", "$M_T$", "$SD_T$", "$M_{Ty}$", "$SD_{Ty}$", "$M_{FK}$", "$SD_{FK}$"),
          format = "latex",
          escape = F,
          align = c("l", rep("c", 10)),
          font_size = 'footnotesize',
          placement = "h"
          )
```

## Inferential Statistics

We utilized a multilevel model (MLM) to analyze if news sources leveraged different vocabularies based on target audience in the same manner as Study 1. Each foundation's weighted percentage was predicted by the source's political lean, using the individual source as a random intercept to control for the nested data structure. Two separate MLMs were constructed from datasets compiled for each topic of interest: the Kavanaugh hearing and the partial government shutdown of 2018-2019.

For the Kavanaugh topic, the multilevel model indicated the presence of a statistically significant effect for *harm/care*, but the practical effect denoted by Cohen's *d* was found to be small. There were no other significant or practical effects of political lean for any of the other four moral foundations. The effect for *harm/care* was in the hypothesized direction with liberal sources tending to use more positively *harm/care* words than conservative sources. Descriptive and test statistics, *p*-values and effect sizes (Cohen's *d*) can be found in Table \@ref(tab:exp2-tablekav).

```{r exp2_kav_calc, include = F, echo = F}
#MFD, mean, sd, mean, sd, t, p, d
tableprint_kav = matrix(NA, ncol = 9, nrow = 5)
colnames(tableprint_kav) = c("Foundation", "M_C", "SD_C", "M_L", "SD_L", "t", "p", "d", "ICC")

#calculate d
#harm
harm_d_kav = d.ind.t(m1 = mean(harm_final_temp_kav$MFDweight[harm_final_temp_kav$lean == "Conservative"], na.rm = T),
                 m2 = mean(harm_final_temp_kav$MFDweight[harm_final_temp_kav$lean == "Liberal"], na.rm = T),
                 sd1 = sd(harm_final_temp_kav$MFDweight[harm_final_temp_kav$lean == "Conservative"], na.rm = T),
                 sd2 = sd(harm_final_temp_kav$MFDweight[harm_final_temp_kav$lean == "Liberal"], na.rm = T),
                 n1 = length(harm_final_temp_kav$MFDweight[harm_final_temp_kav$lean == "Conservative"]),
                 n2 = length(harm_final_temp_kav$MFDweight[harm_final_temp_kav$lean == "Liberal"]),
                 a = .05)

#fair
fair_d_kav = d.ind.t(m1 = mean(fair_final_temp_kav$MFDweight[fair_final_temp_kav$lean == "Conservative"], na.rm = T),
                 m2 = mean(fair_final_temp_kav$MFDweight[fair_final_temp_kav$lean == "Liberal"], na.rm = T),
                 sd1 = sd(fair_final_temp_kav$MFDweight[fair_final_temp_kav$lean == "Conservative"], na.rm = T),
                 sd2 = sd(fair_final_temp_kav$MFDweight[fair_final_temp_kav$lean == "Liberal"], na.rm = T),
                 n1 = length(fair_final_temp_kav$MFDweight[fair_final_temp_kav$lean == "Conservative"]),
                 n2 = length(fair_final_temp_kav$MFDweight[fair_final_temp_kav$lean == "Liberal"]),
                 a = .05)

#ingroup
ingroup_d_kav = d.ind.t(m1 = mean(ingroup_final_temp_kav$MFDweight[ingroup_final_temp_kav$lean == "Conservative"], na.rm = T),
                 m2 = mean(ingroup_final_temp_kav$MFDweight[ingroup_final_temp_kav$lean == "Liberal"], na.rm = T),
                 sd1 = sd(ingroup_final_temp_kav$MFDweight[ingroup_final_temp_kav$lean == "Conservative"], na.rm = T),
                 sd2 = sd(ingroup_final_temp_kav$MFDweight[ingroup_final_temp_kav$lean == "Liberal"], na.rm = T),
                 n1 = length(ingroup_final_temp_kav$MFDweight[ingroup_final_temp_kav$lean == "Conservative"]),
                 n2 = length(ingroup_final_temp_kav$MFDweight[ingroup_final_temp_kav$lean == "Liberal"]),
                 a = .05)

#authority
authority_d_kav = d.ind.t(m1 = mean(authority_final_temp_kav$MFDweight[authority_final_temp_kav$lean == "Conservative"], na.rm = T),
                 m2 = mean(authority_final_temp_kav$MFDweight[authority_final_temp_kav$lean == "Liberal"], na.rm = T),
                 sd1 = sd(authority_final_temp_kav$MFDweight[authority_final_temp_kav$lean == "Conservative"], na.rm = T),
                 sd2 = sd(authority_final_temp_kav$MFDweight[authority_final_temp_kav$lean == "Liberal"], na.rm = T),
                 n1 = length(authority_final_temp_kav$MFDweight[authority_final_temp_kav$lean == "Conservative"]),
                 n2 = length(authority_final_temp_kav$MFDweight[authority_final_temp_kav$lean == "Liberal"]),
                 a = .05)

#purity
purity_d_kav = d.ind.t(m1 = mean(purity_final_temp_kav$MFDweight[purity_final_temp_kav$lean == "Conservative"], na.rm = T),
                 m2 = mean(purity_final_temp_kav$MFDweight[purity_final_temp_kav$lean == "Liberal"], na.rm = T),
                 sd1 = sd(purity_final_temp_kav$MFDweight[purity_final_temp_kav$lean == "Conservative"], na.rm = T),
                 sd2 = sd(purity_final_temp_kav$MFDweight[purity_final_temp_kav$lean == "Liberal"], na.rm = T),
                 n1 = length(purity_final_temp_kav$MFDweight[purity_final_temp_kav$lean == "Conservative"]),
                 n2 = length(purity_final_temp_kav$MFDweight[purity_final_temp_kav$lean == "Liberal"]),
                 a = .05)

#put in the numbers
tableprint_kav[1, ] = c("Harm/Care", harm_d_kav$M1, harm_d_kav$sd1, harm_d_kav$M2, harm_d_kav$sd1,
                    summary(harm_model_kav)$tTable[2,4], summary(harm_model_kav)$tTable[2,5],
                    harm_d_kav$d, icc(harm_icc_k)$ICC_unadjusted)
tableprint_kav[2, ] = c("Fairness/Reciprocity", fair_d_kav$M1, fair_d_kav$sd1, fair_d_kav$M2, fair_d_kav$sd1,
                    summary(fair_model_kav)$tTable[2,4], summary(fair_model_kav)$tTable[2,5],
                    fair_d_kav$d, icc(fair_icc_k)$ICC_unadjusted)
tableprint_kav[3, ] = c("Ingroup/Loyalty", ingroup_d_kav$M1, ingroup_d_kav$sd1, ingroup_d_kav$M2, ingroup_d_kav$sd1,
                    summary(ingroup_model_kav)$tTable[2,4], summary(ingroup_model_kav)$tTable[2,5],
                    ingroup_d_kav$d, icc(ingroup_icc_k)$ICC_unadjusted)
tableprint_kav[4, ] = c("Authority/Respect", authority_d_kav$M1, authority_d_kav$sd1, authority_d_kav$M2, authority_d_kav$sd1,
                    summary(authority_model_kav)$tTable[2,4], summary(authority_model_kav)$tTable[2,5],
                    authority_d_kav$d, icc(authority_icc_k)$ICC_unadjusted)
tableprint_kav[5, ] = c("Purity/Sanctity", purity_d_kav$M1, purity_d_kav$sd1, purity_d_kav$M2, purity_d_kav$sd1,
                    summary(purity_model_kav)$tTable[2,4], summary(purity_model_kav)$tTable[2,5],
                    purity_d_kav$d, icc(purity_icc_k)$ICC_unadjusted)

tableprint_kav[ , c(2:6, 8)] = printnum(as.numeric(tableprint_kav[ , c(2:6, 8)]), big.mark = "")
tableprint_kav[ , 7] = printp(as.numeric(tableprint_kav[ , 7]))
tableprint_kav[ , 9] = printp(as.numeric(tableprint_kav[ , 9]))
```

```{r exp2-tablekav, results = 'asis', echo = F}
apa_table(as.data.frame(tableprint_kav),
          note = "For mean and standard deviation values, 'C' and 'L' refer to 'conservative' and 'liberal,' respectively",
          caption = "Kavanaugh Results - Multilevel Model",
          col.names = c("Foundation", "$M_C$", "$SD_C$", "$M_L$", "$SD_L$", "$t$", "$p$", "$d$", "ICC"),
          format = "latex",
          escape = F,
          align = c("l", rep("c", 7)),
          font_size = 'footnotesize',
          placement = "h"
          )
```

For news articles about the partial U.S. Federal Government Shutdown of 2018-2019, there were no significant or practical effects of political lean for the moral foundations (see Table \@ref(tab:exp2-tablegs)). A small-to-medium effect size was observed for *authority/respect*. The effect was in the predicted direction as well, as conservative sources tended to offer more positive endorsements of the foundation than liberal sources. This effect was similar to Study 1 in which the largest effect size was observed for *authority/respect*. As noted before, the effect found in Study 1 was in the opposite direction as what was hypothesized. Thus, it is difficult to draw comparisons between the two studies despite the similar pattern for effect size. Owing to a lack of similar effects for either Study 1 or the Kavanaugh topic, there is doubt as to whether or not a practical or generalized effect exists for *authority/respect*.

Based on the weighted percent values for the five foundations applied to both topics, MFD words seem to make up little of the article text. A similar pattern was observed for the results in Study 1. As in Study 1, the percentages and means seem to indicate a generally positive endorsement of all five moral foundations across both political leanings.

```{r exp2_gs_calc, include = F, echo = F}
#MFD, mean, sd, mean, sd, t, p, d
tableprint_gs = matrix(NA, ncol = 9, nrow = 5)
colnames(tableprint_gs) = c("Foundation", "M_C", "SD_C", "M_L", "SD_L", "t", "p", "d", "ICC")

#calculate d
#harm
harm_d_gs = d.ind.t(m1 = mean(harm_final_temp_gs$MFDweight[harm_final_temp_gs$lean == "Conservative"], na.rm = T),
                 m2 = mean(harm_final_temp_gs$MFDweight[harm_final_temp_gs$lean == "Liberal"], na.rm = T),
                 sd1 = sd(harm_final_temp_gs$MFDweight[harm_final_temp_gs$lean == "Conservative"], na.rm = T),
                 sd2 = sd(harm_final_temp_gs$MFDweight[harm_final_temp_gs$lean == "Liberal"], na.rm = T),
                 n1 = length(harm_final_temp_gs$MFDweight[harm_final_temp_gs$lean == "Conservative"]),
                 n2 = length(harm_final_temp_gs$MFDweight[harm_final_temp_gs$lean == "Liberal"]),
                 a = .05)

#fair
fair_d_gs = d.ind.t(m1 = mean(fair_final_temp_gs$MFDweight[fair_final_temp_gs$lean == "Conservative"], na.rm = T),
                 m2 = mean(fair_final_temp_gs$MFDweight[fair_final_temp_gs$lean == "Liberal"], na.rm = T),
                 sd1 = sd(fair_final_temp_gs$MFDweight[fair_final_temp_gs$lean == "Conservative"], na.rm = T),
                 sd2 = sd(fair_final_temp_gs$MFDweight[fair_final_temp_gs$lean == "Liberal"], na.rm = T),
                 n1 = length(fair_final_temp_gs$MFDweight[fair_final_temp_gs$lean == "Conservative"]),
                 n2 = length(fair_final_temp_gs$MFDweight[fair_final_temp_gs$lean == "Liberal"]),
                 a = .05)

#ingroup
ingroup_d_gs = d.ind.t(m1 = mean(ingroup_final_temp_gs$MFDweight[ingroup_final_temp_gs$lean == "Conservative"], na.rm = T),
                 m2 = mean(ingroup_final_temp_gs$MFDweight[ingroup_final_temp_gs$lean == "Liberal"], na.rm = T),
                 sd1 = sd(ingroup_final_temp_gs$MFDweight[ingroup_final_temp_gs$lean == "Conservative"], na.rm = T),
                 sd2 = sd(ingroup_final_temp_gs$MFDweight[ingroup_final_temp_gs$lean == "Liberal"], na.rm = T),
                 n1 = length(ingroup_final_temp_gs$MFDweight[ingroup_final_temp_gs$lean == "Conservative"]),
                 n2 = length(ingroup_final_temp_gs$MFDweight[ingroup_final_temp_gs$lean == "Liberal"]),
                 a = .05)

#authority
authority_d_gs = d.ind.t(m1 = mean(authority_final_temp_gs$MFDweight[authority_final_temp_gs$lean == "Conservative"], na.rm = T),
                 m2 = mean(authority_final_temp_gs$MFDweight[authority_final_temp_gs$lean == "Liberal"], na.rm = T),
                 sd1 = sd(authority_final_temp_gs$MFDweight[authority_final_temp_gs$lean == "Conservative"], na.rm = T),
                 sd2 = sd(authority_final_temp_gs$MFDweight[authority_final_temp_gs$lean == "Liberal"], na.rm = T),
                 n1 = length(authority_final_temp_gs$MFDweight[authority_final_temp_gs$lean == "Conservative"]),
                 n2 = length(authority_final_temp_gs$MFDweight[authority_final_temp_gs$lean == "Liberal"]),
                 a = .05)

#purity
purity_d_gs = d.ind.t(m1 = mean(purity_final_temp_gs$MFDweight[purity_final_temp_gs$lean == "Conservative"], na.rm = T),
                 m2 = mean(purity_final_temp_gs$MFDweight[purity_final_temp_gs$lean == "Liberal"], na.rm = T),
                 sd1 = sd(purity_final_temp_gs$MFDweight[purity_final_temp_gs$lean == "Conservative"], na.rm = T),
                 sd2 = sd(purity_final_temp_gs$MFDweight[purity_final_temp_gs$lean == "Liberal"], na.rm = T),
                 n1 = length(purity_final_temp_gs$MFDweight[purity_final_temp_gs$lean == "Conservative"]),
                 n2 = length(purity_final_temp_gs$MFDweight[purity_final_temp_gs$lean == "Liberal"]),
                 a = .05)

#put in the numbers
tableprint_gs[1, ] = c("Harm/Care", harm_d_gs$M1, harm_d_gs$sd1, harm_d_gs$M2, harm_d_gs$sd1,
                    summary(harm_model_gs)$tTable[2,4], summary(harm_model_gs)$tTable[2,5],
                    harm_d_gs$d, icc(harm_icc_gs)$ICC_unadjusted)
tableprint_gs[2, ] = c("Fairness/Reciprocity", fair_d_gs$M1, fair_d_gs$sd1, fair_d_gs$M2, fair_d_gs$sd1,
                    summary(fair_model_gs)$tTable[2,4], summary(fair_model_gs)$tTable[2,5],
                    fair_d_gs$d, icc(fair_icc_gs)$ICC_unadjusted)
tableprint_gs[3, ] = c("Ingroup/Loyalty", ingroup_d_gs$M1, ingroup_d_gs$sd1, ingroup_d_gs$M2, ingroup_d_gs$sd1,
                    summary(ingroup_model_gs)$tTable[2,4], summary(ingroup_model_gs)$tTable[2,5],
                    ingroup_d_gs$d, icc(ingroup_icc_gs)$ICC_unadjusted)
tableprint_gs[4, ] = c("Authority/Respect", authority_d_gs$M1, authority_d_gs$sd1, authority_d_gs$M2, authority_d_gs$sd1,
                    summary(authority_model_gs)$tTable[2,4], summary(authority_model_gs)$tTable[2,5],
                    authority_d_gs$d, icc(authority_icc_gs)$ICC_unadjusted)
tableprint_gs[5, ] = c("Purity/Sanctity", purity_d_gs$M1, purity_d_gs$sd1, purity_d_gs$M2, purity_d_gs$sd1,
                    summary(purity_model_gs)$tTable[2,4], summary(purity_model_gs)$tTable[2,5],
                    purity_d_gs$d, icc(purity_icc_gs)$ICC_unadjusted)

tableprint_gs[ , c(2:6, 8)] = printnum(as.numeric(tableprint_gs[ , c(2:6, 8)]), big.mark = "")
tableprint_gs[ , 7] = printp(as.numeric(tableprint_gs[ , 7]))
tableprint_gs[ , 9] = printp(as.numeric(tableprint_gs[ , 9]))
```

```{r exp2-tablegs, results = 'asis', echo = F}
apa_table(as.data.frame(tableprint_gs),
          note = "For mean and standard deviation values, 'C' and 'L' refer to 'conservative' and 'liberal,' respectively",
          caption = "Government Shutdown Results - Multilevel Model",
          col.names = c("Foundation", "$M_C$", "$SD_C$", "$M_L$", "$SD_L$", "$t$", "$p$", "$d$", "ICC"),
          format = "latex",
          escape = F,
          align = c("l", rep("c", 7)),
          font_size = 'footnotesize',
          placement = "h"
          )
```

```{r conference-pic_kav, eval = F, include = F}
library(ggplot2)
library(reshape)

cleanup = theme(panel.grid.major = element_blank(),
                panel.grid.minor = element_blank(),
                panel.background = element_blank(),
                axis.line.x = element_line(color = "black"),
                axis.line.y = element_line(color = "black"),
                legend.key = element_rect(fill = "white"),
                text = element_text(size = 10))

graphdata_kav = as.data.frame(tableprint_kav)
graphlong_kav = melt(graphdata_kav[ , c(1,2,4)],
                 id = "Foundation")
graphlong2_kav = melt(graphdata_kav[ , c(1, 3,5)],
                  id = "Foundation",
                  measured = c("SD_C", "SD_L"))
graphlong_kav$sd = graphlong2_kav$value
graphlong_kav$lower = as.numeric(as.character(graphlong_kav$value)) - 2*as.numeric(as.character(graphlong_kav$sd))
graphlong_kav$upper = as.numeric(as.character(graphlong_kav$value)) + 2*as.numeric(as.character(graphlong_kav$sd))

graphlong_kav$value = as.numeric(as.character(graphlong_kav$value))

graph_data_kav = ggplot(graphlong_kav, aes(Foundation, value, color = variable)) +
  geom_point(position = position_dodge(width = 0.90)) +
  geom_errorbar(aes(ymin = lower, ymax = upper),
                position = position_dodge(width = 0.90),
                width = .2) +
  cleanup +
  ylab("Mean Weighted Valence") +
  scale_color_manual(values = c("red", "blue"),
                       labels = c("Conservative", "Liberal"),
                       name = "Party") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  geom_hline(yintercept = 0, linetype = 1, color = "black")

#tiff(filename = "exp2_graph_kav.tiff", res = 300, width = 4,
#     height = 3, units = 'in', compression = "lzw")
#plot(graph_data_kav)
#dev.off()
```

```{r conference-pic_gs, eval = F, include = F}
graphdata_gs = as.data.frame(tableprint_gs)
graphlong_gs = melt(graphdata_gs[ , c(1,2,4)],
                 id = "Foundation")
graphlong2_gs = melt(graphdata_gs[ , c(1, 3,5)],
                  id = "Foundation",
                  measured = c("SD_C", "SD_L"))
graphlong_gs$sd = graphlong2_gs$value
graphlong_gs$lower = as.numeric(as.character(graphlong_gs$value)) - 2*as.numeric(as.character(graphlong_gs$sd))
graphlong_gs$upper = as.numeric(as.character(graphlong_gs$value)) + 2*as.numeric(as.character(graphlong_gs$sd))

graphlong_gs$value = as.numeric(as.character(graphlong_gs$value))

graph_data_gs = ggplot(graphlong_gs, aes(Foundation, value, color = variable)) +
  geom_point(position = position_dodge(width = 0.90)) +
  geom_errorbar(aes(ymin = lower, ymax = upper),
                position = position_dodge(width = 0.90),
                width = .2) +
  cleanup +
  ylab("Mean Weighted Valence") +
  scale_color_manual(values = c("red", "blue"),
                       labels = c("Conservative", "Liberal"),
                       name = "Party") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  geom_hline(yintercept = 0, linetype = 1, color = "black")

#tiff(filename = "exp2_graph_gs.tiff", res = 300, width = 4,
#     height = 3, units = 'in', compression = "lzw")
#plot(graph_data_gs)
#dev.off()
```

# Study 3

Results from Study 1 and 2 indicated that no differences were found in the MFD for Liberal and Conservative sources using the traditional dictionary and valence weighting. The MFD was developed in conjunction with the Moral Foundations Questionnaire (MFQ), using the same five latent areas. In this set of studies, we examined the MFD and MFQ within the same study. The first two sub-studies were used to develop a (potentially) larger dictionary for the MFD and collect data on both scales. The last sub-study examined the MFD and MFQ using multi-trait multi-method analysis [CITE WIDAMEN AND BYRNE].

DESCRIBE MTMM

## Study 3.1

In this study, participants were given a word association task elicit additional semantically related word forms for each moral foundation. This data was used to expand the MFD for each latent area to determine if these additional words could improve scores and test measurement relation to the MFQ in Study 3.3. 

### Participants

```{r demos-mtmm-study-3.1, include = FALSE}
exp1data <- import("exp3_data/study3.1_fixed_associations.csv")

##clear out completely columns we don't need
crapcolumns <- c(1, 2, 3, 5:14)
finalsample <- exp1data[ , -crapcolumns]

##accuracy
summary(finalsample) #Check Q15_1 and Q23 for in-range scores -WP
finalsample$Q23 <- factor(finalsample$Q23,
                         levels = 1:3,
                         labels = c("Democrat", "Republican", "Independent"))

#missing 
#by people 
missing_demo1 <- apply(finalsample, 1, percentmiss) 
table(missing_demo1)

replacepeople1 <- subset(finalsample, missing_demo1 <= 5)  #we are using 5%, yes? 
#by column 
apply(replacepeople1, 2, percentmiss) 
#missing data is on the politics scale which we don't want to replace 

finalsample <- replacepeople1
summary(finalsample)

party <- table(finalsample$Q23)
##be sure to exclude the writing columns columns 2:6 
#I take it I should also remove column 1: ResponseId? 
##outliers
mahal1 <- mahalanobis(finalsample[ , -c(1:6,22,23)], 
                    colMeans(finalsample[ , -c(1:6,22,23)], na.rm = TRUE),
                    cov(finalsample[ , -c(1:6,22,23)], use="pairwise.complete.obs"))
#mahal1
cutoff1 <- qchisq(1 - .001,ncol(finalsample[ , -c(1:6,22,23)]))
cutoff1
ncol(finalsample[ , -c(1:6,22,23)])
summary(mahal1 < cutoff1) #Hmm what to do w/ NAs?? -WP
noout1 <- subset(finalsample, mahal1 < cutoff1)

##assumptions
#correlations for MFQ
correlations1 <- cor(noout1[,-c(1:6,22,23)], use="pairwise.complete.obs")
correlations1
symnum(correlations1)

#making the random stuff
random1 <- rchisq(nrow(noout1), 7)
fake1 <- lm(random1~., data=noout1[ , -c(1:6)])
#normal
standardized1 <- rstudent(fake1)
hist(standardized1, breaks=15) 

#linear
{qqnorm(standardized1) 
abline(0,1)}
#homog + s
fitvalues1 <- scale(fake1$fitted.values)
{plot(fitvalues1, standardized1) 
abline(0,0)
abline(v = 0)}

####create the MFQ subscales####
noout1$harmMFQ <- apply(noout1[ , 7:9], 1, sum)
noout1$fairMFQ <- apply(noout1[ , 10:12], 1, sum)
noout1$ingroupMFQ <- apply(noout1[ , 13:15], 1, sum)
noout1$authorityMFQ <- apply(noout1[ , 16:18], 1, sum)
noout1$purityMFQ <- apply(noout1[ , 19:21], 1, sum)
```

`r nrow(exp1data)` participants were collected from a large Midwestern university. Participants were given course credit for their introductory psychology course for completing the study. `r nrow(finalsample)` participants had less than five percent missing data and were retained for analyses. Participants were asked to denote their political party, and `r printnum(party["Democrat"]/sum(party)*100,digits = 1)`% indicated they were Democrats, `r printnum(party["Republican"]/sum(party)*100,digits = 1)`% were Republican, and `r printnum(party["Independent"]/sum(party)*100,digits = 1)`% indicated they were Independent.

### Materials and Procedure

A complete example of the survey can be found online at OSF LINK. First, participants were given a description of associative memory as the relation between words that comes about through many pairings in writing and speech. Next, the free association task, similar to that used in @Nelson2004 and @SWOW_FIX_THIS was described to the participants as listing the "first word that pops into mind". The participants were then given three example free association cues, *lost*, *old*, and *article*. For each cue, participants were asked to write all the words that come to mind. To elicit free association to the moral foundation areas, participants were given the following instructions:

"Moral Foundations Theory states that when making moral judgments/decisions, the concerns people have can be divided into five categories. Below are labels of each of these five categories. You will then be asked to list words you think are associated with each of the labels."

Each of the foundation pairs were listed together (i.e., *harm/care*, *fairness/cheating*) with a space for participants to list their free association concepts. After the free association task, participants were then given the 15-items from the moral relevance section of the MFQ as described in the introduction. Last, participants were asked to denote their political orientation from 1 *conservative* to 10 *liberal*, as well as which political party they associated with: Democrat, Republican, and Independent. The survey was delivered through Qualtrics, and participants were recruited through the online participant management system for the university (SONA). Each participant signed an online consent form at the beginning of the study and was given participation credit at the end of the study. 

### Results 

All data was screening for inaccurate responses, as well as missing data, as described in the participant section. Two participants were missing data on the political orientation scale after excluding participants with more than five percent missing data, and this data was excluded pairwise. The MFQ data was screened for multivariate outliers with Mahalanobis distance as described in @Tabachnick2012, and fourteen outliers were found using $\chi^2_{p < .001}$(`r ncol(finalsample[ , -c(1:6,22,23)])`) = `r cutoff1`. These participants were excluded from further analyses, representing `r nrow(noout1)` final participants. The final data was screened for assumptions of normality, linearity, homogeneity and homoscedasticity, and these were found to be satisfactory. 

The sum of each moral foundation area was calculated in order to determine which words were linked to their respective moral foundation. The average scores were: harm (*M* = `r printnum(mean(noout1$harmMFQ))`, *SD* = `r printnum(sd(noout1$harmMFQ))`), fairness  (*M* = `r printnum(mean(noout1$fairMFQ))`, *SD* = `r printnum(sd(noout1$fairMFQ))`), ingroup (*M* = `r printnum(mean(noout1$ingroupMFQ))`, *SD* = `r printnum(sd(noout1$ingroupMFQ))`), authority  (*M* = `r printnum(mean(noout1$authorityMFQ))`, *SD* = `r printnum(sd(noout1$authorityMFQ))`), and purity (*M* = `r printnum(mean(noout1$purityMFQ))`, *SD* = `r printnum(sd(noout1$purityMFQ))`). Participants free association responses were processed using the *tm* library [@CITE] after spell checking. Each set of answers was cleaned for punctuation, English stop words (e.g., *the*, *an*, *of*) were removed, and each word was stemmed using the English library in *tm*. We did not combine related words in this section (i.e., *injure* and *injury*, which have different stems *injur* and *injuri*) to allow for maximum coverage of different word forms present in the dictionary. Additionally, with the use of automated stemmers like that present in the *tm* library, leaving both word forms in the dictionary would capture more of the concepts present in future analyses with a different corpus without the requirement on the experimenter to manuall recode all word forms. Frequency counts of the stemmed words were tabulated and only words mentioned with at least one percent frequency were used in the subsequent analyses. The complete set of word frequencies for each foundation can be found in our supplemental materials. 

```{r harm-analysis-3.1, include = FALSE}
#q27 through 34 are the writing columns
noout1$Q27 = as.character(noout1$Q27)

##stem the data

for (i in 1:nrow(noout1)) {
  noout1$Q27[i] = paste(unlist(
    text_tokens(noout1$Q27[i], stemmer = "en")), collapse = " ")
}

##create a corpus
harm_corpus = Corpus(VectorSource(noout1$Q27))
harm_TDM = as.matrix(TermDocumentMatrix(harm_corpus,
                              control = list(removePunctuation = TRUE,
                                             stopwords = TRUE)))

##view the most frequent words
harm_freq = data.frame(Word = rownames(harm_TDM),
                       Freq = rowSums(harm_TDM),
                       row.names = NULL)
harm_freq$Word = as.character(harm_freq$Word)
harm_freq$percent = harm_freq$Freq/nrow(noout1) *100

write.csv(harm_freq, "exp1_harm_freq.csv", row.names = F)

##subset out to only words with 1% mentions
harm_words = harm_freq$Word[harm_freq$percent >=1]
##turn sideways to add to dataset
harm_TDM = as.data.frame(t(harm_TDM))
harm_TDM = harm_TDM[ , harm_words]

##final dataset for harm
harm_final = cbind(noout1[ , c("ResponseId", "Q15_1", "Q23", "harmMFQ")],
                   harm_TDM)

harm_cor = apply(harm_final[ , 5:ncol(harm_final)], 2, function (x) { cor(x, harm_final$harmMFQ)})

harmcut = mean(harm_cor) + 2*sd(harm_cor)
harm_words_reduce = names(harm_cor[abs(harm_cor) >= harmcut])
```

```{r fair-analysi-3.1, include = FALSE}
#q27 through 34 are the writing columns
noout1$Q29 = as.character(noout1$Q29)

##stem the data
for (i in 1:nrow(noout1)) {
  noout1$Q29[i] = paste(unlist(
    text_tokens(noout1$Q29[i], stemmer = "en")), collapse = " ")
}

##create a corpus
fair_corpus = Corpus(VectorSource(noout1$Q29))
fair_TDM = as.matrix(TermDocumentMatrix(fair_corpus,
                              control = list(removePunctuation = TRUE,
                                             stopwords = TRUE)))

##view the most frequent words
fair_freq = data.frame(Word = rownames(fair_TDM),
                       Freq = rowSums(fair_TDM),
                       row.names = NULL)
fair_freq$Word = as.character(fair_freq$Word)
fair_freq$percent = fair_freq$Freq/nrow(noout1) *100

write.csv(fair_freq, "exp1_fair_freq.csv", row.names = F)

##subset out to only words with 1% mentions
fair_words = fair_freq$Word[fair_freq$percent >=1]
##turn sideways to add to dataset
fair_TDM = as.data.frame(t(fair_TDM))
fair_TDM = fair_TDM[ , fair_words]

##final dataset for fair
fair_final = cbind(noout1[ , c("ResponseId", "Q15_1", "Q23", "fairMFQ")],
                   fair_TDM)

fair_cor = apply(fair_final[ , 5:ncol(fair_final)], 2, function (x) { cor(x, fair_final$fairMFQ)})

faircut = mean(fair_cor) + 2*sd(fair_cor)
fair_words_reduce = names(fair_cor[abs(fair_cor) >= faircut])
```

```{r ingroup-analysis-3.1, include=FALSE}
#q27 through 34 are the writing columns
noout1$Q30 = as.character(noout1$Q30)

##stem the data
for (i in 1:nrow(noout1)) {
  noout1$Q30[i] = paste(unlist(
    text_tokens(noout1$Q30[i], stemmer = "en")), collapse = " ")
}

##create a corpus
ingroup_corpus = Corpus(VectorSource(noout1$Q30))
ingroup_TDM = as.matrix(TermDocumentMatrix(ingroup_corpus,
                              control = list(removePunctuation = TRUE,
                                             stopwords = TRUE)))

##view the most frequent words
ingroup_freq = data.frame(Word = rownames(ingroup_TDM),
                       Freq = rowSums(ingroup_TDM),
                       row.names = NULL)
ingroup_freq$Word = as.character(ingroup_freq$Word)
ingroup_freq$percent = ingroup_freq$Freq/nrow(noout1) *100

write.csv(ingroup_freq, "exp1_ingroup_freq.csv", row.names = F)

##subset out to only words with 1% mentions
ingroup_words = ingroup_freq$Word[ingroup_freq$percent >=1]
##turn sideways to add to dataset
ingroup_TDM = as.data.frame(t(ingroup_TDM))
ingroup_TDM = ingroup_TDM[ , ingroup_words]

##final dataset for ingroup
ingroup_final = cbind(noout1[ , c("ResponseId", "Q15_1", "Q23", "ingroupMFQ")],
                   ingroup_TDM)

ingroup_cor = apply(ingroup_final[ , 5:ncol(ingroup_final)], 2, function (x) { cor(x, ingroup_final$ingroupMFQ)})

ingroupcut = mean(ingroup_cor) + 2*sd(ingroup_cor)
ingroup_words_reduce = names(ingroup_cor[abs(ingroup_cor) >= ingroupcut])
```

```{r authority-analysis-3.1, include = FALSE}
#q27 through 34 are the writing columns
noout1$Q32 = as.character(noout1$Q32)

##stem the data
for (i in 1:nrow(noout1)) {
  noout1$Q32[i] = paste(unlist(
    text_tokens(noout1$Q32[i], stemmer = "en")), collapse = " ")
}

##create a corpus
authority_corpus = Corpus(VectorSource(noout1$Q32))
authority_TDM = as.matrix(TermDocumentMatrix(authority_corpus,
                              control = list(removePunctuation = TRUE,
                                             stopwords = TRUE)))

##view the most frequent words
authority_freq = data.frame(Word = rownames(authority_TDM),
                       Freq = rowSums(authority_TDM),
                       row.names = NULL)
authority_freq$Word = as.character(authority_freq$Word)
authority_freq$percent = authority_freq$Freq/nrow(noout1) *100

write.csv(authority_freq, "exp1_authority_freq.csv", row.names = F)

##subset out to only words with 1% mentions
authority_words = authority_freq$Word[authority_freq$percent >=1]
##turn sideways to add to dataset
authority_TDM = as.data.frame(t(authority_TDM))
authority_TDM = authority_TDM[ , authority_words]

##final dataset for authority
authority_final = cbind(noout1[ , c("ResponseId", "Q15_1", "Q23", "authorityMFQ")],
                   authority_TDM)

authority_cor = apply(authority_final[ , 5:ncol(authority_final)], 2, function (x) { cor(x, authority_final$authorityMFQ)})

authoritycut = mean(authority_cor) + 2*sd(authority_cor)
authority_words_reduce = names(authority_cor[abs(authority_cor) >= authoritycut])
```

```{r purity-analysis-3.1, include = FALSE}
#q27 through 34 are the writing columns
noout1$Q34 = as.character(noout1$Q34)

##stem the data
for (i in 1:nrow(noout1)) {
  noout1$Q34[i] = paste(unlist(
    text_tokens(noout1$Q34[i], stemmer = "en")), collapse = " ")
}

##create a corpus
purity_corpus = Corpus(VectorSource(noout1$Q34))
purity_TDM = as.matrix(TermDocumentMatrix(purity_corpus,
                              control = list(removePunctuation = TRUE,
                                             stopwords = TRUE)))

##view the most frequent words
purity_freq = data.frame(Word = rownames(purity_TDM),
                       Freq = rowSums(purity_TDM),
                       row.names = NULL)
purity_freq$Word = as.character(purity_freq$Word)
purity_freq$percent = purity_freq$Freq/nrow(noout1) *100

write.csv(purity_freq, "exp1_purity_freq.csv", row.names = F)

##subset out to only words with 1% mentions
purity_words = purity_freq$Word[purity_freq$percent >=1]
##turn sideways to add to dataset
purity_TDM = as.data.frame(t(purity_TDM))
purity_TDM = purity_TDM[ , purity_words]

##final dataset for purity
purity_final = cbind(noout1[ , c("ResponseId", "Q15_1", "Q23", "purityMFQ")],
                   purity_TDM)

purity_cor = apply(purity_final[ , 5:ncol(purity_final)], 2, function (x) { cor(x, purity_final$purityMFQ)})

puritycut = mean(purity_cor) + 2*sd(purity_cor)
purity_words_reduce = names(purity_cor[abs(purity_cor) >= puritycut])
```

This procedure generated a large frequency of words for a new dictionary of moral foundations: harm `r length(harm_words)`, fairness `r length(fair_words)`, ingroup `r length(ingroup_words)`, authority `r length(authority_words)`, and purity `r length(purity_words)`. These concepts were included in the full dictionary used for Experiment 3. We additionally created a reduced dictionary that included only concepts correlated with their respective moral foundations scores. Correlations between word frequency and the sum of the MFQ were calculated for each foundation and set of concepts. Words were included in the reduced dictionary if their correlation was two standard deviations away from the mean correlation for that foundation. The reduced dataset included the following number of words for each foundation: harm `r length(harm_words_reduce)`, fairness `r length(fair_words_reduce)`, ingroup `r length(ingroup_words_reduce)`, authority `r length(authority_words_reduce)`, and purity `r length(purity_words_reduce)`.

## Study 3.2

this section is about the writing 

### Participants

```{r demos-mtmm-study-3.2, include=FALSE, warning=FALSE}
sample1 = read.csv("fixed_sample 1.csv", stringsAsFactors = F)
sample2 = read.csv("fixed_sample 2.csv", stringsAsFactors = F)

##merge files together
fullsample = merge(sample1, sample2, all = TRUE)

##merge together the writing samples
#q24, q25, q26, q7 
fullsample$writing = apply(fullsample[, c("Q24", "Q25", "Q26", "Q7")], 
                           1, function(x) toString(na.omit(x)))

##clear out completely columns we don't need
crapcolumns = c(1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 51:61)
finalsample = fullsample[ , -crapcolumns]

##accuracy
summary(finalsample[ , 2:40])

finalsample$Q10 = factor(finalsample$Q10,
                         levels = 1:2,
                         labels = c("Man", "Woman"))
finalsample$Q11 = as.numeric(finalsample$Q11)
finalsample$Q12 = factor(finalsample$Q12,
                         levels = 1:7,
                         labels = c("White", "Black", 
                                    "Hispanic", "Asian",
                                    "Native American", 
                                    "Mixed", "Other"))

gender = table(finalsample$Q10)/sum(table(finalsample$Q10))*100
race = table(finalsample$Q12)/sum(table(finalsample$Q12))*100

write.csv(finalsample, 'exp2_finalsample.csv', row.names = FALSE)
newMFD = read.csv('exp2_finalsample_newMFD.csv')
colnames(newMFD)[1:41] = colnames(finalsample)[1:41]
newMFD = newMFD[,c(1,42:55)]
finalsample = merge(finalsample, newMFD, by="ResponseId")

##take out the people with less than 25 words
##use the ngram library to examine the data
##preprocess only works on one string at a time, so going to use a loop go through all the rows (apply won't work because we only want to work on one column)

for (i in 1:nrow(finalsample)) {
  
  finalsample$writing[i] = preprocess(finalsample$writing[i], case="lower", remove.punct=TRUE)
  finalsample$wordcount[i] = string.summary(finalsample$writing[i])$words
  
}

#remove small words people
finalwords = subset(finalsample, wordcount >=25)

##check out missing data
#missing by row
missing = apply(finalwords, 1, percentmiss)
table(missing)
goodrows = subset(finalwords, missing <= 5)

#missing by column
apply(goodrows, 2, percentmiss)

##don't fill in Q10 to the end, be sure to merge these back together
goodcolumns = goodrows[ , -c(32:42)]
badcolumns = goodrows[ , c(32:42)]

#fill in missing data points
library(mice)
tempnomiss = mice(goodcolumns)
nomiss = complete(tempnomiss, 1)
summary(nomiss)
#merge
allcolumns = cbind(nomiss, badcolumns) 
summary(allcolumns)

##outliers
mahal2 = mahalanobis(allcolumns[ , -c(1,46:56)], 
                    colMeans(allcolumns[ , -c(1,46:56)], na.rm = TRUE),
                    cov(allcolumns[ , -c(1,46:56)], use="pairwise.complete.obs"))
#mahal2
cutoff2 = qchisq(1 - .001,ncol(allcolumns[ , -c(1,46:56)]))
cutoff2
ncol(allcolumns[ , -c(1,46:56)])
summary(mahal2 < cutoff2) #Hmm what to do w/ NAs?? 
noout2 = subset(allcolumns, mahal2 < cutoff2)

##assumptions on the questions i.e., not Q10 to the end
#correlations
correlations2 = cor(noout2[,-c(1,46:56)], use="pairwise.complete.obs")
#correlations2
symnum(correlations2)

#the random stuff
random2 = rchisq(nrow(noout2), 7)
fake2 = lm(random2~., data=noout2[ , -c(1,46:56)])

#normal
standardized2 = rstudent(fake2)
hist(standardized2, breaks=15)

#linear
{qqnorm(standardized2)   
abline(0,1)}    

#homog + s
fitvalues2 = scale(fake2$fitted.values)
{plot(fitvalues2, standardized2) 
abline(0,0)
abline(v = 0)}

####create the MFQ subscales####
noout2$harmMFQ = apply(noout2[ , 2:4], 1, sum)
noout2$fairMFQ = apply(noout2[ , 5:7], 1, sum)
noout2$ingroupMFQ = apply(noout2[ , 8:10], 1, sum)
noout2$authorityMFQ = apply(noout2[ , 11:13], 1, sum)
noout2$purityMFQ = apply(noout2[ , 14:16], 1, sum)
```

Participants were recruited in two waves as part of a larger investigation on priming political and religious attitudes [@Jordan]. Participants were recruited via an online research system (SONA) and were given course credit for their participation. `r nrow(finalsample)` participants were included in the this study. The study was mostly women (`r printnum(gender["Woman"], digits = 1)`%) and White (`r printnum(race["White"], digits = 1)`%) participants with a mix of minority participants: Black (`r printnum(race["Black"], digits = 1)`%), (`r printnum(race["Hispanic"], digits = 1)`%), (`r printnum(race["Asian"], digits = 1)`%), Native American (`r printnum(race["Native American"], digits = 1)`%), Mixed (`r printnum(race["Mixed"], digits = 1)`%) and Other (`r printnum(race["Other"], digits = 1)`%). The average listed age was `r printnum(mean(finalsample$Q11, na.rm = T))` (*SD* = `r printnum(sd(finalsample$Q11, na.rm = T))`).

###	Materials and Procedure

Data was again collected via Qualtrics. Four fake new stories were presented to participants, which were roughly 400 words each. First, all news stories included a few sentences describing the use of chemical weapons in the Syrian civil war. The news stories were manipulated with political (Republican v. Democrat) and religious (religious v. not) quotes in a 2 x 2 design. News stories can be found in the online materials. Participants also completed the 30-item version of the MFQ as described in the introduction. In addition to basic demographics (gender, age), participant political orientation was assessed with the same scale described in Experiment 1. 

After consenting to participate in the study, participants were randomly shown one of the four new articles about Syria's use of chemical weapons. Participants were then asked to write for 5-10 minutes about their reaction to Syria's use of chemical weapons and the needed response from the United States. The second wave of data collection included different writing prompts designed to capture more of the moral foundation areas in their writing. The following writing prompt was used, "Please write about your attitudes on abortion (or same-sex marriage or environmentalism) as well as your reason for this stance." The three prompts were chosen to create a more varied word set by using topics that should elicit words from each moral foundations category by soliciting a moral response. In each wave of data collection (Syria prompts, moral prompts) the prompt material was randomized between participants. Participants then completed the MFQ, demographics, and the political orientation scale. 

### Results 

Participant data was first spell checked and screening for inaccurate responses. Participants who did not write more than fifty words in response to a given prompt were excluded (*n* = `r nrow(finalsample) - nrow(finalwords)`). One missing datapoint was estimated using the *mice* library from *R* [@CITE] for a missing MFQ question, and all other missing data was present in the demographics sections, which were not filled in. The MFQ data were screened for outliers using Mahalanobis distance, and fourteen outliers were found at $\chi^2_{p<.001}$(`r ncol(allcolumns[ , -c(1,32:42)])`) = `r printnum(cutoff2)`. These data were excluded leading to a final sample size of `r nrow(noout2)`. Data were screened for assumptions described in Experiment 1 and were found to be satisfactory. 

```{r writing-analysis-3.2, include=FALSE}
##stem the data
for (i in 1:nrow(noout2)) {
  noout2$writing2[i] = paste(unlist(
    text_tokens(noout2$writing[i], stemmer = "en")), collapse = " ")
}

##create a corpus
overall_corpus = Corpus(VectorSource(noout2$writing2))
overall_TDM = as.matrix(TermDocumentMatrix(overall_corpus,
                              control = list(removePunctuation = TRUE,
                                             stopwords = TRUE)))

##view the most frequent words
overall_freq = data.frame(Word = rownames(overall_TDM),
                          Freq = rowSums(overall_TDM),
                          row.names = NULL)
overall_freq$Word = as.character(overall_freq$Word)
overall_freq$percent = overall_freq$Freq/nrow(noout2)*100

write.csv(overall_freq, "exp2_freq.csv", row.names = F)

##subset out to only words with 1% mentions
##this goes over 100% but mostly want to subset out things that were only mentioned
##a few times by participants
all_words = overall_freq$Word[overall_freq$percent >=1]

##turn sideways to add to dataset
overall_TDM = as.data.frame(t(overall_TDM))
overall_TDM = overall_TDM[ , all_words]

##final dataset
overall_final = cbind(noout2[ , c("ResponseId", "harmMFQ", "fairMFQ",
                                  "authorityMFQ", "purityMFQ","ingroupMFQ")],
                   overall_TDM)
```

```{r mfq-cor-3.2, include = FALSE}
##harm
harm_cor = apply(overall_final[ , 7:ncol(overall_final)], 2, function (x) { cor(x, overall_final$harmMFQ)})

harmcut = mean(harm_cor) + 2*sd(harm_cor)
harm_words_reduce_exp2 = names(harm_cor[abs(harm_cor) >= harmcut])

##fair
fair_cor = apply(overall_final[ , 7:ncol(overall_final)], 2, function (x) { cor(x, overall_final$fairMFQ)})

faircut = mean(fair_cor) + 2*sd(fair_cor)
fair_words_reduce_exp2 = names(fair_cor[abs(fair_cor) >= faircut])

##purity
purity_cor = apply(overall_final[ , 7:ncol(overall_final)], 2, function (x) { cor(x, overall_final$purityMFQ)})

puritycut = mean(purity_cor) + 2*sd(purity_cor)
purity_words_reduce_exp2 = names(purity_cor[abs(purity_cor) >= puritycut])

##authority
authority_cor = apply(overall_final[ , 7:ncol(overall_final)], 2, function (x) { cor(x, overall_final$authorityMFQ)})

authoritycut = mean(authority_cor) + 2*sd(authority_cor)
authority_words_reduce_exp2 = names(authority_cor[abs(authority_cor) >= authoritycut])

##ingroup
ingroup_cor = apply(overall_final[ , 7:ncol(overall_final)], 2, function (x) { cor(x, overall_final$ingroupMFQ)})

ingroupcut = mean(ingroup_cor) + 2*sd(ingroup_cor)
ingroup_words_reduce_exp2 = names(ingroup_cor[abs(ingroup_cor) >= ingroupcut])

##print out words list to look at for further analysis
#write.csv(harm_words_reduce_exp2, "words/harm_exp2.csv", row.names = F)
#write.csv(fair_words_reduce_exp2, "words/fair_exp2.csv", row.names = F)
#write.csv(authority_words_reduce_exp2, "words/authority_exp2.csv", row.names = F)
#write.csv(purity_words_reduce_exp2, "words/purity_exp2.csv", row.names = F)
#write.csv(ingroup_words_reduce_exp2, "words/ingroup_exp2.csv", row.names = F)
```

In the first study, only free association responses were collected, but in this study, full writing samples were collected. Therefore, we expected many of the words listed to be part of creating a cohesive discourse, rather than only related to the moral foundation targeted. To find only the most related words, the correlation between word frequency and moral foundation was calculated and words with correlations greater than two standard deviations outside the mean were selected for the dictionary analysis in Experiment 3.  The sum of each moral foundation area was calculated in order to determine which words were linked to their respective moral foundation. The average scores were: harm (*M* = `r printnum(mean(noout2$harmMFQ))`, *SD* = `r printnum(sd(noout2$harmMFQ))`), fairness  (*M* = `r printnum(mean(noout2$fairMFQ))`, *SD* = `r printnum(sd(noout2$fairMFQ))`), ingroup (*M* = `r printnum(mean(noout2$ingroupMFQ))`, *SD* = `r printnum(sd(noout2$ingroupMFQ))`), authority  (*M* = `r printnum(mean(noout2$authorityMFQ))`, *SD* = `r printnum(sd(noout2$authorityMFQ))`), and purity (*M* = `r printnum(mean(noout2$purityMFQ))`, *SD* = `r printnum(sd(noout2$purityMFQ))`). 

```{r compare-ratings-3.2, include = FALSE}
authority_erin = read.csv("words/authority_exp2 erin.csv", stringsAsFactors = F)
authority_will = read.csv("words/authority_exp2 will.csv", stringsAsFactors = F)
authority_erin$x[authority_erin$use != authority_will$use]

authority_words_reduce_exp2 = authority_words_reduce_exp2[authority_words_reduce_exp2 %in% authority_will$x[authority_will$use == 1]]

fair_erin = read.csv("words/fair_exp2 erin.csv", stringsAsFactors = F)
fair_will = read.csv("words/fair_exp2 will.csv", stringsAsFactors = F)
fair_erin$x[fair_erin$use != fair_will$use]
fair_will$use[fair_will$x == "carbon"] = 0
fair_will$use[fair_will$x == "emiss"] = 0
#exclude carbon and emiss due to the prompt

fair_words_reduce_exp2 = fair_words_reduce_exp2[fair_words_reduce_exp2 %in% fair_will$x[fair_will$use == 1]]

purity_erin = read.csv("words/purity_exp2 erin.csv", stringsAsFactors = F)
purity_will = read.csv("words/purity_exp2 will.csv", stringsAsFactors = F)
purity_erin$x[purity_erin$use != purity_will$use]
purity_will$use[purity_will$x == "befor"] = 1
#before include because of "before sex/ruined/etc."

purity_words_reduce_exp2 = purity_words_reduce_exp2[purity_words_reduce_exp2 %in% purity_will$x[purity_will$use == 1]]

ingroup_erin = read.csv("words/ingroup_exp2 erin.csv", stringsAsFactors = F)
ingroup_will = read.csv("words/ingroup_exp2 will.csv", stringsAsFactors = F)
ingroup_erin$x[ingroup_erin$use != ingroup_will$use]
ingroup_will$use[ingroup_will$x == "mean"] = 1
#mean should be included

ingroup_words_reduce_exp2 = ingroup_words_reduce_exp2[ingroup_words_reduce_exp2 %in% ingroup_will$x[ingroup_will$use == 1]]

harm_erin = read.csv("words/harm_exp2 erin.csv", stringsAsFactors = F)
harm_will = read.csv("words/harm_exp2 will.csv", stringsAsFactors = F)
harm_erin$x[harm_erin$use != harm_will$use]
harm_will$use[harm_will$x == "import"] = 1
#import for important 

harm_words_reduce_exp2 = harm_words_reduce_exp2[harm_words_reduce_exp2 %in% harm_will$x[harm_will$use == 1]]
```

This set of words was then coded by two of the authors for relevant words with discussion over coding constituting a tiebreaker. For example, for harm words in this study both *also* and *Syria* appeared as correlated words to the harm foundation. The first word does not meet face validity of correlation with the dictionary, and these type of function words or ambiguous verbs (i.e., *get*, *can*) were usually excluded. The second example is likely because of the writing prompt, and therefore, proper nouns were also excluded. The reduced dataset included the following number of words for each foundation: harm `r length(harm_words_reduce_exp2)`, fairness `r length(fair_words_reduce_exp2)`, ingroup `r length(ingroup_words_reduce_exp2)`, authority `r length(authority_words_reduce_exp2)`, and purity `r length(purity_words_reduce_exp2)`.

## Study 3.3

This part is the mtmm

```{r mtmm-setup, include = FALSE}
##original mfd words
original_mfd = read.csv("original_mfd.csv", stringsAsFactors = F)

##adding forms/conjugations of words to original_mfd
#harm/care
original_mfd[c(27:95),1] = c("abusive","abuser","abused","abusing",
                             "sympathetic","sympathies","damaged",
                             "damaging","attacked","attacking","attacker",
                             "attacks","attackers", "benefits", "benefitted",
                             "benefitting", "cares", "cared", "caring", "crushes",
                             "crushing", "crushed", "dangerous", "defends", "defending",
                             "defended", "detroys", "destroyed", "destroying",
                             "fights", "fought", "fighting", "guards", "guarded",
                             "guarding", "harms", "harmed", "harming", "hurts",
                             "hurting", "kills", "killed", "killing", "preserves",
                             "preserved", "preserving", "protects", "protected",
                             "protecting", "protection", "ruins", "ruined", "ruining",
                             "safely", "safer", "shelters", "sheltered", "sheltering",
                             "spurns", "spurned", "spurning", "stomps", "stomped",
                             "stomping", "suffers", "suffered", "suffering",
                             "violence", "warring")
                             
#fairness/reciprocity
original_mfd[c(20:64),2] = c("balances", "balanced", "balancing","biased",
                             "biases", "discriminates", "discriminated",
                             "discriminating", "discrimination", "equals",
                             "equaled", "equaling", "equates", "equated",
                             "equating", "evens", "evened", "evening",
                             "excludes", "excluded", "excluding", "fairness",
                             "favors", "favored", "favoring", "honesty",
                             "impariality", "justice", "justifies", "justified",
                             "justifying", "prefers", "preferred", "preferring",
                             "prejudices", "prejudiced", "prejudicing", "reasons",
                             "reasoned", "reasoning", "rights", "tolerates",
                             "tolerated", "tolerating", "toleration")

#ingroup/loyalty
original_mfd[c(16:47),3] = c("collects", "collected", "collecting", "collective",
                             "communities", "deceives", "deceived", "deceiving",
                             "deception", "deceptions", "deserts", "deserted",
                             "deserting", "desertion", "families", "fellows",
                             "foreigners", "groups", "grouped", "grouping",
                             "indviduals", "indvidualize", "individualized",
                             "individualizing", "members", "nations", "sides",
                             "togetherness", "traits", "unites", "united", "uniting")

#authority/respect
original_mfd[c(31:112),4] = c("abides", "abided", "abiding", "authorities",
                              "classes", "classed", "classing", "command",
                              "commanded", "commanding", "controls", "controlled",
                              "controlling", "defects", "defected", "defecting",
                              "defers", "deferred", "deferring", "deference",
                              "defies", "defied", "defying", "defiance", "deserts",
                              "deserted", "deserting", "desertion", "duties",
                              "faiths", "fathers", "fathered", "fathering",
                              "honors", "honored", "honoring", "laws", "leads",
                              "leading", "mothers", "mothered", "mothering",
                              "obeys", "obeyed", "obeying", "opposes", "opposed",
                              "opposing", "orders", "ordered", "ordering", "permits",
                              "permitted", "permitting", "positions", "positioned",
                              "positioning", "preserves", "preserved", "preserving",
                              "preservation", "protests", "protested", "protesting",
                              "refuses", "refused", "refusing", "refusal", "respects",
                              "respected", "respecting", "respectful", "reveres",
                              "revered", "revering", "reverence", "serves", "served",
                              "serving", "traditions", "traditional", "traits")

#purity/sanctity
original_mfd[c(21:60),5] = c("abstains", "abstained", "abstaining", "abstinence",
                             "adulteries", "adulterous", "adulterer", "adulterers",
                             "churches", "cleans", "cleaned", "cleaning", "cleanse",
                             "cleanliness", "dirty", "diseases", "diseased", 
                             "disgusts", "disgusted", "disgusting", "grossness",
                             "innocence", "modesty", "preserves", "preserved",
                             "preserving", "preservation", "promiscuity",
                             "promiscuities", "purity", "rights", "ruins", "ruined",
                             "ruining", "sacredness", "sickness", "sicknesses",
                             "sins", "wholeness", "wholesome")

##stem the original mfd
for(i in 1:nrow(original_mfd)) {
  original_mfd$h2[i] = stemDocument(original_mfd$h2[i], language = "english")
  original_mfd$f2[i] = stemDocument(original_mfd$f2[i], language = "english")
  original_mfd$i2[i] = stemDocument(original_mfd$i2[i], language = "english")
  original_mfd$a2[i] = stemDocument(original_mfd$a2[i], language = "english")
  original_mfd$p2[i] = stemDocument(original_mfd$p2[i], language = "english")
}

mtmmdata = noout2[ , c(1:31, 42) ]

####figure out the percents for the exp2 data
for (i in 1:nrow(mtmmdata)) {
  
  ##figure out the sum for just the original mfd
  mtmmdata$harm_orig[i] = sum(overall_final[ i , colnames(overall_final) %in% unique(original_mfd$h2[original_mfd$h2 != "" & original_mfd$h2 != "NA"])])
  
  mtmmdata$purity_orig[i] = sum(overall_final[ i , colnames(overall_final) %in% unique(original_mfd$p2[original_mfd$p2 != "" & original_mfd$p2 != "NA"])])
    
  mtmmdata$fair_orig[i] = sum(overall_final[ i , colnames(overall_final) %in% unique(original_mfd$f2[original_mfd$f2 != "" & original_mfd$f2 != "NA"])])

  mtmmdata$authority_orig[i] = sum(overall_final[ i , colnames(overall_final) %in% unique(original_mfd$a2[original_mfd$a2 != "" & original_mfd$a2 != "NA"])])
  
  mtmmdata$ingroup_orig[i] = sum(overall_final[ i , colnames(overall_final) %in% unique(original_mfd$i2[original_mfd$i2 != "" & original_mfd$i2 != "NA"])])
  
  ##figure out the sum for all words ever 
  mtmmdata$harm_all[i] = sum(overall_final[ i , colnames(overall_final) %in% unique(c(original_mfd$h2[original_mfd$h2 != "" & original_mfd$h2 != "NA"], harm_words, harm_words_reduce_exp2))])
  
  mtmmdata$purity_all[i] = sum(overall_final[ i , colnames(overall_final) %in% unique(c(original_mfd$p2[original_mfd$p2 != "" & original_mfd$p2 != "NA"], purity_words, purity_words_reduce_exp2))])
    
  mtmmdata$fair_all[i] = sum(overall_final[ i , colnames(overall_final) %in% unique(c(original_mfd$f2[original_mfd$f2 != "" & original_mfd$f2 != "NA"], fair_words, fair_words_reduce_exp2))])

  mtmmdata$authority_all[i] = sum(overall_final[ i , colnames(overall_final) %in% unique(c(original_mfd$a2[original_mfd$a2 != "" & original_mfd$a2 != "NA"], authority_words, authority_words_reduce_exp2))])
  
  mtmmdata$ingroup_all[i] = sum(overall_final[ i , colnames(overall_final) %in% unique(c(original_mfd$i2[original_mfd$i2 != "" & original_mfd$i2 != "NA"], ingroup_words, ingroup_words_reduce_exp2))])
  
  ##figure out the sum for reduced words
  mtmmdata$harm_reduce[i] = sum(overall_final[ i , colnames(overall_final) %in% unique(c(original_mfd$h2[original_mfd$h2 != "" & original_mfd$h2 != "NA"], harm_words_reduce, harm_words_reduce_exp2))])
  
  mtmmdata$purity_reduce[i] = sum(overall_final[ i , colnames(overall_final) %in% unique(c(original_mfd$p2[original_mfd$p2 != "" & original_mfd$p2 != "NA"], purity_words_reduce, purity_words_reduce_exp2))])
    
  mtmmdata$fair_reduce[i] = sum(overall_final[ i , colnames(overall_final) %in% unique(c(original_mfd$f2[original_mfd$f2 != "" & original_mfd$f2 != "NA"], fair_words_reduce, fair_words_reduce_exp2))])

  mtmmdata$authority_reduce[i] = sum(overall_final[ i , colnames(overall_final) %in% unique(c(original_mfd$a2[original_mfd$a2 != "" & original_mfd$a2 != "NA"], authority_words_reduce, authority_words_reduce_exp2))])
  
  mtmmdata$ingroup_reduce[i] = sum(overall_final[ i , colnames(overall_final) %in% unique(c(original_mfd$i2[original_mfd$i2 != "" & original_mfd$i2 != "NA"], ingroup_words_reduce, ingroup_words_reduce_exp2))])

}

#create percents instead of frequencies
mtmmdata[ , c(33:47)] = mtmmdata[ , c(33:47)] / mtmmdata$wordcount * 100 

summary(mtmmdata[ , 33:47])

```

```{r mtmm_orig, include = FALSE}
###Run chunk 8: demos_study2 to update data
###Use noout2 df as dataframe for mtmm
###Columns labeled Harm1/Fairness1/Loyalty1/Authority1/Purity1 are original MFD
###Columns labeled Harm2/Fairness2/Loyalty2/Authority2/Purity2 are revised MFD

##now run some MTMM!
library(semPlot)
library(lavaan)

####mtmm original dictionary####

{model1 = '
harmL =~ Q8_1+Q8_2+Q8_3+harm_orig
fairL =~ Q8_4+Q8_5+Q8_6+fair_orig
ingroupL =~ Q8_7+Q8_8+Q8_9+ingroup_orig
authorityL =~ Q8_10+Q8_11+Q8_12+authority_orig
purityL=~ Q8_13+Q8_14+Q8_15+purity_orig 
mfq =~ Q8_1+Q8_2+Q8_3+Q8_4+Q8_5+Q8_6+Q8_7+Q8_8+Q8_9+Q8_10+Q8_11+Q8_12+Q8_13+Q8_14+Q8_15
mfd =~ harm_orig+fair_orig+ingroup_orig+authority_orig+purity_orig

##fix the covariances
harmL~~0*mfq
fairL~~0*mfq
ingroupL~~0*mfq
authorityL~~0*mfq
purityL~~0*mfq
harmL~~0*mfd
fairL~~0*mfd
ingroupL~~0*mfd
authorityL~~0*mfd
purityL~~0*mfd
'}

model1.fit = cfa(model1, data=mtmmdata, std.lv=TRUE)
summary(model1.fit, rsquare=TRUE, standardized=TRUE)
semPaths(model1.fit, whatLabels = "std", layout = "tree")
fitMeasures(model1.fit, fit.measures = "aic")

{model1.2 = '
harmL =~ Q8_1+Q8_2+Q8_3+harm_orig
fairL =~ Q8_4+Q8_5+Q8_6+fair_orig
ingroupL =~ Q8_7+Q8_8+Q8_9+ingroup_orig
authorityL =~ Q8_10+Q8_11+Q8_12+authority_orig
purityL=~ Q8_13+Q8_14+Q8_15+purity_orig 
mfq =~ Q8_1+Q8_2+Q8_3+Q8_4+Q8_5+Q8_6+Q8_7+Q8_8+Q8_9+Q8_10+Q8_11+Q8_12+Q8_13+Q8_14+Q8_15
mfd =~ harm_orig+fair_orig+ingroup_orig+authority_orig+purity_orig

fair_orig ~~ 1167.145*fair_orig

##fix the covariances
harmL~~0*mfq
fairL~~0*mfq
ingroupL~~0*mfq
authorityL~~0*mfq
purityL~~0*mfq
harmL~~0*mfd
fairL~~0*mfd
ingroupL~~0*mfd
authorityL~~0*mfd
purityL~~0*mfd
'}

model1.2.fit = cfa(model1.2, data=mtmmdata, std.lv=TRUE)
summary(model1.2.fit, rsquare=TRUE, standardized=TRUE)
semPaths(model1.2.fit, whatLabels = "std", layout = "tree")
fitMeasures(model1.2.fit, fit.measures = "aic")

{model2 ='
mfq =~ Q8_1+Q8_2+Q8_3+Q8_4+Q8_5+Q8_6+Q8_7+Q8_8+Q8_9+Q8_10+Q8_11+Q8_12+Q8_13+Q8_14+Q8_15
mfd =~ harm_orig+fair_orig+ingroup_orig+authority_orig+purity_orig

fair_orig ~~ 1167.145*fair_orig
'}

model2.fit = cfa(model2, data=mtmmdata, std.lv=TRUE)
summary(model2.fit, rsquare=TRUE, standardized=TRUE)
fitMeasures(model2.fit, fit.measures = "aic")

{model3 = '
harmL =~ Q8_1+Q8_2+Q8_3+harm_orig
fairL =~ Q8_4+Q8_5+Q8_6+fair_orig
ingroupL =~ Q8_7+Q8_8+Q8_9+ingroup_orig
authorityL =~ Q8_10+Q8_11+Q8_12+authority_orig
purityL=~ Q8_13+Q8_14+Q8_15+purity_orig 
mfq =~ Q8_1+Q8_2+Q8_3+Q8_4+Q8_5+Q8_6+Q8_7+Q8_8+Q8_9+Q8_10+Q8_11+Q8_12+Q8_13+Q8_14+Q8_15
mfd =~ harm_orig+fair_orig+ingroup_orig+authority_orig+purity_orig

##fix the covariances
harmL~~0*mfq
fairL~~0*mfq
ingroupL~~0*mfq
authorityL~~0*mfq
purityL~~0*mfq
harmL~~0*mfd
fairL~~0*mfd
ingroupL~~0*mfd
authorityL~~0*mfd
purityL~~0*mfd
harmL~~1*fairL
harmL~~1*ingroupL
harmL~~1*authorityL
harmL~~1*purityL
fairL~~1*ingroupL
fairL~~1*authorityL
fairL~~1*purityL
ingroupL~~1*authorityL
ingroupL~~1*purityL
authorityL~~1*purityL

fair_orig ~~ 1167.145*fair_orig
'}

model3.fit = cfa(model3, data=mtmmdata, std.lv=TRUE)
summary(model3.fit, rsquare=TRUE, standardized=TRUE)
fitMeasures(model3.fit, fit.measures = "aic")

{model4 = '
harmL =~ Q8_1+Q8_2+Q8_3+harm_orig
fairL =~ Q8_4+Q8_5+Q8_6+fair_orig
ingroupL =~ Q8_7+Q8_8+Q8_9+ingroup_orig
authorityL =~ Q8_10+Q8_11+Q8_12+authority_orig
purityL=~ Q8_13+Q8_14+Q8_15+purity_orig 
mfq =~ Q8_1+Q8_2+Q8_3+Q8_4+Q8_5+Q8_6+Q8_7+Q8_8+Q8_9+Q8_10+Q8_11+Q8_12+Q8_13+Q8_14+Q8_15
mfd =~ harm_orig+fair_orig+ingroup_orig+authority_orig+purity_orig

##fix the covariances
harmL~~0*mfq
fairL~~0*mfq
ingroupL~~0*mfq
authorityL~~0*mfq
purityL~~0*mfq
harmL~~0*mfd
fairL~~0*mfd
ingroupL~~0*mfd
authorityL~~0*mfd
purityL~~0*mfd
mfq ~~ 0*mfd

fair_orig ~~ 1167.145*fair_orig
'}

model4.fit = cfa(model4, data=mtmmdata, std.lv=TRUE)
summary(model4.fit, rsquare=TRUE, standardized=TRUE)
fitMeasures(model4.fit, fit.measures = "aic")
```

```{r mtmm_reduce, include = FALSE}

{model1 = '
harmL =~ Q8_1+Q8_2+Q8_3+harm_reduce
fairL =~ Q8_4+Q8_5+Q8_6+fair_reduce
ingroupL =~ Q8_7+Q8_8+Q8_9+ingroup_reduce
authorityL =~ Q8_10+Q8_11+Q8_12+authority_reduce
purityL=~ Q8_13+Q8_14+Q8_15+purity_reduce 
mfq =~ Q8_1+Q8_2+Q8_3+Q8_4+Q8_5+Q8_6+Q8_7+Q8_8+Q8_9+Q8_10+Q8_11+Q8_12+Q8_13+Q8_14+Q8_15
mfd =~ harm_reduce+fair_reduce+ingroup_reduce+authority_reduce+purity_reduce

##fix the covariances
harmL~~0*mfq
fairL~~0*mfq
ingroupL~~0*mfq
authorityL~~0*mfq
purityL~~0*mfq
harmL~~0*mfd
fairL~~0*mfd
ingroupL~~0*mfd
authorityL~~0*mfd
purityL~~0*mfd
'}

model1.fit = cfa(model1, data=mtmmdata, std.lv=TRUE)
summary(model1.fit, rsquare=TRUE, standardized=TRUE)
semPaths(model1.fit, whatLabels = "std", layout = "tree")
fitMeasures(model1.fit, fit.measures = "aic")

{model2 ='
mfq =~ Q8_1+Q8_2+Q8_3+Q8_4+Q8_5+Q8_6+Q8_7+Q8_8+Q8_9+Q8_10+Q8_11+Q8_12+Q8_13+Q8_14+Q8_15
mfd =~ harm_reduce+fair_reduce+ingroup_reduce+authority_reduce+purity_reduce
'}

model2.fit = cfa(model2, data=mtmmdata, std.lv=TRUE)
summary(model2.fit, rsquare=TRUE, standardized=TRUE)
fitMeasures(model2.fit, fit.measures = "aic")

{model3 = '
harmL =~ Q8_1+Q8_2+Q8_3+harm_reduce
fairL =~ Q8_4+Q8_5+Q8_6+fair_reduce
ingroupL =~ Q8_7+Q8_8+Q8_9+ingroup_reduce
authorityL =~ Q8_10+Q8_11+Q8_12+authority_reduce
purityL=~ Q8_13+Q8_14+Q8_15+purity_reduce 
mfq =~ Q8_1+Q8_2+Q8_3+Q8_4+Q8_5+Q8_6+Q8_7+Q8_8+Q8_9+Q8_10+Q8_11+Q8_12+Q8_13+Q8_14+Q8_15
mfd =~ harm_reduce+fair_reduce+ingroup_reduce+authority_reduce+purity_reduce

##fix the covariances
harmL~~0*mfq
fairL~~0*mfq
ingroupL~~0*mfq
authorityL~~0*mfq
purityL~~0*mfq
harmL~~0*mfd
fairL~~0*mfd
ingroupL~~0*mfd
authorityL~~0*mfd
purityL~~0*mfd
harmL~~1*fairL
harmL~~1*ingroupL
harmL~~1*authorityL
harmL~~1*purityL
fairL~~1*ingroupL
fairL~~1*authorityL
fairL~~1*purityL
ingroupL~~1*authorityL
ingroupL~~1*purityL
authorityL~~1*purityL
'}

model3.fit = cfa(model3, data=mtmmdata, std.lv=TRUE)
summary(model3.fit, rsquare=TRUE, standardized=TRUE)
fitMeasures(model3.fit, fit.measures = "aic")

{model4 = '
harmL =~ Q8_1+Q8_2+Q8_3+harm_reduce
fairL =~ Q8_4+Q8_5+Q8_6+fair_reduce
ingroupL =~ Q8_7+Q8_8+Q8_9+ingroup_reduce
authorityL =~ Q8_10+Q8_11+Q8_12+authority_reduce
purityL=~ Q8_13+Q8_14+Q8_15+purity_reduce 
mfq =~ Q8_1+Q8_2+Q8_3+Q8_4+Q8_5+Q8_6+Q8_7+Q8_8+Q8_9+Q8_10+Q8_11+Q8_12+Q8_13+Q8_14+Q8_15
mfd =~ harm_reduce+fair_reduce+ingroup_reduce+authority_reduce+purity_reduce

##fix the covariances
harmL~~0*mfq
fairL~~0*mfq
ingroupL~~0*mfq
authorityL~~0*mfq
purityL~~0*mfq
harmL~~0*mfd
fairL~~0*mfd
ingroupL~~0*mfd
authorityL~~0*mfd
purityL~~0*mfd
mfq ~~ 0*mfd
'}

model4.fit = cfa(model4, data=mtmmdata, std.lv=TRUE)
summary(model4.fit, rsquare=TRUE, standardized=TRUE)
fitMeasures(model4.fit, fit.measures = "aic")
```

```{r mtmm_all, include = FALSE}

{model1 = '
harmL =~ Q8_1+Q8_2+Q8_3+harm_all
fairL =~ Q8_4+Q8_5+Q8_6+fair_all
ingroupL =~ Q8_7+Q8_8+Q8_9+ingroup_all
authorityL =~ Q8_10+Q8_11+Q8_12+authority_all
purityL=~ Q8_13+Q8_14+Q8_15+purity_all 
mfq =~ Q8_1+Q8_2+Q8_3+Q8_4+Q8_5+Q8_6+Q8_7+Q8_8+Q8_9+Q8_10+Q8_11+Q8_12+Q8_13+Q8_14+Q8_15
mfd =~ harm_all+fair_all+ingroup_all+authority_all+purity_all

##fix the covariances
harmL~~0*mfq
fairL~~0*mfq
ingroupL~~0*mfq
authorityL~~0*mfq
purityL~~0*mfq
harmL~~0*mfd
fairL~~0*mfd
ingroupL~~0*mfd
authorityL~~0*mfd
purityL~~0*mfd
'}

model1.fit = cfa(model1, data=mtmmdata, std.lv=TRUE)
summary(model1.fit, rsquare=TRUE, standardized=TRUE)
semPaths(model1.fit, whatLabels = "std", layout = "tree")
fitMeasures(model1.fit, fit.measures = "aic")

{model2 ='
mfq =~ Q8_1+Q8_2+Q8_3+Q8_4+Q8_5+Q8_6+Q8_7+Q8_8+Q8_9+Q8_10+Q8_11+Q8_12+Q8_13+Q8_14+Q8_15
mfd =~ harm_all+fair_all+ingroup_all+authority_all+purity_all
'}

model2.fit = cfa(model2, data=mtmmdata, std.lv=TRUE)
summary(model2.fit, rsquare=TRUE, standardized=TRUE)
fitMeasures(model2.fit, fit.measures = "aic")

{model3 = '
harmL =~ Q8_1+Q8_2+Q8_3+harm_all
fairL =~ Q8_4+Q8_5+Q8_6+fair_all
ingroupL =~ Q8_7+Q8_8+Q8_9+ingroup_all
authorityL =~ Q8_10+Q8_11+Q8_12+authority_all
purityL=~ Q8_13+Q8_14+Q8_15+purity_all 
mfq =~ Q8_1+Q8_2+Q8_3+Q8_4+Q8_5+Q8_6+Q8_7+Q8_8+Q8_9+Q8_10+Q8_11+Q8_12+Q8_13+Q8_14+Q8_15
mfd =~ harm_all+fair_all+ingroup_all+authority_all+purity_all

##fix the covariances
harmL~~0*mfq
fairL~~0*mfq
ingroupL~~0*mfq
authorityL~~0*mfq
purityL~~0*mfq
harmL~~0*mfd
fairL~~0*mfd
ingroupL~~0*mfd
authorityL~~0*mfd
purityL~~0*mfd
harmL~~1*fairL
harmL~~1*ingroupL
harmL~~1*authorityL
harmL~~1*purityL
fairL~~1*ingroupL
fairL~~1*authorityL
fairL~~1*purityL
ingroupL~~1*authorityL
ingroupL~~1*purityL
authorityL~~1*purityL
'}

model3.fit = cfa(model3, data=mtmmdata, std.lv=TRUE)
summary(model3.fit, rsquare=TRUE, standardized=TRUE)
fitMeasures(model3.fit, fit.measures = "aic")

{model4 = '
harmL =~ Q8_1+Q8_2+Q8_3+harm_all
fairL =~ Q8_4+Q8_5+Q8_6+fair_all
ingroupL =~ Q8_7+Q8_8+Q8_9+ingroup_all
authorityL =~ Q8_10+Q8_11+Q8_12+authority_all
purityL=~ Q8_13+Q8_14+Q8_15+purity_all 
mfq =~ Q8_1+Q8_2+Q8_3+Q8_4+Q8_5+Q8_6+Q8_7+Q8_8+Q8_9+Q8_10+Q8_11+Q8_12+Q8_13+Q8_14+Q8_15
mfd =~ harm_all+fair_all+ingroup_all+authority_all+purity_all

##fix the covariances
harmL~~0*mfq
fairL~~0*mfq
ingroupL~~0*mfq
authorityL~~0*mfq
purityL~~0*mfq
harmL~~0*mfd
fairL~~0*mfd
ingroupL~~0*mfd
authorityL~~0*mfd
purityL~~0*mfd
mfq ~~ 0*mfd
'}

model4.fit = cfa(model4, data=mtmmdata, std.lv=TRUE)
summary(model4.fit, rsquare=TRUE, standardized=TRUE)
fitMeasures(model4.fit, fit.measures = "aic")
```



  Data Cleaning and Descriptives. In sample 1, participants who wrote less than 50 words were deleted (*n* = 69) leaving *n* = 221 participants. The average political orientation was 4.80 (*SD* = 2.21) on a scale of 1 (*conservative*) to 10 (*liberal*). In sample 2, all 160 participants wrote at least 50 words. The mean political orientation was 5.01 (*SD* = 2.33) for sample 2. The data from sample 1 and sample 2 were combined. Before any analyses were conducted, participants who did not use any words from the MFD were deleted; 16 participants were deleted from sample 1 and 25 from sample 2. The final sample size for analysis was *N* = 340 which had a mean political orientation of 4.90 (*SD* = 2.28). MFD scores were computed using NVivo *(CITE)* as both frequency for each foundation and percent coverage for each foundation. Frequency was simply the count of the number of words used from a given foundation dictionary; for example, a participant using the word *war* once and the word *peace* twice would have a frequency score of 3 for the *harm* dictionary. Percent coverage was calculated by taking the frequency and dividing by the word count; for example, given a frequency score of 3 for the *harm* dictionary and a word count of 100, then the percent coverage would be .03 for the *harm* dictionary. MFQ scores for each foundation were calculated by averaging the six items pertaining to each foundation. 
	Reliability. Here we should talk about the reliability of the MFQ for each piece, as well as the reliability of the words for the MFD. I think to do that you might need a thing that has each word as frequency count yes/no or however the LIWC version thing was done. 
	MTMM. BASIC SEM STUFF HERE (also that you used bayes)
Data screening was conducted using SPSS version 22 and AMOS version 22. Participants who were missing data for the MFD, MFQ, or political orientation were deleted from all analyses. Given the distribution of the dictionary variables, participants whose writing sample were less than 2% words from the MFD were deleted resulting in a sample size of 252. Additionally, 7 outliers were deleted.
Widaman's (1985; as cited in @Byrne2009) four-step nested method was used to test the convergent and divergent validity of the MFD and MFQ. The first step is the baseline model (Model 1), which establishes correlation among traits (*harm*, *purity*, *fairness*, *authority*, and *ingroup*) as well as correlation among methods (MFD and MFQ) but no cross correlation of traits and methods. The individual questions from the 30 item version of the MFQ and the total frequency of concepts from each foundation in the MFD were used as measured variables. 
The fit of this first model indicated some misfit, as fit indices were a mix of poor and acceptable, $\chi$ 2 (514) = 977.46, $\chi$ 2/df = 1.90, CFI = .842, RMSEA = .061 [95% CI = .055-.067], SRMR = .0623. In this model, the MFD *harm*, *fairness*, and *ingroup* items significantly loaded onto their trait factors, while *authority* and *purity* did not. All foundations but *authority* loaded significantly on the method traits. All but two of the *ingroup* questions and one *authority* question loaded onto the MFQ trait factors. Several questions of the MFQ did not load significantly onto the methods factors; however, this result was taken as an indicator that traits variance was higher than methods variance. Generally, trait loadings were higher than method loadings for both the MFD and MFQ for *harm* and *fairness* traits. However, the *purity*, *ingroup*, and *authority* foundations did not show this loading pattern. 
ERIN STOPPED HERE CUZ HEADACHE. 
The second step (Model 2) involved eliminating the latent traits from the model. This model was significantly worse than Model 1 indicating the traits are important to the model ($\delta$ $\chi$ 2 = 1141.09, $\delta$ df = 45, $\delta$ CFI = .351). This supports convergent validity for the traits measured by both methods which in this case are the five moral foundations. The third step (Model 3) involved forcing the five traits to be perfectly correlated. This model was significantly worse than Model 1 indicating the usefulness of five unique traits ($\delta$ $\chi$ 2 = 311.09, $\delta$ df = 10, $\delta$ CFI = .097). This supports discriminant validity for the existence of five unique moral foundations. The final step (Model 4) involved allowing the correlations between the traits to be freely estimated and forcing the methods to be uncorrelated. This model was similar to Model 1 indicating the methods both measure the traits but they are both unique methods ($\delta$ $\chi$ 2 = 2.23, $\delta$ df = 1, $\delta$ CFI = .001). This supports discriminant validity for the methods. This set of analyses suggests the MFD is a possibly valid measure of moral foundations but does not measure them well enough to be useful in all applications and may be measuring them differently than the MFQ. 
	Regression predicting Political Orientation. The MFQ has predicted political orientation across many studies [@Federico2013; @Graham2009; @Haidt2009; @Weber2013]. Therefore, in addition to the MTMM analysis, we compared how well the MFD score predicted political orientation compared to how well the MFQ predicted the political orientation. First, total MFQ scores were calculated for each foundation by averaging all six items. Then, a regression analysis was conducted with the five MFQ foundation score predicting political orientation. The overall model was significant, *R2* = .35, *F* (5, 255) = 26.91, *p* < .05. Higher scores on the harm and fairness foundations predicted a more liberal political orientation with harm accounting for 3% of the variance and fairness accounting for 6%. Higher scores on ingroup, authority, and purity predicted a more conservative orientation accounting for 1%, 2%, and 8% on the variance respectively. See *table ?* for regression coefficients. Next, a regression analysis was conducted to determine how well the five MFD scores predicted political orientation. The overall model was not significant, *R2* = .16, *F* (5, 255) = 1.36, *p* = .241. Higher harm scores somewhat predicted more liberal orientation accounting for 1% of the variance in political orientation. Higher purity scores somewhat predicted more conservative orientation accounting for 1% of the variance. See *table ?* for regression coefficients.



# Participants

Participants were recruited in two waves as part of a larger investigation on priming political and religious attitudes (???). Participants were recruited via an online research system (SONA) and were given course credit for their participation. 463 participants were
included in the this study. The study was mostly women (53.9%) and White (76.4%) participants with a mix of minority participants: Black (6.1%), (3.6%), (4.2%), Native American (1.9%), Mixed (2.9%) and Other (4.9%). The average listed age was 19.75 (SD =
200 2.94).

# Materials and Procedure

Data was again collected via Qualtrics. Four fake new stories were presented to participants, which were roughly 400 words each. First, all news stories included a few
sentences describing the use of chemical weapons in the Syrian civil war. The news stories were manipulated with political (Republican v. Democrat) and religious (religious v. not) quotes in a 2 x 2 design. News stories can be found in the online materials. Participants also completed the 30-item version of the MFQ as described in the introduction. In addition to basic demographics (gender, age), participant political orientation was assessed with the same scale described in Experiment 1.

After consenting to participate in the study, participants were randomly shown one of
the four new articles about Syrias use of chemical weapons. Participants were then asked to
write for 5-10 minutes about their reaction to Syrias use of chemical weapons and the
needed response from the United States. The second wave of data collection included
different writing prompts designed to capture more of the moral foundation areas in their writing. The following writing prompt was used, Please write about your attitudes on
abortion (or same-sex marriage or environmentalism) as well as your reason for this stance.
The three prompts were chosen to create a more varied word set by using topics that should
elicit words from each moral foundations category by soliciting a moral response. In each wave of data collection (Syria prompts, moral prompts) the prompt material was randomized between participants. Participants then completed the MFQ, demographics, and the political
orientation scale.

# Results


# Expanding the MFD

In a separate study of 466 university students, participants completed a free association task where we asked them to list all the words that came to mind from *harm/care*, *fairness/cheating*, *loyalty/XX*, *authority/XX*, *purity/XX*. They also completed the 15 item MFQ. Responses to the free association task were cleaned and stemmed. This lead to a new set of moral foundation words: harm-96, fairness-76, ingroup-86, authority-81, and purity-80. These concepts were included in the full dictionary used for Experiment 3. 

We additionally created a reduced dictionary that included only concepts correlated with their respective moral foundations scores. Correlations between word frequency and the sum of the MFQ were calculated for each foundation and set of concepts. Words were included in the reduced dictionary if their correlation was two standard deviations away from the mean correlation for that foundation. The reduced dataset included the following number of words for each foundation: harm 4, fairness 3, ingroup 3, authority 4, and purity 2.

```{r word-association}
#need the code for the the above stuff
```

[ERIN, Please do mathy-math here]

# Testing Model Structure

Before testing the theorized differences between liberals and conservatives, we sought to test the validity of the MFD using Multi-Trait, Multi-Method modelling (MTMM) to determine if the MFD is measuring the same latent variables as the MFQ as it should.

```{r mtmm}


```

# Testing Group Differences

```{r mtmm-groupdiffs}

```

# Discussion

The results obtained in Study 2 are slightly more in line with expectations from MFT, however, in all but one case, the differences were not statistically significant. The only statistically significant difference was in the harm foundation; liberals did endorse harm more than conservatives during the Kavanaugh hearings, but the effect was smaller than expected given @Graham2009. Generally for both the Kavanaugh hearings and the Government shutdown, the differences were in the expected direction (liberals endorsing harm more and conservatives endorsing authority and loyalty more), but the differences were not statistically significant and the practical effects much smaller than reported in @Graham2009. While not significant, fairness was endorsed more by conservatives in both cases. In contrast, purity was endorsed more by conservatives for the government shutdown, but more by liberals for the Kavanaugh hearing though neither difference was statistically significant.

Together with Study 1 and past work, Study 2 further calls into question the usefulness and efficacy of the Moral Foundations as well as cast doubt on the predictions made by MFT. One issue that Study 2 brings up is that moral differences between liberals and conservatives may be moderated by a number of factors as shown in @Sterling2018. For example, here we have liberals concerned with purity for the Kavanaugh hearings (a moral bad for liberals and a moral good for conservatives) and conservatives concerned with purity during the government shutdown (a moral bad for conservatives and a moral good for liberals). The original predictions made by the Moral Foundations are very simplistic and likely much more complex in reality.

# Conclusions

Within the theoretical framework of MFT [@Haidt2007], we attempted to devise a method leveraging the MFD [@Graham2009] in order to quantify political bias stemming from content published by several prominent American news sources. In Study 1,the results obtained were not significant in any statistical or practical sense. There was a small effect found for the *authority/respect* foundation according to Cohen's *d*, but the effect suggested endorsement for that foundation opposite to what was hypothesized. In Study 2, the direction of the differences were generally in line with MFT, however, the difference were very small and lacks statistically significance. Building on @Frimer2020 and other critiques of MFT and the MFD, we show that MFD is not a useful tool for measuring moral language while also calling into question the validity of MFT in terms of theorized partisan differences.

Despite the fact the results regarding political bias were inconclusive, we still retain confidence in the overall structure of the methodology established in the current study. Specifically, the procedure for scraping text from the web, processing, stemming, and weighting the scores with valence seems to represent a solid method for preparing a high quantity of text passages for data analysis. We implemented valence as an indicator of the directionality of endorsement due to the inherent ambiguity of simply calculating MFD word percent occurrence. This method served both to augment the face validity of the MFD by incorporating valence (thus reducing ambiguity) and to generate a score that is easy to understand and analyze.

However, political lean and other important political/moral constructs may be communicated through methods other than through the use of particular words. As mentioned before, MFD is a measure developed from MFT [@Graham2009]. Based upon the results obtained, it might be necessary to investigate alternative instruments that could better elucidate the differences of interest. Going beyond specific instruments, other theoretical perspectives may be more equipped to explain political differences in discourse. Likewise, an atheoretical approach in which large quantities of data are collected from which theories are formulated may be best suited to this area of research.

In critiquing MFT, @Schein2015 proposed an alternative theory explaining moral choices and potential partisan differences: Dyadic Theory of Morality. Across many studies, researchers find that supposed differences in moral foundation can be more easily explained by a harm-focused morality where someone/thing is harmed by someone/thing else [@Gray2014, @Schein2015]. Rather than liberals and conservatives having difference conceptions of morality, dyadic morality argues that they simply identify harm differently. For example, in the case of abortion, liberals tend to identify the primary harm to the mother leading to a pro-choice position whereas conservative tend to identify the primary harm to the fetus leading to a pro-life position. While as of yet, no linguistic measurement of dyadic morality exists; such an approach may be able to better identify the systematic differences between liberals and conservatives.

Turning to atheoretical approaches, future studies aiming to uncover political lean in discourse may benefit from a bottom-up, data-driven approach. Researchers might derive substantive insights into political lean through gathering data after which they may formulate theories that explain systematic observations obtained from that data. The availability of text corpora along with methods for extracting large amounts of text from the internet (as was demonstrated in the current study) potentially make this a feasible option. Likewise, there are several approaches to analyzing such data, including linear models (like multilevel models) and network-style models such as latent semantic analysis [@Landauer1998]. Owing to the wealth of representative data as well as the sophistication of current analytic tools, there is high potential for the explanatory power of new theories involving political discourse.  

Never before has political discourse represented such fertile ground for psychological research. The plethora of options for news sources has created not only an abundance of choice but also vast quantities of text data. Along with this recent increase in the amount of text information, there is now an obligation on the part of researchers to devise proper methods for analyzing that text. Solid methodologies must be constructed and periodically improved to keep pace with evolving technologies. Likewise, a strong theoretical foundation is paramount to making sense of the current and future media ecosystem. Therefore, it is incumbent upon social scientists to continue investigating the information consumed by millions of Americans every day so that insights into the nature and consequences of political discourse can be more completely understood.

\newpage

# References

\begingroup
<div id="refs" custom-style="Bibliography"></div>
\endgroup
